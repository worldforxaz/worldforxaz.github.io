<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>xaz的花花世界</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2025-09-17T11:48:29.165Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>xaz</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>读书集</title>
    <link href="http://example.com/2025/09/14/8-%E6%9D%82%E8%B0%88/%E8%AF%BB%E4%B9%A6%E9%9B%86/"/>
    <id>http://example.com/2025/09/14/8-%E6%9D%82%E8%B0%88/%E8%AF%BB%E4%B9%A6%E9%9B%86/</id>
    <published>2025-09-14T07:53:48.000Z</published>
    <updated>2025-09-17T11:48:29.165Z</updated>
    
    <content type="html"><![CDATA[<p>[toc]</p><h1 id="书"><a href="#书" class="headerlink" title="书"></a>书</h1><ol><li><p>景观社会 -德波</p></li><li><p>昨日的世界  -茨威格</p></li><li><p>生命是什么  -薛定谔</p></li><li><p>论灵魂的激情 -笛卡尔</p></li><li><p>权力与特权</p></li><li><p>二十一世纪资本论</p></li><li><p>宇宙的琴弦（The Elegent  Universe)</p></li><li><p>韩非子</p></li><li><p>沉思录 -埃比克泰德</p></li><li><p>纠缠性与隐缠序 -波姆</p></li><li><p>尼安德特人 -帕博</p></li><li><p>我的回忆 -张国焘</p></li><li><p>中国人民解放军政治工作历史资料选编</p></li><li><p>伟大的中国革命 -费正清</p></li><li><p>剑桥中国史</p></li><li><p>宅兹中国 -葛兆光</p></li><li><p>三体 -刘慈欣</p></li><li><p>1989北京制止动乱-平息反革命暴乱纪事</p></li><li><p>培根随笔 </p></li><li><p>朱自清散文选集</p></li><li><p>王安石文集</p></li><li><p>宋濂文集</p></li><li><p>Breaking Through  -Katalin Karikó</p></li></ol><h1 id="文"><a href="#文" class="headerlink" title="文"></a>文</h1><p><a href="https://datagubbe.se/famous/">Not as famous as they should be</a></p><p><a href="https://harpers.org/archive/1932/10/in-praise-of-idleness/">In Praise of Idleness, by Bertrand Russell</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;[toc]&lt;/p&gt;
&lt;h1 id=&quot;书&quot;&gt;&lt;a href=&quot;#书&quot; class=&quot;headerlink&quot; title=&quot;书&quot;&gt;&lt;/a&gt;书&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;景观社会 -德波&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;昨日的世界  -茨威格&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>无监督学习</title>
    <link href="http://example.com/2025/09/08/4-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"/>
    <id>http://example.com/2025/09/08/4-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/</id>
    <published>2025-09-08T02:48:28.000Z</published>
    <updated>2025-09-12T12:25:32.071Z</updated>
    
    <content type="html"><![CDATA[<p>[toc]</p><h1 id="1-无监督学习介绍"><a href="#1-无监督学习介绍" class="headerlink" title="1. 无监督学习介绍"></a>1. 无监督学习介绍</h1><p>无监督学习（Unsupervised Learning）是机器学习的一个核心分支，其主要特点是使用<strong>未经标记</strong>的数据进行训练。无监督学习算法需要自行在数据中探索和发现隐藏的结构、模式和关系。</p><p>无监督学习主要包括以下几种任务类型：</p><p>聚类：对数据进行分类。相比于排序，聚类的优势是能够在多维分析。聚类不是为了“排名”，而是为了“画像”</p><p>降维：减少数据特征的数量。降维就是在尽可能保留数据最重要信息的前提下，用更少的特征来表示数据</p><p>关联规则挖掘：在数据中发现项与项的关联关系。关联特征分析不处理特征数值的大小，只处理特征之间出现的协同性。处理特征数值大小之间的关系的是相关性分析。</p><h1 id="2-无监督学习和监督学习的区别"><a href="#2-无监督学习和监督学习的区别" class="headerlink" title="2. 无监督学习和监督学习的区别"></a>2. 无监督学习和监督学习的区别</h1><p>无监督学习是对整体进行操作分类，监督学习是在训练好后对个体的预测</p><h1 id="3-聚类"><a href="#3-聚类" class="headerlink" title="3.聚类"></a>3.聚类</h1><p>聚类的结果，高度依赖于你喂给它的特征。你想得到什么样的分类，就必须提供与之强相关的特征数据</p><p>相比于排序，聚类的优势是能够在多维分析</p><p>聚类不是为了“排名”，而是为了“画像”</p><h1 id="4-降维"><a href="#4-降维" class="headerlink" title="4.降维"></a>4.降维</h1><p>降维就是在尽可能保留数据最重要信息的前提下，用更少的特征来表示数据</p><p>降维主要通过两种途径实现：特征选择和特征提取</p><p>算法的任务不是去“学习一个映射关系去预测某个标签”，而是必须在数据内部“自力更生”，仅通过分析数据点本身，去发现其中隐藏的、有意义的结构和模式。</p><ul><li>聚类如何体现无监督？ 它在拿到一堆客户数据时，不需要预先知道“哪个客户是高价值客户”或“哪个客户即将流失”。它完全不依赖任何已有标签，而是自主地、仅仅根据客户数据特征（如消费金额、频率）之间的相似性，去划分出不同的客户群体。</li><li>降维如何体现无监督？ 它同样不需要任何标签来指导。它在拿到描述汽车的上百个特征时，不需要知道“哪辆车是豪车”或“哪辆车性能好”。它只是自主地分析这些特征之间的内在关系（如相关性、方差分布），然后找到一种更简洁、更高效的方式来表达整个数据集，比如用几个“主成分”来概括。</li></ul><p>所以，它们最根本、最核心的相似点就是：</p><p>它们的目标都不是“预测”一个外部标签，而是“理解”数据自身的内在结构。</p><hr><h1 id="Gemini"><a href="#Gemini" class="headerlink" title="Gemini"></a>Gemini</h1><p>什么是无监督学习 </p><h2 id="什么是无监督学习？"><a href="#什么是无监督学习？" class="headerlink" title="什么是无监督学习？"></a>什么是无监督学习？</h2><p>无监督学习（Unsupervised Learning）是机器学习的一个核心分支，其主要特点是使用<strong>未经标记</strong>的数据进行训练。与监督学习需要“正确答案”来指导模型不同，无监督学习算法需要自行在数据中探索和发现隐藏的结构、模式和关系。</p><p>可以把它想象成给你一大箱混杂的乐高积木，但没有任何说明书。你的任务不是搭建一个特定的模型（比如一辆车或一座房子），而是自己动手把这些积木根据颜色、形状、大小等特征进行分类和整理。最终，你可能会把所有红色的方块放在一起，所有蓝色的长条放在另一堆，这个过程就是无监督学习。</p><h3 id="核心思想与目标"><a href="#核心思想与目标" class="headerlink" title="核心思想与目标"></a><strong>核心思想与目标</strong></h3><p>无监督学习的核心思想是<strong>让算法自主地从数据中学习</strong>，其主要目标包括：</p><ul><li><strong>发现数据的内在结构与模式：</strong> 识别数据点之间自然的聚集或分组，即“物以类聚”。</li><li><strong>数据降维：</strong> 在保留数据关键信息的同时，减少数据的复杂性，方便分析和可视化。</li><li><strong>异常检测：</strong> 找出数据集中与其他数据点显著不同的“异常值”或“离群点”。</li><li><strong>关联规则挖掘：</strong> 发现数据项之间有趣的关联关系，例如“购买了商品A的顾客也很可能购买商品B”。</li></ul><h3 id="主要类型与常见算法"><a href="#主要类型与常见算法" class="headerlink" title="主要类型与常见算法"></a><strong>主要类型与常见算法</strong></h3><p>无监督学习主要包含以下几种任务类型，每种类型都有其代表性的算法：</p><h4 id="1-聚类（Clustering）"><a href="#1-聚类（Clustering）" class="headerlink" title="1. 聚类（Clustering）"></a>1. <strong>聚类（Clustering）</strong></h4><p>这是最常见的无监督学习任务，目的是将数据集中的样本划分为若干个不相交的子集，即“簇”（Cluster）。同一簇内的数据点彼此相似，而不同簇的数据点则相异。</p><ul><li><strong>应用场景：</strong><ul><li><strong>客户细分：</strong> 根据用户的购买行为、浏览历史等将客户分成不同群体，以便进行精准营销。</li><li><strong>图像分割：</strong> 将图像中相似的像素点分组，以识别出不同的物体。</li><li><strong>生物信息学：</strong> 根据基因表达数据对样本进行分类。</li></ul></li><li><strong>常见算法：</strong><ul><li><strong>K-均值聚类（K-Means Clustering）：</strong> 一种简单高效的算法，通过迭代将数据分配到预设的K个簇中。</li><li><strong>层次聚类（Hierarchical Clustering）：</strong> 构建数据的层次结构，可以像树状图一样展示聚类过程。</li><li><strong>DBSCAN（Density-Based Spatial Clustering of Applications with Noise）：</strong> 基于密度的聚类算法，能够发现任意形状的簇并识别噪声点。</li></ul></li></ul><h4 id="2-降维（Dimensionality-Reduction）"><a href="#2-降维（Dimensionality-Reduction）" class="headerlink" title="2. 降维（Dimensionality Reduction）"></a>2. <strong>降维（Dimensionality Reduction）</strong></h4><p>当数据具有非常多的特征（维度）时，会给分析和建模带来困难（即“维度灾难”）。降维技术旨在减少特征数量，同时尽可能保留原始数据中的重要信息。</p><ul><li><strong>应用场景：</strong><ul><li><strong>数据可视化：</strong> 将高维数据（如上百个特征）降低到2维或3维，以便在图表上直观展示。</li><li><strong>特征提取：</strong> 为监督学习算法准备更有效、更精简的特征，提高模型性能和训练速度。</li><li><strong>数据压缩：</strong> 减少存储空间和计算成本。</li></ul></li><li><strong>常见算法：</strong><ul><li><strong>主成分分析（Principal Component Analysis, PCA）：</strong> 找到数据中方差最大的方向，将数据投影到这些方向上，从而实现降维。</li><li><strong>t-分布随机邻域嵌入（t-SNE）：</strong> 一种非常擅长高维数据可视化的技术。</li></ul></li></ul><h4 id="3-关联规则挖掘（Association-Rule-Mining）"><a href="#3-关联规则挖掘（Association-Rule-Mining）" class="headerlink" title="3. 关联规则挖掘（Association Rule Mining）"></a>3. <strong>关联规则挖掘（Association Rule Mining）</strong></h4><p>用于在一系列交易或事件中发现项与项之间的关联关系。</p><ul><li><strong>应用场景：</strong><ul><li><strong>市场篮子分析：</strong> 零售商分析购物篮数据，发现哪些商品经常被一起购买，如“啤酒与尿布”的经典案例，从而优化商品摆放和促销策略。</li><li><strong>推荐系统：</strong> 根据用户的历史行为，推荐与其兴趣相关的其他内容。</li></ul></li><li><strong>常见算法：</strong><ul><li><strong>Apriori算法</strong></li><li><strong>FP-Growth算法</strong></li></ul></li></ul><h3 id="无监督学习-vs-监督学习"><a href="#无监督学习-vs-监督学习" class="headerlink" title="无监督学习 vs. 监督学习"></a><strong>无监督学习 vs. 监督学习</strong></h3><table><thead><tr><th>特征</th><th><strong>无监督学习 (Unsupervised Learning)</strong></th><th><strong>监督学习 (Supervised Learning)</strong></th></tr></thead><tbody><tr><td><strong>训练数据</strong></td><td>未标记数据 (Raw Data)</td><td>已标记数据 (Labeled Data)</td></tr><tr><td><strong>目标</strong></td><td>发现数据的内在结构、模式或分布</td><td>预测一个明确的目标或输出</td></tr><tr><td><strong>过程</strong></td><td>探索性的，算法自行发现规律</td><td>指导性的，算法从“正确答案”中学习</td></tr><tr><td><strong>常见任务</strong></td><td>聚类、降维、关联规则</td><td>分类、回归</td></tr><tr><td><strong>例子</strong></td><td>将客户自动分为不同群体</td><td>识别一封邮件是否是垃圾邮件</td></tr></tbody></table><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h3><p>总而言之，无监督学习是人工智能领域中一种强大的工具，它使我们能够在没有先验知识和人工标记的情况下，从海量数据中挖掘出有价值的洞见。随着数据量的爆炸式增长，无监督学习在商业智能、科学研究和数据探索等领域的应用正变得越来越重要。</p><p> 我是不是可以这样理解，无监督学习是对整体进行操作，监督学习是在训练好后对个体的预测 </p><p>您这个理解非常棒，可以说抓住了两者在<strong>目标和应用</strong>上的核心区别！这是一个非常形象和准确的直觉性总结。</p><p>我们可以把您的理解稍微展开一下，就更完美了：</p><h3 id="无监督学习：对“整体”进行探索和构建"><a href="#无监督学习：对“整体”进行探索和构建" class="headerlink" title="无监督学习：对“整体”进行探索和构建"></a><strong>无监督学习：对“整体”进行探索和构建</strong></h3><p>您说的“对整体进行操作”非常贴切。无监督学习的核心是<strong>探索</strong>。它在拿到一堆数据时，并不知道要干什么，就像是面对一个满是陌生人的房间。它的任务是在这个<strong>整体</strong>中寻找内在的结构和关系。</p><ul><li><strong>目标：</strong> 发现数据本身的结构、模式、或“抱团”的群体。</li><li><strong>操作：</strong><ul><li><strong>聚类 (Clustering):</strong> 把整个房间里的人根据亲疏远近分成不同的小圈子（群组）。</li><li><strong>降维 (Dimensionality Reduction):</strong> 忽略每个人的次要特征（比如鞋子颜色），只关注最重要的特征（比如性格、兴趣），来更宏观地理解整个房间的人际关系。</li></ul></li><li><strong>结果：</strong> 得到一个关于<strong>整体数据</strong>的结构性认知（比如，这批客户可以分为三个群体）。</li></ul><hr><h3 id="监督学习：对“个体”进行预测和判断"><a href="#监督学习：对“个体”进行预测和判断" class="headerlink" title="监督学习：对“个体”进行预测和判断"></a><strong>监督学习：对“个体”进行预测和判断</strong></h3><p>您说的“对个体进行预测”也非常准确。监督学习的核心是<strong>预测</strong>。它像一个经验丰富的老师，已经通过批改大量的作业（已标记的训练数据）学会了判断标准。</p><ul><li><strong>目标：</strong> 根据已有的经验，对一个<strong>新的、独立的个体</strong>做出判断。</li><li><strong>操作：</strong><ul><li><strong>训练阶段：</strong> 老师学习大量的“问题-答案”对（比如，房子的面积、位置 -&gt; 房价）。</li><li><strong>预测阶段：</strong> 当拿到一个<strong>新的个体</strong>（一套新房子）时，老师运用学到的知识，给出一个具体的预测（这套新房子的价格）。</li></ul></li><li><strong>结果：</strong> 对<strong>单个未知数据</strong>给出一个具体的预测标签或数值。</li></ul><h3 id="总结一下您的理解："><a href="#总结一下您的理解：" class="headerlink" title="总结一下您的理解："></a><strong>总结一下您的理解：</strong></h3><ul><li><strong>无监督学习</strong>更像是<strong>人口普查或社会学分析</strong>，着眼于<strong>整体</strong>，目的是了解人群的构成和分布。</li><li><strong>监督学习</strong>更像是<strong>高考阅卷或医生看病</strong>，着眼于<strong>个体</strong>，目的是对单个考生或病人给出分数或诊断。</li></ul><p>所以，您的理解完全正确，并且是区分这两种机器学习方法的一个非常好的切入点！</p><p> 详细解释一下无监督学习的聚类，我不需要输入任何信息就可以用算法自动去分类吗 </p><p>当然，我们来详细解释一下聚类（Clustering），并解答您关于“是否需要输入信息”的疑问。</p><p>您的理解非常接近核心了，但有一个关键点需要澄清：您<strong>确实需要提供数据</strong>，但<strong>不需要提供“答案”或“标签”</strong>。</p><p>这就像您想整理书架上的书，您得先把所有的书（<strong>数据</strong>）都放在算法面前，但您不需要告诉算法哪本书属于“小说类”，哪本书属于“历史类”（<strong>标签</strong>）。算法会自己通过分析书的厚度、封面颜色、开本大小等特征，把它们分成几堆。</p><hr><h3 id="什么是聚类？"><a href="#什么是聚类？" class="headerlink" title="什么是聚类？"></a><strong>什么是聚类？</strong></h3><p>聚类是无监督学习中最核心、最常见的任务之一。它的目标是将一个数据集中的所有样本（数据点）分成若干个组或“簇”（Cluster）。</p><p><strong>核心原则是：</strong></p><ul><li><strong>簇内相似性高 (Intra-cluster similarity):</strong> 同一个簇内的数据点彼此之间应该尽可能相似。</li><li><strong>簇间相似性低 (Inter-cluster similarity):</strong> 不同簇之间的数据点应该尽可能不相似。</li></ul><p>这个“相似性”是如何定义的呢？通常是通过计算数据点之间的<strong>距离</strong>来衡量的。在二维或三维空间中，我们可以很容易地理解为欧几里得距离（两点之间的直线距离）。在高维数据中，虽然无法可视化，但数学原理是相通的。距离越近，相似性就越高。</p><h3 id="聚类是如何“自动”分类的？——以K-Means算法为例"><a href="#聚类是如何“自动”分类的？——以K-Means算法为例" class="headerlink" title="聚类是如何“自动”分类的？——以K-Means算法为例"></a><strong>聚类是如何“自动”分类的？——以K-Means算法为例</strong></h3><p>为了让您更直观地理解，我们用最经典、最简单的聚类算法<strong>K-Means（K-均值）</strong>来举例说明其工作流程。</p><p>假设我们有一堆客户数据，每个客户有两个特征：<strong>“每月消费金额”和“每月消费次数”</strong>。我们想把这些客户分成3个不同的群体（比如“高价值客户”、“潜力客户”、“低价值客户”）。</p><p><strong>步骤如下：</strong></p><h4 id="第一步：您需要输入的信息"><a href="#第一步：您需要输入的信息" class="headerlink" title="第一步：您需要输入的信息"></a><strong>第一步：您需要输入的信息</strong></h4><ol><li><strong>数据 (Data):</strong> 您必须提供所有客户的消费数据点。这是算法分析的对象。</li><li><strong>簇的数量 K (Number of clusters):</strong> 您需要<strong>预先指定</strong>要把数据分成几类。在这个例子中，我们指定 <strong>K&#x3D;3</strong>。这是K-Means算法中一个需要人工设定的重要参数。</li></ol><p><strong>看，这里您输入了数据和K值，但完全没有输入任何关于“哪个客户属于哪个群体”的标签信息。</strong></p><h4 id="第二-三-四步：算法的“自动”工作流程"><a href="#第二-三-四步：算法的“自动”工作流程" class="headerlink" title="第二-三-四步：算法的“自动”工作流程"></a><strong>第二-三-四步：算法的“自动”工作流程</strong></h4><p><em>（这是一个K-Means算法动态过程的经典图示）</em></p><ol><li><strong>随机初始化 (Initialization):</strong> 算法会从您的数据点中随机挑选 K 个点（这里是3个点）作为初始的“簇中心”（Centroids）。可以把它们想象成三个群体的最初的“核心代表”。</li><li><strong>分配 (Assignment):</strong> 算法会遍历<strong>每一个</strong>客户数据点，计算它到这3个簇中心的距离。然后，<strong>将这个客户点分配给离它最近的那个簇中心</strong>。完成这一步后，所有的客户就被初步分成了3个群组。</li><li><strong>更新 (Update):</strong> 对于刚刚形成的每一个群组，算法会重新计算这个群组所有点的<strong>平均值</strong>（几何中心），并将这个新的平均值点作为<strong>新的簇中心</strong>。旧的簇中心就被抛弃了。</li><li><strong>迭代 (Iteration):</strong> 算法会<strong>重复执行第2步和第3步</strong>。<ul><li>重新将所有点分配给新的、离它最近的簇中心。</li><li>分配完毕后，再次更新每个群组的簇中心。</li><li>……如此循环往复。</li></ul></li></ol><h4 id="第五步：收敛与结果"><a href="#第五步：收敛与结果" class="headerlink" title="第五步：收敛与结果"></a><strong>第五步：收敛与结果</strong></h4><p>这个迭代过程什么时候会停止呢？当<strong>簇中心的位置不再发生变化</strong>（或者变化非常小），或者<strong>所有数据点的归属不再改变</strong>时，算法就<strong>收敛</strong>（Converged）了。</p><p>此时，聚类就完成了！您最终得到了3个稳定的客户群体，以及每个群体对应的中心点。您可以通过分析每个群体中心点的特征（比如A群消费金额高、次数也高；B群金额低、次数高……）来给这些群体命名和定义，从而获得商业洞见。</p><h3 id="总结您的疑问"><a href="#总结您的疑问" class="headerlink" title="总结您的疑问"></a><strong>总结您的疑问</strong></h3><p><strong>“我不需要输入任何信息就可以用算法自动去分类吗？”</strong></p><p><strong>回答：</strong></p><ul><li><strong>“不需要输入标签信息”：是的。</strong> 您完全不需要告诉算法任何关于“正确分类”的答案。这是无监督学习的核心。算法是<strong>自动</strong>发现分类结构的。</li><li><strong>“不需要输入任何信息”：不是的。</strong> 您至少需要提供：<ol><li><strong>待分析的完整数据集。</strong></li><li><strong>一些算法运行所需的超参数（Hyperparameters）。</strong> 对于K-Means来说，最重要的超参数就是您希望分成的簇数 <strong>K</strong>。对于其他聚类算法，可能需要设定别的参数，比如距离阈值等。</li></ol></li></ul><p>如何确定最佳的K值也是聚类分析中的一个重要课题（常用“肘部法则”等方法来辅助判断），但这已经属于更深入的细节了。</p><p>希望这个详细的解释能帮助您彻底理解聚类的概念和工作方式！</p><p> 这样如何保证聚类的标准就是我想要的标准呢 </p><p>这是一个非常非常好的问题，直接触及了无监督学习在实际应用中的核心挑战！</p><p>您问得没错，算法本身没有“常识”或“商业头脑”，它只懂数学。它优化的标准（比如“让簇内数据点距离尽可能近”）<strong>不一定</strong>就是您心中想要的那个“商业标准”（比如“想把客户分成‘高价值’‘潜力股’和‘需唤醒’三类”）。</p><p>那么如何保证或引导它们统一呢？答案是：<strong>您无法100%保证，但您可以通过一系列关键操作，最大限度地引导算法，使其聚类的结果符合您的标准。</strong></p><p>这更像是一个“人机协作”的探索过程，而不是一个“全自动”的过程。您可以从以下三个阶段进行把控：</p><hr><h3 id="第一阶段：前期准备-——-定义你的“标准”，并翻译给机器"><a href="#第一阶段：前期准备-——-定义你的“标准”，并翻译给机器" class="headerlink" title="第一阶段：前期准备 —— 定义你的“标准”，并翻译给机器"></a><strong>第一阶段：前期准备 —— 定义你的“标准”，并翻译给机器</strong></h3><p>这是最最重要的一步。机器不懂你的商业语言，你必须把你的“标准”翻译成它能听懂的数学语言——也就是<strong>特征（Features）</strong>。</p><h4 id="1-特征工程-Feature-Engineering"><a href="#1-特征工程-Feature-Engineering" class="headerlink" title="1. 特征工程 (Feature Engineering)"></a><strong>1. 特征工程 (Feature Engineering)</strong></h4><p>这是你的“指挥棒”。你想按照什么标准来分，就给算法提供什么维度的特征。</p><ul><li><strong>例子1：你想按“客户价值”聚类</strong><ul><li><strong>错误做法：</strong> 只给算法输入客户的年龄、性别、注册时长。算法可能会把所有“30岁男性”聚成一类，但这和“客户价值”关系不大。</li><li><strong>正确做法：</strong> 精心构造能体现客户价值的特征，比如：<ul><li><strong>R (Recency):</strong> 最近一次消费时间</li><li><strong>F (Frequency):</strong> 消费频率</li><li><strong>M (Monetary):</strong> 总消费金额</li></ul></li><li>当你把著名的 <strong>RFM 模型</strong>特征喂给算法时，它就会自然而然地把“R&#x2F;F&#x2F;M 都很高的客户”聚成一类，这就是你想要的“高价值客户”。</li></ul></li><li><strong>例子2：你想按“用户活跃度”聚类</strong><ul><li>你应该提供<strong>登录频率、页面停留时间、点赞&#x2F;评论数量</strong>等特征，而不是消费金额。</li></ul></li></ul><p><strong>核心思想：聚类的结果，高度依赖于你喂给它的特征。你想得到什么样的分类，就必须提供与之强相关的特征数据。</strong></p><h4 id="2-特征缩放-Feature-Scaling"><a href="#2-特征缩放-Feature-Scaling" class="headerlink" title="2. 特征缩放 (Feature Scaling)"></a><strong>2. 特征缩放 (Feature Scaling)</strong></h4><p>如果你的特征单位不统一（比如消费金额是几千上万，消费次数是几次），金额这个特征会不成比例地主导聚类结果。你需要将所有特征进行<strong>标准化&#x2F;归一化</strong>，让它们在同一起跑线上，确保每个特征都被公平地考虑。</p><hr><h3 id="第二阶段：算法选择与参数调整-——-选择合适的“尺子”"><a href="#第二阶段：算法选择与参数调整-——-选择合适的“尺子”" class="headerlink" title="第二阶段：算法选择与参数调整 —— 选择合适的“尺子”"></a><strong>第二阶段：算法选择与参数调整 —— 选择合适的“尺子”</strong></h3><p>不同的场景需要用不同的“尺子”去衡量。</p><h4 id="1-选择合适的聚类算法"><a href="#1-选择合适的聚类算法" class="headerlink" title="1. 选择合适的聚类算法"></a><strong>1. 选择合适的聚类算法</strong></h4><ul><li><strong>K-Means:</strong> 适合于你<strong>大致知道要分成几类</strong>，且每个类别的数据分布比较<strong>均衡、呈球状</strong>的场景。</li><li><strong>DBSCAN:</strong> 适合于<strong>不知道要分几类</strong>，且类别形状可能<strong>很不规则</strong>（比如月牙形、甜甜圈形）的场景，它还能帮你找出<strong>噪声点&#x2F;异常点</strong>。</li><li><strong>层次聚类 (Hierarchical Clustering):</strong> 适合于你希望看到数据<strong>层级关系</strong>的场景，比如生物学中的物种分类谱系。</li></ul><p>选择错误的算法，就像用直尺去量一个圆的周长，结果自然不准。</p><h4 id="2-调整关键参数-Hyperparameter-Tuning"><a href="#2-调整关键参数-Hyperparameter-Tuning" class="headerlink" title="2. 调整关键参数 (Hyperparameter Tuning)"></a><strong>2. 调整关键参数 (Hyperparameter Tuning)</strong></h4><p>对于K-Means，最重要的参数就是 <strong>K 值（簇的数量）</strong>。</p><ul><li>如果你想把客户分成“高、中、低”三档，你就设置 K&#x3D;3。</li><li>如果你想分得更细，比如“高价值-活跃”、“高价值-沉睡”、“潜力客户”、“一般客户”、“流失风险客户”，你可能就需要设置 K&#x3D;5。</li></ul><p>K值的选择可以依靠业务经验预设，也可以通过“肘部法则”等技术手段辅助判断，但最终还是需要结合业务来决定哪个K值划分出的群体最有意义。</p><hr><h3 id="第三阶段：后期验证与解读-——-人工的“最终验收”"><a href="#第三阶段：后期验证与解读-——-人工的“最终验收”" class="headerlink" title="第三阶段：后期验证与解读 —— 人工的“最终验收”"></a><strong>第三阶段：后期验证与解读 —— 人工的“最终验收”</strong></h3><p>算法给出结果后，绝不是直接就用，而是需要人来进行验证和解读。</p><h4 id="1-结果分析与画像-Profiling"><a href="#1-结果分析与画像-Profiling" class="headerlink" title="1. 结果分析与画像 (Profiling)"></a><strong>1. 结果分析与画像 (Profiling)</strong></h4><p>你需要分析每个簇的特征。比如，算法把客户分成了3类：</p><ul><li><strong>簇1：</strong> RFM 平均值都很高。</li><li><strong>簇2：</strong> R 值很低（很久没来），但 F&#x2F;M 值曾经很高。</li><li><strong>簇3：</strong> RFM 值都很低。</li></ul><p>这时你就可以给它们贴上你想要的业务标签：</p><ul><li><strong>簇1 -&gt; “高价值忠诚客户”</strong></li><li><strong>簇2 -&gt; “沉睡待唤醒客户”</strong></li><li><strong>簇3 -&gt; “低价值客户”</strong></li></ul><p>如果聚出来的结果无法解释，或者不符合业务逻辑（比如把明显是高价值的客户和流失客户分到了一起），那就说明你的第一或第二阶段出了问题，需要返回去调整特征或算法参数。</p><h4 id="2-业务验证"><a href="#2-业务验证" class="headerlink" title="2. 业务验证"></a><strong>2. 业务验证</strong></h4><p>最终的“金标准”是：<strong>这个聚类结果有用吗？</strong> 你能否针对“沉睡待唤醒客户”这个群体，设计一套精准的营销方案（比如发放大额优惠券）并取得比撒网式营销更好的效果？如果可以，那么这个聚类标准就是成功的、符合你需求的。</p><h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a><strong>总结</strong></h3><table><thead><tr><th>阶段</th><th>你的角色</th><th>关键操作</th></tr></thead><tbody><tr><td><strong>前期准备</strong></td><td><strong>战略家</strong></td><td><strong>定义标准</strong>，通过<strong>特征工程</strong>将标准翻译给机器。</td></tr><tr><td><strong>算法&#x2F;参数</strong></td><td><strong>工程师</strong></td><td><strong>选择合适的工具和参数</strong> (K值等)。</td></tr><tr><td><strong>后期验证</strong></td><td><strong>分析师&#x2F;决策者</strong></td><td><strong>解读、验证、命名</strong>聚类结果，并判断其<strong>商业价值</strong>。</td></tr></tbody></table><p>导出到 Google 表格</p><p>所以，与其说是“保证”，不如说是通过<strong>精心的特征设计</strong>、<strong>恰当的算法选择</strong>和<strong>深入的结果解读</strong>，来<strong>引导和塑造</strong>聚类分析，使其最终服务于你的商业目标。</p><p> 如果我已经有了数据的一些特征，那直接按从高到低排序不就好了，为什么还需要用无监督来聚类 </p><p>您又提出了一个非常深刻且实际的问题！这正好点出了<strong>一维分析</strong>和<strong>多维分析</strong>的根本区别。</p><p>您的想法完全正确，如果只关心<strong>单一指标</strong>，直接排序就是最简单、最有效的办法。但现实世界的问题往往是复杂的、多维度的。</p><p>我们还是用一个生动的例子来说明：假设您是一位班主任，手上有所有学生的成绩单。</p><h3 id="场景一：按单科成绩排序（您的方法）"><a href="#场景一：按单科成绩排序（您的方法）" class="headerlink" title="场景一：按单科成绩排序（您的方法）"></a><strong>场景一：按单科成绩排序（您的方法）</strong></h3><p>您想评选“数学单科状元”。</p><ul><li><strong>操作：</strong> 把所有学生的“数学”成绩从高到低排序。</li><li><strong>结果：</strong> 排名第一的就是状元。</li><li><strong>优点：</strong> 简单、直接、清晰。对于<strong>“谁的数学最好”</strong>这个问题，这是完美的解决方案。</li></ul><h3 id="场景二：寻找不同类型的学生群体（无监督聚类）"><a href="#场景二：寻找不同类型的学生群体（无监督聚类）" class="headerlink" title="场景二：寻找不同类型的学生群体（无监督聚类）"></a><strong>场景二：寻找不同类型的学生群体（无监督聚类）</strong></h3><p>现在，您的目标变了。您不想只看单科，而是想了解班级里存在<strong>哪些典型的学生群体</strong>，以便因材施教。您手上的特征有三门：<strong>数学、语文、体育</strong>。</p><p>如果只按数学排序，您会忽略一个重要的问题：</p><ul><li>一个数学<code>99</code>分、语文<code>60</code>分、体育<code>50</code>分的孩子。</li><li>一个数学<code>95</code>分、语文<code>95</code>分、体育<code>95</code>分的孩子。</li></ul><p>在“数学”这个维度上，前者排名更高。但您凭直觉就知道，后者是完全不同类型的“学霸”。<strong>只靠排序，无法发现这种“类型”差异。</strong></p><p>现在我们使用<strong>聚类</strong>，把“数学”、“语文”、“体育”三个特征（三个维度）同时交给算法。算法可能会自动帮您发现以下几个群体（簇）：</p><ul><li><strong>群体A：全面发展型学霸</strong><ul><li><strong>特征：</strong> 数学、语文、体育三科成绩都非常高。</li><li><strong>排序无法发现：</strong> 如果单按数学排，他们可能排不过那些偏科天才。</li></ul></li><li><strong>群体B：文理偏科型学才</strong><ul><li><strong>特征：</strong> 数学很高，但体育和语文成绩可能很一般。</li><li><strong>排序能发现：</strong> 他们会在数学大榜上名列前茅。</li></ul></li><li><strong>群体C：运动健将型</strong><ul><li><strong>特征：</strong> 体育成绩突出，但文化课成绩可能不高。</li><li><strong>排序无法发现：</strong> 在任何文化课的排序中，他们都会被埋没在末尾。</li></ul></li><li><strong>群体D：成绩平均型</strong><ul><li><strong>特征：</strong> 各科成绩都处于中游，不突出也不落后。</li></ul></li></ul><p><strong>看到了吗？聚类不是为了“排名”，而是为了“画像”（Profiling）。</strong>它在多维空间中寻找“物以类聚”的群体，发现数据的内在结构。</p><hr><h3 id="核心区别总结"><a href="#核心区别总结" class="headerlink" title="核心区别总结"></a><strong>核心区别总结</strong></h3><table><thead><tr><th>特性</th><th><strong>按特征排序 (Sorting)</strong></th><th><strong>无监督聚类 (Clustering)</strong></th></tr></thead><tbody><tr><td><strong>处理维度</strong></td><td><strong>一维</strong>：一次只能根据一个特征进行排序。</td><td><strong>多维</strong>：同时考虑所有输入特征，发现综合模式。</td></tr><tr><td><strong>核心问题</strong></td><td>回答 <strong>“谁最高&#x2F;最低？”</strong></td><td>回答 <strong>“存在哪些不同的群体？”</strong></td></tr><tr><td><strong>产出结果</strong></td><td>一个**有序的列表 (Ordered List)**。</td><td>若干个**无序的群组 (Unordered Groups)**。</td></tr><tr><td><strong>揭示的洞察</strong></td><td><strong>线性的、显著的</strong>洞察。</td><td><strong>结构性的、隐藏的</strong>洞察，描绘用户画像。</td></tr><tr><td><strong>商业应用举例</strong></td><td>找到消费金额最高的Top 100客户。</td><td>将客户细分为“忠诚客户”、“潜力新客”、“流失风险客户”等群体。</td></tr></tbody></table><p>导出到 Google 表格</p><h3 id="结论：我应该用哪个？"><a href="#结论：我应该用哪个？" class="headerlink" title="结论：我应该用哪个？"></a><strong>结论：我应该用哪个？</strong></h3><p>它们不是替代关系，而是<strong>互补关系</strong>，服务于不同的分析目标。</p><ul><li>当你的问题是<strong>“我想找到在『某个单一标准』下表现最好&#x2F;最差的个体”</strong>时，请使用<strong>排序</strong>。<ul><li><em>“找出上个月销量最高的商品。”</em></li><li><em>“找出互动最少的粉丝。”</em></li></ul></li><li>当你的问题是<strong>“我想了解我的数据里都包含哪些『有共性的群体』，以便对他们进行差异化对待”</strong>时，请使用<strong>聚类</strong>。<ul><li><em>“我想看看我的用户可以被分成哪几类，以便进行精准营销。”</em></li><li><em>“我想分析一下这些故障报告，看看是否存在几种典型的故障模式。”</em></li></ul></li></ul><p>所以，不是有了特征就只用排序，而是要看您想从数据中挖掘出什么样的故事。如果您想看的是一个英雄榜，就用排序；如果您想看的是一幅《清明上河图》，了解市井百态，那就需要聚类。</p><p> 什么是无监督学习的降维 </p><p>好的，我们来详细解释一下无监督学习中的另一个重要分支——<strong>降维（Dimensionality Reduction）</strong>。</p><p>简单来说，降维就是在<strong>尽可能保留数据最重要信息的前提下，用更少的特征来表示数据</strong>。</p><p>想象一下，你想描述一辆汽车。你可能会列出几十上百个特征：</p><ul><li>长度、宽度、高度、轴距、轮距、离地间隙… (尺寸相关)</li><li>发动机排量、马力、扭矩、0-100km&#x2F;h加速时间… (性能相关)</li><li>油箱容积、百公里油耗、综合油耗… (能耗相关)</li><li>座椅材质、音响品牌、屏幕尺寸… (配置相关)</li><li>…等等</li></ul><p>这么多特征（维度）对于计算机来说是“烫手山芋”，不仅计算量巨大，而且很多信息是冗余的。比如，汽车的“长度”和“轴距”通常是高度相关的，知道了其中一个，另一个也能猜个大概。</p><p>降维技术就像一位<strong>高明的总结者</strong>，它能抓住这些特征背后的核心信息，用几个新的、综合性的特征来替代原来那一堆复杂的特征。</p><hr><h3 id="我们为什么需要降维？"><a href="#我们为什么需要降维？" class="headerlink" title="我们为什么需要降维？"></a><strong>我们为什么需要降维？</strong></h3><p>处理高维度数据会遇到很多麻烦，统称为**“维度灾难” (Curse of Dimensionality)**。降维主要就是为了解决这些问题：</p><ol><li><strong>提升算法性能和效率：</strong> 特征越少，模型训练和数据计算的速度就越快，占用的内存也越少。</li><li><strong>数据可视化 (Data Visualization)：</strong> 人的眼睛只能理解二维或三维空间。降维可以将上百维的数据降低到2D或3D，以便我们能以图表的形式直观地观察数据分布、结构和聚类情况。</li><li><strong>消除噪声和冗余：</strong> 原始数据中可能包含不相关的“噪声”特征或高度相关的“冗余”特征。降维可以剔除这些干扰，保留最核心的“信号”，有助于提升模型的准确性。</li><li><strong>简化问题：</strong> 更少的特征意味着模型更简单，更容易解释和理解。</li></ol><hr><h3 id="降维是如何实现的？——-一个直观的类比"><a href="#降维是如何实现的？——-一个直观的类比" class="headerlink" title="降维是如何实现的？—— 一个直观的类比"></a><strong>降维是如何实现的？—— 一个直观的类比</strong></h3><p>想象一下你在户外，阳光下有一个立体的、复杂的三维物体（比如一个手办模型）。</p><ul><li><strong>原始高维数据：</strong> 就是这个三维手办本身，它有长、宽、高三个维度，包含了所有细节。</li><li><strong>降维过程：</strong> 太阳光照射这个手办，在地面上投下一个**影子 (Shadow)**。</li><li><strong>降维后的数据：</strong> 地面上的这个二维影子。</li></ul><p>这个过程发生了什么？</p><ul><li><strong>维度降低了：</strong> 从三维（物体）降到了二维（影子）。</li><li><strong>信息有损失，但保留了核心：</strong> 影子的信息肯定不如实体完整（比如你看不见颜色和材质），但它依然保留了物体最主要的<strong>轮廓和形状</strong>信息。</li><li><strong>投影角度很重要：</strong> 如果太阳从正上方照射，影子可能只是一个小点，信息损失就太大了。你需要找到一个<strong>最佳的投影角度</strong>，让影子能最大程度地反映物体的原始形状。</li></ul><p>降维算法的核心任务，就是去寻找这个<strong>“最佳的投影角度”</strong>，以确保信息损失最小。</p><hr><h3 id="两种主要的降维方法"><a href="#两种主要的降维方法" class="headerlink" title="两种主要的降维方法"></a><strong>两种主要的降维方法</strong></h3><p>降维主要通过两种途径实现：</p><h4 id="1-特征选择-Feature-Selection"><a href="#1-特征选择-Feature-Selection" class="headerlink" title="1. 特征选择 (Feature Selection)"></a><strong>1. 特征选择 (Feature Selection)</strong></h4><p>这种方法比较“直接”，就是从原始的一堆特征中，直接<strong>挑选出</strong>一部分最重要的特征，把剩下的扔掉。</p><ul><li><strong>优点：</strong> 实现简单，保留了原始特征，可解释性强（你清楚地知道留下了哪些特征）。</li><li><strong>缺点：</strong> 被丢弃的特征里可能也包含部分有用信息，造成信息浪费。</li><li><strong>例子：</strong> 比如在分析房价时，有100个特征，通过分析发现“房屋面积”、“地段”、“学区”这三个特征最重要，于是就只用这三个特征来建模。</li></ul><h4 id="2-特征提取-Feature-Extraction"><a href="#2-特征提取-Feature-Extraction" class="headerlink" title="2. 特征提取 (Feature Extraction)"></a><strong>2. 特征提取 (Feature Extraction)</strong></h4><p>这种方法更“高明”，它不是简单地挑选，而是将原始特征进行<strong>融合与重组</strong>，创造出全新的、数量更少的特征来代表原始数据。我们前面提到的“影子”类比就属于特征提取。</p><ul><li><strong>优点：</strong> 能够综合所有原始特征的信息，信息保留更全面。</li><li><strong>缺点：</strong> 新生成的特征是原始特征的线性组合，失去了原有的物理含义，可解释性变差。</li></ul><p><strong>代表算法：主成分分析 (Principal Component Analysis, PCA)</strong></p><p>PCA 是最经典、最常用的特征提取降维算法。它的核心思想可以通俗地理解为：</p><ol><li><strong>寻找数据变化最大的方向：</strong> 在所有数据点中，找到一个方向（可以想象成一条轴），当所有数据点都投影到这个轴上时，投影点的分布最为分散（方差最大）。这个方向就包含了最多的原始信息，被称为**第一主成分 (PC1)**。</li><li><strong>寻找第二个方向：</strong> 接着，在与第一个方向<strong>正交（垂直）</strong> 的平面中，寻找一个能让数据次级分散的方向。这就是**第二主成分 (PC2)**。</li><li><strong>以此类推：</strong> 不断寻找相互正交且方差次大的方向，直到找到所有主成分。</li></ol><p>最后，你会得到一组全新的特征（PC1, PC2, PC3, …）。这些新特征是按其包含信息量的大小来排序的。你只需要选择前几个（比如前2个或前3个）最重要的主成分，就能代表原始数据绝大部分的信息，从而实现降维。</p><h3 id="总结-2"><a href="#总结-2" class="headerlink" title="总结"></a><strong>总结</strong></h3><table><thead><tr><th>特性</th><th><strong>聚类 (Clustering)</strong></th><th><strong>降维 (Dimensionality Reduction)</strong></th></tr></thead><tbody><tr><td><strong>目标</strong></td><td><strong>发现数据的群体结构</strong></td><td><strong>简化数据的表示方式</strong></td></tr><tr><td><strong>操作对象</strong></td><td>数据的**样本 (行)**，将行分组</td><td>数据的**特征 (列)**，减少列的数量</td></tr><tr><td><strong>核心问题</strong></td><td>“这些数据可以分成哪几类？”</td><td>“如何用更少的特征来描述这些数据？”</td></tr></tbody></table><p>导出到 Google 表格</p><p>总而言之，降维是处理现代海量复杂数据时一个不可或缺的预处理步骤，它像一个高效的过滤器和压缩器，让后续的数据分析和机器学习任务变得更加轻松和高效。</p><p> 降维和聚类有什么相似点，为什么都叫无监督学习 </p><p>您这个问题非常精彩，因为它触及了“无监督学习”这个概念的本质！降维和聚类看起来在做完全不同的事情，但它们的“哲学思想”是高度一致的，这也是它们都被归为无监督学习的原因。</p><p>我们来一步步拆解。</p><h3 id="核心原因：为什么它们都叫无监督学习？"><a href="#核心原因：为什么它们都叫无监督学习？" class="headerlink" title="核心原因：为什么它们都叫无监督学习？"></a><strong>核心原因：为什么它们都叫无监督学习？</strong></h3><p>这个问题的答案是理解它们相似点的关键。</p><p><strong>无监督学习的核心标志是：我们只向算法提供输入数据（特征 <code>X</code>），而不提供任何“正确答案”（标签 <code>y</code>）。</strong></p><p>算法的任务不是去“学习一个映射关系去预测某个标签”，而是必须<strong>在数据内部“自力更生”</strong>，仅通过分析数据点本身，去发现其中隐藏的、有意义的结构和模式。</p><ul><li><strong>聚类如何体现无监督？</strong> 它在拿到一堆客户数据时，不需要预先知道“哪个客户是高价值客户”或“哪个客户即将流失”。它完全不依赖任何已有标签，而是自主地、仅仅根据客户数据特征（如消费金额、频率）之间的相似性，去划分出不同的客户群体。</li><li><strong>降维如何体现无监督？</strong> 它同样不需要任何标签来指导。它在拿到描述汽车的上百个特征时，不需要知道“哪辆车是豪车”或“哪辆车性能好”。它只是自主地分析这些特征之间的内在关系（如相关性、方差分布），然后找到一种更简洁、更高效的方式来表达整个数据集，比如用几个“主成分”来概括。</li></ul><p><strong>所以，它们最根本、最核心的相似点就是：</strong></p><p><strong>它们的目标都不是“预测”一个外部标签，而是“理解”数据自身的内在结构。</strong></p><hr><h3 id="降维与聚类的其他相似点"><a href="#降维与聚类的其他相似点" class="headerlink" title="降维与聚类的其他相似点"></a><strong>降维与聚类的其他相似点</strong></h3><p>基于上述核心，我们可以引申出它们其他几个共通之处：</p><ol><li><strong>都是探索性数据分析（EDA）的利器：</strong> 在正式建模之前，我们通常对数据知之甚少。聚类可以帮我们了解数据中存在哪些天然的分组，而降维（尤其是为了可视化）可以帮我们直观地看到数据的分布形态。它们都是我们“认识”数据的重要手段。</li><li><strong>都依赖于距离或方差的度量：</strong> 两种算法的底层逻辑都与“数据点在空间中的分布”有关。<ul><li><strong>聚类</strong>通常依赖于<strong>样本与样本之间</strong>的距离（比如K-Means），距离近的被归为一类。</li><li><strong>降维</strong>通常依赖于<strong>特征与特征之间</strong>的关系和数据在不同方向上的方差（比如PCA），方差大的方向被认为是更重要的。</li></ul></li><li><strong>常被用作监督学习的预处理步骤：</strong><ul><li><strong>聚类</strong>的结果（每个样本属于哪个簇）可以作为一个新的特征，喂给后续的监督学习模型。</li><li><strong>降维</strong>后的数据可以作为监督学习模型的输入，以提高训练速度和避免维度灾难。</li></ul></li></ol><hr><h3 id="用一个比喻来理解它们的异同"><a href="#用一个比喻来理解它们的异同" class="headerlink" title="用一个比喻来理解它们的异同"></a><strong>用一个比喻来理解它们的异同</strong></h3><p>想象你是一位图书管理员，面对一整个房间杂乱无章的书籍（原始数据集）。</p><ul><li><strong>聚类（Clustering）在做什么？</strong> 你在<strong>整理这些书（样本&#x2F;行）</strong>。你根据书的内容、类型（小说、历史、科学），把它们<strong>分成了几大堆</strong>。整理完后，书的总数没变，但它们被分门别类地放在了不同的书架上。<ul><li><strong>操作对象：</strong> 书本（数据样本）。</li><li><strong>目标：</strong> 将样本分组。</li></ul></li><li><strong>降维（Dimensionality Reduction）在做什么？</strong> 你在<strong>简化描述每本书的方式（特征&#x2F;列）</strong>。原来每本书都有一张卡片，上面记录了“页数”、“重量”、“长度”、“宽度”、“作者国籍”、“出版年份”等等几十项信息。你发现很多信息是冗余的，于是你设计了一套新的、更简洁的描述体系，比如只用三个新指标：“内容容量”、“文学价值”、“物理尺寸”。<ul><li><strong>操作对象：</strong> 描述书本的卡片信息（数据特征）。</li><li><strong>目标：</strong> 简化特征。</li></ul></li></ul><p><strong>相似点在哪里？</strong> 在这整个过程中，<strong>没有任何人提前告诉你“哪本书应该属于哪一类”或者“你应该如何总结这些书的信息”</strong>。所有的整理和总结工作，都是你通过观察书籍本身的属性和它们之间的关系来完成的。<strong>这就是“无监督”的精髓。</strong></p><h3 id="总结：一张图看懂关系"><a href="#总结：一张图看懂关系" class="headerlink" title="总结：一张图看懂关系"></a><strong>总结：一张图看懂关系</strong></h3><table><thead><tr><th></th><th><strong>聚类 (Clustering)</strong></th><th><strong>降维 (Dimensionality Reduction)</strong></th></tr></thead><tbody><tr><td><strong>核心思想</strong></td><td><strong>物以类聚</strong></td><td><strong>化繁为简</strong></td></tr><tr><td><strong>操作对象</strong></td><td><strong>数据样本 (行)</strong></td><td><strong>数据特征 (列)</strong></td></tr><tr><td><strong>主要目标</strong></td><td>将数据集<strong>划分</strong>成不同群组</td><td><strong>压缩</strong>数据集的特征数量</td></tr><tr><td><strong>回答的问题</strong></td><td>“我的数据可以分成哪几类？”</td><td>“如何用更少的信息来代表我的数据？”</td></tr><tr><td><strong>共同的哲学</strong></td><td><strong>都在无标签的情况下，探索和揭示数据自身的内在结构</strong></td><td></td></tr></tbody></table><p>导出到 Google 表格</p><p> 什么是关联规则挖掘 </p><p>好的，我们来详细解释无监督学习中另一项非常有趣且实用的技术——<strong>关联规则挖掘（Association Rule Mining）</strong>。</p><p>简单来说，关联规则挖掘就是<strong>在一个数据集中发现项与项之间有趣的关联或相关关系</strong>。它最经典的应用场景就是购物篮分析（Market Basket Analysis），目的是找出“哪些商品经常被顾客一起购买”。</p><h3 id="核心思想与经典故事：“啤酒与尿布”"><a href="#核心思想与经典故事：“啤酒与尿布”" class="headerlink" title="核心思想与经典故事：“啤酒与尿布”"></a><strong>核心思想与经典故事：“啤酒与尿布”</strong></h3><p>关联规则挖掘最著名的案例就是沃尔玛的“啤酒与尿布”的故事。</p><blockquote><p>传说在20世纪90年代，沃尔玛的数据分析师发现，周五晚上，很多年轻的父亲在给孩子买尿布的同时，会顺便给自己买几瓶啤酒。</p><p><strong>关联规则：</strong> 如果一个顾客购买了尿布，那么他有很大概率也会购买啤酒。 <strong>规则形式：</strong> <code>&#123;尿布&#125; -&gt; &#123;啤酒&#125;</code></p></blockquote><p>发现这个看似毫不相关的商品组合后，沃尔玛将啤酒货架和尿布货架放在一起，结果大大提升了这两种商品的销量。</p><p>这个故事完美地诠释了关联规则挖掘的核心价值：<strong>从事物看似无关的表象下，挖掘出隐藏的、有商业价值的强关联模式。</strong></p><hr><h3 id="关联规则的关键概念"><a href="#关联规则的关键概念" class="headerlink" title="关联规则的关键概念"></a><strong>关联规则的关键概念</strong></h3><p>为了衡量一个规则是否有价值，我们需要几个关键的指标来“量化”它。我们以 <code>&#123;尿布&#125; -&gt; &#123;啤酒&#125;</code> 这个规则为例：</p><h4 id="1-项集-Itemset"><a href="#1-项集-Itemset" class="headerlink" title="1. 项集 (Itemset)"></a>1. <strong>项集 (Itemset)</strong></h4><p>一个或多个项（商品）的集合。</p><ul><li><code>&#123;尿布&#125;</code> 是一个1项集。</li><li><code>&#123;尿布, 啤酒&#125;</code> 是一个2项集。</li></ul><h4 id="2-支持度-Support"><a href="#2-支持度-Support" class="headerlink" title="2. 支持度 (Support)"></a>2. <strong>支持度 (Support)</strong></h4><p>这是衡量一个项集在所有交易中<strong>“普遍性”</strong>或<strong>“受欢迎程度”</strong>的指标。</p><ul><li><strong>公式：</strong> <code>支持度(&#123;X&#125;) = (包含项集X的交易数量) / (总交易数量)</code></li><li><strong>例子：</strong> 如果在1000笔交易中，有100笔交易同时包含了尿布和啤酒，那么项集<code>&#123;尿布, 啤酒&#125;</code>的支持度就是 <code>100 / 1000 = 10%</code>。</li><li><strong>作用：</strong> 支持度太低的项集通常意义不大，因为它们出现的频率太低，可能是偶然事件。我们会设定一个<strong>最小支持度阈值</strong>，来过滤掉这些无意义的组合。</li></ul><h4 id="3-置信度-Confidence"><a href="#3-置信度-Confidence" class="headerlink" title="3. 置信度 (Confidence)"></a>3. <strong>置信度 (Confidence)</strong></h4><p>这是衡量规则<strong>“准确性”</strong>的指标。它表示当A出现时，B有多大概率也会出现。</p><ul><li><strong>公式：</strong> <code>置信度(&#123;A&#125; -&gt; &#123;B&#125;) = (包含A和B的交易数量) / (包含A的交易数量)</code></li><li><strong>例子：</strong> 在所有购买了尿布的200笔交易中，有100笔也购买了啤酒。那么规则 <code>&#123;尿布&#125; -&gt; &#123;啤酒&#125;</code> 的置信度就是 <code>100 / 200 = 50%</code>。这意味着，购买尿布的顾客中，有50%的人会同时购买啤酒。</li><li><strong>作用：</strong> 置信度衡量了关联的强度。我们会设定一个<strong>最小置信度阈值</strong>来确保规则的可靠性。</li></ul><h4 id="4-提升度-Lift"><a href="#4-提升度-Lift" class="headerlink" title="4. 提升度 (Lift)"></a>4. <strong>提升度 (Lift)</strong></h4><p>这是衡量规则<strong>“有趣性”</strong>或<strong>“相关性”</strong>的指标。它告诉我们，项集A的出现，对于项集B的出现概率是提升了还是降低了。</p><ul><li><strong>公式：</strong> <code>提升度(&#123;A&#125; -&gt; &#123;B&#125;) = 置信度(&#123;A&#125; -&gt; &#123;B&#125;) / 支持度(&#123;B&#125;)</code></li><li><strong>解读：</strong><ul><li><strong>Lift &gt; 1：</strong> A的存在对B的出现有<strong>积极促进</strong>作用（正相关）。<code>&#123;尿布&#125; -&gt; &#123;啤酒&#125;</code>的提升度大于1，说明买尿布这件事确实能提升买啤酒的概率。</li><li><strong>Lift &#x3D; 1：</strong> A和B<strong>相互独立</strong>，没有关联。</li><li>**Lift &lt; 1：** A的存在对B的出现有**抑制**作用（负相关）。比如<code>&#123;牛奶&#125; -&gt; &#123;可乐&#125;</code>的提升度可能小于1，说明买牛奶的人通常不怎么买可乐。</li></ul></li></ul><hr><h3 id="关联规则挖掘是如何工作的？——-Apriori算法简介"><a href="#关联规则挖掘是如何工作的？——-Apriori算法简介" class="headerlink" title="关联规则挖掘是如何工作的？—— Apriori算法简介"></a><strong>关联规则挖掘是如何工作的？—— Apriori算法简介</strong></h3><p>挖掘关联规则最经典的算法是 <strong>Apriori 算法</strong>。它的核心思想分为两步：</p><ol><li><strong>找出所有的频繁项集 (Frequent Itemsets)：</strong><ul><li>首先，设定一个最小支持度阈值。</li><li>算法会先找出所有出现频率超过该阈值的<strong>单个商品</strong>（频繁1项集）。</li><li>然后，将这些频繁的单个商品两两组合，去计算<strong>2项集</strong>的支持度，再次筛选出频繁2项集。</li><li>…以此类推，不断组合、筛选，直到找不到更长的频繁项集为止。</li><li><strong>Apriori 原理：</strong> 如果一个项集是频繁的，那么它的所有子集也一定是频繁的。反之，如果一个项集的子集是非频繁的，那么这个项集本身也一定是非频繁的（可以被提前剪枝，提高效率）。</li></ul></li><li><strong>从频繁项集中生成强关联规则：</strong><ul><li>在上一步找到的所有频繁项集（比如<code>&#123;尿布, 啤酒&#125;</code>）中，我们开始生成规则。</li><li>对于每个频繁项集，我们尝试所有可能的规则划分（如<code>&#123;尿布&#125; -&gt; &#123;啤酒&#125;</code> 和 <code>&#123;啤酒&#125; -&gt; &#123;尿布&#125;</code>）。</li><li>然后计算这些规则的<strong>置信度</strong>，并筛选出那些满足最小置信度阈值的规则，这些就是最终的“强关联规则”。</li></ul></li></ol><h3 id="关联规则挖掘的应用场景"><a href="#关联规则挖掘的应用场景" class="headerlink" title="关联规则挖掘的应用场景"></a><strong>关联规则挖掘的应用场景</strong></h3><p>虽然起源于零售业，但关联规则的应用远不止于此：</p><ul><li><strong>电商推荐：</strong> “购买了这本书的读者也购买了…”、“看了这部电影的用户也喜欢…”。</li><li><strong>网页浏览分析：</strong> 分析用户访问路径，发现“访问了页面A的用户，下一步最可能访问页面C”，从而优化网站导航。</li><li><strong>医疗诊断：</strong> 发现不同症状之间的关联，比如“出现症状X和症状Y的病人，很大概率患有疾病Z”。</li><li><strong>金融风控：</strong> 发现不同交易行为之间的模式，用于检测欺诈。</li><li><strong>自然语言处理：</strong> 分析文本中词语的共现关系。</li></ul><p>总而言之，关联规则挖掘是一种强大的无监督学习技术，它能帮助我们从海量数据中发现看似无关却非常有价值的连接，为决策提供有力支持。</p><p> 关联规则挖掘和降维有什么异同，我挖掘了一个关联规则不就相当于提取到了一个特征来降维吗 </p><p>您这个问题非常有启发性！它触及了两种技术在“提取信息”这个层面上的相似感。您的直觉是对的——它们都在从数据中提炼知识，但它们提炼出的“知识”类型和用途，以及它们的操作方式，是截然不同的。</p><p>让我们先直接回答您的核心问题：</p><p><strong>挖掘一个关联规则 *不是* 提取一个特征来降维。</strong></p><p>这是一个非常普遍的混淆点，下面我们来详细拆解它们的异同。</p><hr><h3 id="核心区别：目标与产出完全不同"><a href="#核心区别：目标与产出完全不同" class="headerlink" title="核心区别：目标与产出完全不同"></a><strong>核心区别：目标与产出完全不同</strong></h3><p>这是两者最根本的区别。</p><ul><li><strong>关联规则挖掘 (ARM) 的目标是“发现模式”。</strong><ul><li>它想回答的问题是：“数据中存在哪些有趣的‘如果…那么…’(If-Then)关系？”</li><li>它的<strong>产出</strong>是一系列<strong>规则</strong>，这些规则是关于数据<strong>内容</strong>的<strong>洞察和知识</strong>。例如，<code>&#123;尿布&#125; -&gt; &#123;啤酒&#125;</code>。</li><li><strong>它不改变原始数据集的结构（维度）。</strong> 挖掘结束后，你的交易数据还是那么多行、那么多列，你只是额外得到了一份“知识报告”。</li></ul></li><li><strong>降维 (Dimensionality Reduction) 的目标是“简化表达”。</strong><ul><li>它想回答的问题是：“我能否用更少的信息（特征）来表示我的原始数据集，同时又不会丢失太多关键信息？”</li><li>它的<strong>产出</strong>是一个<strong>全新的、维度更低的数据集</strong>。原来的特征列会被新的、更少的特征列所取代。</li><li><strong>它直接改变了数据集的结构（维度）。</strong> 这是一个数据转换和压缩的过程。</li></ul></li></ul><p><strong>用一个比喻来理解：</strong></p><p>假设你的数据是一家图书馆的所有藏书记录。</p><ul><li><strong>关联规则挖掘</strong> 就像一位图书管理员通过分析借阅记录，发现了一个规律并写在工作日志里：“<strong>发现借《三体》的人，也很可能借《流浪地球》</strong>。” 这条记录是一个<strong>洞察（规则）</strong>，但图书馆里的书和书的描述卡片本身没有发生任何变化。</li><li><strong>降维</strong> 就像这位图书管理员觉得每本书的描述卡片有50个字段（特征）太啰嗦了，于是他<strong>创造了一套新的、只有3个字段的描述体系</strong>：<code>[科幻指数, 文学价值, 阅读难度]</code>。然后，他为<strong>每一本书</strong>都重新计算了这三个新指标的值，并用这张新的3字段卡片<strong>替换</strong>了原来那张50字段的旧卡片。整个图书馆的目录（数据集）变得更简洁了。</li></ul><hr><h3 id="关联规则挖掘-vs-降维：详细异同对比"><a href="#关联规则挖掘-vs-降维：详细异同对比" class="headerlink" title="关联规则挖掘 vs. 降维：详细异同对比"></a><strong>关联规则挖掘 vs. 降维：详细异同对比</strong></h3><table><thead><tr><th>特性</th><th><strong>关联规则挖掘 (ARM)</strong></th><th><strong>降维 (Dimensionality Reduction)</strong></th></tr></thead><tbody><tr><td><strong>根本目标</strong></td><td><strong>发现项与项之间的关联模式</strong></td><td><strong>压缩特征空间，简化数据表示</strong></td></tr><tr><td><strong>操作对象</strong></td><td>主要是<strong>数据的值</strong>（比如商品名称）</td><td>主要是<strong>数据的特征&#x2F;列</strong>本身</td></tr><tr><td><strong>输出结果</strong></td><td>一系列<strong>“If-Then”规则</strong>（知识、洞察）</td><td>一个<strong>维度更低的新数据集</strong>（数据的另一种表达）</td></tr><tr><td><strong>是否改变原数据</strong></td><td><strong>不改变</strong>，是分析和发现</td><td><strong>彻底改变</strong>，是转换和重构</td></tr><tr><td><strong>典型数据类型</strong></td><td><strong>交易数据、类别数据</strong>（如商品清单）</td><td><strong>数值型数据、连续型数据</strong>（如传感器读数）</td></tr><tr><td><strong>典型算法</strong></td><td>Apriori, FP-Growth</td><td>PCA, t-SNE</td></tr></tbody></table><p>导出到 Google 表格</p><h3 id="它们的相似点在哪里？"><a href="#它们的相似点在哪里？" class="headerlink" title="它们的相似点在哪里？"></a><strong>它们的相似点在哪里？</strong></h3><p>尽管目标和操作截然不同，但它们确实有相似之处，这也是它们都被归为“无监督学习”的原因：</p><ol><li><strong>都无需标签：</strong> 它们都不需要一个预先定义好的“正确答案”来指导学习过程。</li><li><strong>都在探索数据内在结构：</strong><ul><li>ARM 探索的是<strong>项集之间的共现结构</strong>。</li><li>降维 探索的是<strong>特征之间的相关性结构或方差结构</strong>。</li><li>它们都在试图理解“数据本身告诉了我们什么”，而不是去预测一个外部变量。</li></ul></li></ol><h3 id="回到您的问题"><a href="#回到您的问题" class="headerlink" title="回到您的问题"></a><strong>回到您的问题</strong></h3><blockquote><p>“我挖掘了一个关联规则不就相当于提取到了一个特征来降维吗？”</p></blockquote><p>现在我们就能清晰地回答了：</p><ul><li>您挖掘的规则 <code>&#123;A&#125; -&gt; &#123;B&#125;</code> 是一个<strong>洞察</strong>，它告诉您 A 和 B 之间存在强关联。</li><li>您可以基于这个洞察<strong>手动创造</strong>一个新的特征，这个过程叫做<strong>特征工程（Feature Engineering）</strong>。例如，您可以增加一列叫 <code>is_A_B_buyer</code>，如果一个客户同时购买了 A 和 B，就标记为1，否则为0。</li><li>但是，这个<strong>手动创造新特征</strong>的动作，和降维算法（如PCA）<strong>自动地将几十个特征压缩成几个新特征</strong>，是完全不同的两件事。前者是基于一个特定模式的人工操作，后者是基于整个数据集方差分布的算法转换。</li></ul><p><strong>总结：</strong></p><ul><li><strong>关联规则挖掘告诉你一个故事</strong>（例如，“买尿布的人也爱买啤酒”）。</li><li><strong>降维给你提供了一张更简洁的地图</strong>（例如，用“经纬度”两个特征替代复杂的街道、门牌号等十几个特征）。</li></ul><p>一个是为了获得可以指导行动的<strong>商业洞察</strong>，另一个是为了<strong>优化数据本身</strong>，使其更易于存储、计算和可视化。</p><p> 是不是我可以先根据数据特征进行关联规则判断，如果两个特征有关联，我可以去掉其中一个，然后把剩下的特征来做聚类 </p><p>您这个想法非常有创意，而且逻辑上是自洽的！您准确地抓住了数据预处理的一个核心思想：<strong>在进行聚类或建模之前，应该先处理特征之间的冗余性，因为冗余的特征会影响算法的效果。</strong></p><p>这个思路的大方向是<strong>完全正确</strong>的。但是，使用“关联规则挖掘”来做这件事，属于一个<strong>“用对了逻辑，但选错了工具”</strong>的情况。</p><p>下面我们来详细解释为什么，并告诉您正确的工具应该是什么。</p><hr><h3 id="为什么用关联规则挖掘来处理特征冗余是“不合适”的？"><a href="#为什么用关联规则挖掘来处理特征冗余是“不合适”的？" class="headerlink" title="为什么用关联规则挖掘来处理特征冗余是“不合适”的？"></a><strong>为什么用关联规则挖掘来处理特征冗余是“不合适”的？</strong></h3><p>关联规则挖掘（ARM）和我们通常所说的特征间关联，虽然都叫“关联”，但它们处理的场景和数据类型完全不同。</p><ol><li><strong>ARM处理的是“交易数据” (Transactional Data)</strong><ul><li>ARM的“篮子”里装的是<strong>“项” (Items)<strong>，比如<code>&#123;牛奶, 面包, 啤酒&#125;</code>。它分析的是</strong>项与项之间的共现关系</strong>。</li><li>它的输入数据通常是稀疏的，每一行是一个交易，列是所有可能的商品。</li></ul></li><li><strong>特征关联处理的是“属性数据” (Attribute Data)</strong><ul><li>聚类的数据，每一行是一个样本（如一个客户），每一列是一个**“特征” (Feature)**，比如<code>年龄</code>、<code>收入</code>、<code>消费频率</code>。</li><li>我们在这里关心的是<strong>特征与特征（列与列）之间的关系</strong>，比如<code>年龄</code>这个特征和<code>收入</code>这个特征是不是高度相关。</li></ul></li></ol><p><strong>把特征当作“项”来跑关联规则，会遇到问题：</strong></p><ul><li><strong>数据格式不匹配：</strong> 您需要对数据进行复杂的转换（比如将连续的<code>收入</code>值离散化成“高、中、低”这样的“项”），这个过程本身就会损失大量信息。</li><li><strong>衡量标准不适用：</strong> ARM的支持度、置信度等指标，是为衡量“商品A出现时，商品B也出现”的场景设计的。而衡量两个特征（如<code>身高</code>和<code>体重</code>）的关系，我们有更直接、更强大的数学工具。</li></ul><hr><h3 id="处理特征冗余的“正确工具”是什么？"><a href="#处理特征冗余的“正确工具”是什么？" class="headerlink" title="处理特征冗余的“正确工具”是什么？"></a><strong>处理特征冗余的“正确工具”是什么？</strong></h3><p>您想实现的“如果两个特征有关联，我可以去掉其中一个”这个目标，在机器学习中通常通过以下两种标准方法实现：</p><h4 id="方法一：相关性分析-Correlation-Analysis-——-针对数值型特征"><a href="#方法一：相关性分析-Correlation-Analysis-——-针对数值型特征" class="headerlink" title="方法一：相关性分析 (Correlation Analysis) —— 针对数值型特征"></a><strong>方法一：相关性分析 (Correlation Analysis) —— 针对数值型特征</strong></h4><p>这是最直接、最常用的方法。</p><ul><li><strong>操作：</strong> 计算所有特征两两之间的<strong>相关系数</strong>（如皮尔逊相关系数）。这个系数的范围在-1到+1之间。<ul><li><strong>+1：</strong> 完全正相关（一个特征增加，另一个也以相同比例增加）。</li><li><strong>-1：</strong> 完全负相关（一个特征增加，另一个以相同比例减少）。</li><li><strong>0：</strong> 完全不相关。</li></ul></li><li><strong>判断：</strong> 您可以设定一个阈值，比如，如果两个特征之间的相关系数的<strong>绝对值大于0.8或0.9</strong>，就认为它们是高度冗余的。</li><li><strong>决策：</strong> 从这两个高度相关的特征中，您可以：<ol><li><strong>根据业务理解，保留更重要的一个</strong>，删除另一个。</li><li>如果无法判断，可以<strong>随机删除一个</strong>。</li><li>或者，将它们<strong>组合成一个新特征</strong>（比如取平均值）。</li></ol></li></ul><p><strong>这完美地、且更精确地实现了您的想法。</strong></p><h4 id="方法二：使用降维算法-Dimensionality-Reduction-——-更优越的自动化方案"><a href="#方法二：使用降维算法-Dimensionality-Reduction-——-更优越的自动化方案" class="headerlink" title="方法二：使用降维算法 (Dimensionality Reduction) —— 更优越的自动化方案"></a><strong>方法二：使用降维算法 (Dimensionality Reduction) —— 更优越的自动化方案</strong></h4><p>手动删除特征虽然简单，但缺点是会<strong>完全丢失被删除特征所包含的独有信息</strong>。一个更优雅、信息损失更少的方案是使用我们之前讨论过的<strong>降维</strong>，尤其是<strong>主成分分析（PCA）</strong>。</p><ul><li><strong>PCA如何解决冗余问题？</strong> PCA能够自动检测到特征之间的相关性。比如，它发现<code>身高</code>和<code>体重</code>高度相关，它不会粗暴地扔掉任何一个，而是会<strong>智能地将它们融合成一个新的、综合性的特征</strong>，比如可以理解为“体格因子”。</li><li><strong>优点：</strong><ul><li><strong>自动化：</strong> 无需手动选择阈值和要删除的特征。</li><li><strong>信息保留更完整：</strong> 它不是删除信息，而是重组和压缩信息，将多个相关特征的精华提取到一个新的特征中。</li></ul></li></ul><hr><h3 id="总结：您的思路的正确升级路径"><a href="#总结：您的思路的正确升级路径" class="headerlink" title="总结：您的思路的正确升级路径"></a><strong>总结：您的思路的正确升级路径</strong></h3><p>您的想法是一个非常好的起点，现在我们可以把它升级为机器学习的标准工作流：</p><ol><li><strong>您的原始想法：</strong> <code>数据 -&gt; 用关联规则判断特征关系 -&gt; 删除冗余特征 -&gt; 聚类</code></li><li><strong>标准实践方法A（手动选择）：</strong> <code>数据 -&gt; 计算特征间的**相关系数矩阵** -&gt; 识别并**手动删除**高度相关的特征 -&gt; 聚类</code></li><li><strong>标准实践方法B（自动提取）：</strong> <code>数据 -&gt; 使用**PCA等降维技术**将原始特征转换为少数几个新的主成分 -&gt; 使用**新的主成分**进行聚类</code></li></ol><p><strong>结论：</strong> 您的核心逻辑——“消除冗余以优化聚类”——是完全正确的，这是数据科学家一直在做的事情。只是实现这个逻辑的工具，应该是<strong>相关性分析</strong>或<strong>PCA</strong>，而不是关联规则挖掘。您已经非常接近专业的数据处理思维了！</p><p> 那我是不是可以先使用无监督学习降维再进行无监督学习聚类 </p><p>是的，完全正确！您刚才描述的这个流程，<strong>不仅是可行的，而且是机器学习中非常常用、非常强大的一种标准实践（Best Practice）</strong>。</p><p>将降维和聚类结合使用，通常被称为“先降维，再聚类”，是无监督学习工具箱里一套威力十足的“组合拳”。</p><hr><h3 id="为什么这是一个“黄金组合”？"><a href="#为什么这是一个“黄金组合”？" class="headerlink" title="为什么这是一个“黄金组合”？"></a><strong>为什么这是一个“黄金组合”？</strong></h3><p>在很多情况下，直接在高维度的原始数据上进行聚类，效果可能并不理想。而先进行降维，则可以为后续的聚类算法提供一个更理想、更干净的“工作台”。这样做有四大核心好处：</p><h4 id="1-攻克“维度灾难”-Curse-of-Dimensionality"><a href="#1-攻克“维度灾难”-Curse-of-Dimensionality" class="headerlink" title="1. 攻克“维度灾难” (Curse of Dimensionality)"></a>1. <strong>攻克“维度灾难” (Curse of Dimensionality)</strong></h4><p>当数据特征（维度）非常多时，数据点会变得异常稀疏，任何两个点之间的距离都可能变得很大且相差无几。这会让依赖距离计算的聚类算法（如K-Means）难以判断样本间的真实亲疏关系，导致聚类效果下降。降维可以有效缓解这个问题。</p><h4 id="2-提升聚类效果与速度-Improving-Quality-and-Speed"><a href="#2-提升聚类效果与速度-Improving-Quality-and-Speed" class="headerlink" title="2. 提升聚类效果与速度 (Improving Quality and Speed)"></a>2. <strong>提升聚类效果与速度 (Improving Quality and Speed)</strong></h4><ul><li><strong>去除噪声：</strong> 原始特征中可能包含很多与数据内在结构无关的“噪声”。降维（尤其是PCA）擅长捕捉数据的主要变化方向（信号），而忽略次要的随机波动（噪声）。在更“纯净”的数据上聚类，效果自然更好。</li><li><strong>减少冗余：</strong> 降维处理了特征间的相关性，避免了聚类算法被几个高度相关的特征重复“误导”。</li><li><strong>加快计算：</strong> 特征数量减少了，聚类算法的计算量会大幅下降，尤其是在处理大型数据集时，可以节省大量时间和计算资源。</li></ul><h4 id="3-方便可视化与理解-Enabling-Visualization-and-Understanding"><a href="#3-方便可视化与理解-Enabling-Visualization-and-Understanding" class="headerlink" title="3. 方便可视化与理解 (Enabling Visualization and Understanding)"></a>3. <strong>方便可视化与理解 (Enabling Visualization and Understanding)</strong></h4><p>这是一个非常直观的好处。您无法画出一张100维的图，但通过降维将数据降到2维或3维后，您就可以轻松地将数据点绘制在散点图上。此时，如果数据有明显的聚类结构，你将<strong>用肉眼直接看到</strong>它们分成几堆，这对于理解数据、确定聚类数量（K值）以及验证聚类结果都非常有帮助。</p><hr><h3 id="一个典型的操作流程-A-Typical-Workflow"><a href="#一个典型的操作流程-A-Typical-Workflow" class="headerlink" title="一个典型的操作流程 (A Typical Workflow)"></a><strong>一个典型的操作流程 (A Typical Workflow)</strong></h3><p>假设您手上有包含上百个特征的客户数据，想对他们进行分群。</p><ol><li><strong>第一步：数据预处理 (Preprocessing)</strong><ul><li>对原始数据进行<strong>标准化（Scaling）</strong>。这是非常关键的一步，因为像PCA这样的降维算法对数据的尺度非常敏感。通常使用 <code>StandardScaler</code>。</li></ul></li><li><strong>第二步：应用降维 (Dimensionality Reduction)</strong><ul><li>使用<strong>PCA</strong>算法处理标准化后的数据。</li><li>您可以决定保留多少个主成分（比如，选择能解释原始数据90%或95%方差的前N个主成分）。这样，您的数据就从几百维降到了N维（N通常远小于原始维度）。</li></ul></li><li><strong>第三步：应用聚类 (Clustering)</strong><ul><li>在<strong>降维后的新数据集</strong>上运行聚类算法（如<strong>K-Means</strong>）。</li><li>此时算法会运行得更快，并且更容易在低维空间中找到清晰的簇边界。</li></ul></li><li><strong>第四步：结果分析与解读 (Analysis)</strong><ul><li>分析聚类结果。您可以将降到2维的数据点和聚类结果一起可视化，直观地查看分群效果。</li><li>要理解每个簇的业务含义，您需要将簇的标签映射回原始的高维特征空间，去分析每个群体的客户在原始特征上的具体表现。</li></ul></li></ol><hr><h3 id="一个生动的比喻：雕塑家的工作"><a href="#一个生动的比喻：雕塑家的工作" class="headerlink" title="一个生动的比喻：雕塑家的工作"></a><strong>一个生动的比喻：雕塑家的工作</strong></h3><p>您可以把这个过程想象成一位雕塑家创作一件作品：</p><ul><li><strong>原始高维数据：</strong> 一块巨大、粗糙、未经雕琢的大理石原料。</li><li><strong>降维 (PCA)：</strong> 雕塑家首先用大锤和凿子，<strong>砍掉大块多余的石料</strong>，勾勒出作品的大致轮廓。这个过程去除了“噪声”和“冗余”，让作品的核心形态显现出来。</li><li><strong>聚类 (K-Means)：</strong> 在这个已经有了基本轮廓的石胚上，雕塑家再换上小刻刀，进行<strong>精雕细琢</strong>，刻画出人物的五官、衣物的褶皱等细节。这些细节就是数据中不同的“簇”。</li></ul><p>如果不先进行第一步的“塑形”，直接在巨大的原料上进行精雕细琢，不仅费时费力，而且很容易迷失在细节中，无法把握整体结构。</p><p><strong>总结：</strong> 您的想法完全正确，并且是解决复杂数据分析问题的标准思路。<strong>先用降维负责“清理和浓缩”数据，再用聚类负责“分组和打标”</strong>，两者相辅相成，能够达到 <code>1+1 &gt; 2</code> 的效果。</p><p> 关联特征分析是不是不处理特征数值的大小，只处理特征之间出现的协同性 </p><p>您这个问题提得非常精准！您的描述，“<strong>不处理特征数值的大小，只处理特征之间出现的协同性</strong>”，完美地概括了我们之前讨论的<strong>关联规则挖掘（Association Rule Mining）</strong>的核心特点。</p><p>但是，“关联特征分析”这个词可以有更广泛的含义，它包含了多种不同的技术。所以，您的这个说法<strong>是否正确，取决于我们具体指的是哪一种分析方法</strong>。</p><p>让我们来清晰地辨析一下：</p><hr><h3 id="情况一：当“关联特征分析”指代“关联规则挖掘”时，您的说法完全正确！"><a href="#情况一：当“关联特征分析”指代“关联规则挖掘”时，您的说法完全正确！" class="headerlink" title="情况一：当“关联特征分析”指代“关联规则挖掘”时，您的说法完全正确！"></a><strong>情况一：当“关联特征分析”指代“关联规则挖掘”时，您的说法完全正确！</strong></h3><p>关联规则挖掘（ARM）的本质就是分析**“协同性” (Co-occurrence)**，也就是“出现”与“不出现”的问题。</p><ul><li><strong>核心思想：</strong> 它处理的是**离散的、分门别类的“项” (Items)**。数据被看作是一系列“交易”，每个交易包含一个“项”的集合。</li><li><strong>如何对待数值：</strong> 它不关心数值本身的大小或程度。例如，在购物篮分析中：<ul><li>系统只关心顾客的购物篮里<strong>有没有</strong>“牛奶”和“面包”。</li><li>它<strong>不关心</strong>顾客是买了1升牛奶还是2升牛奶（数值大小），也不关心他买的是10元的面包还是20元的面包（数值大小）。</li><li>只要“牛奶”和“面包”这两个“项”同时出现在购物篮里，这次交易就被计入协同出现的次数。</li></ul></li></ul><p>所以，对于关联规则挖掘，您的总结是100%准确的。它是一个基于<strong>“是否出现”</strong>的逻辑，而不是基于<strong>“数值高低”</strong>的逻辑。</p><hr><h3 id="情况二：当“关联特征分析”指代“相关性分析”时，您的说法就不正确了。"><a href="#情况二：当“关联特征分析”指代“相关性分析”时，您的说法就不正确了。" class="headerlink" title="情况二：当“关联特征分析”指代“相关性分析”时，您的说法就不正确了。"></a><strong>情况二：当“关联特征分析”指代“相关性分析”时，您的说法就不正确了。</strong></h3><p>相关性分析（Correlation Analysis）是另一种衡量特征关联度的常用方法，它专门用来处理<strong>数值型特征</strong>，并且<strong>完全依赖于数值的大小</strong>。</p><ul><li><strong>核心思想：</strong> 它衡量的是一个数值型特征<strong>变化</strong>时，另一个数值型特征<strong>如何随之变化</strong>。</li><li><strong>如何对待数值：</strong> 数值的大小和变化趋势是其分析的全部基础。例如，分析<code>身高</code>和<code>体重</code>这两个特征：<ul><li>我们不是关心一个人“有没有身高”和“有没有体重”。</li><li>我们关心的是<code>身高</code><strong>数值较高</strong>的人，其<code>体重</code><strong>数值是否也倾向于较高</strong>。</li><li>相关系数（比如+0.8）这个结果，就是通过计算所有人的身高和体重具体数值的线性关系得出的。数值的大小和变化方向是决定性的。</li></ul></li></ul><hr><h3 id="总结对比"><a href="#总结对比" class="headerlink" title="总结对比"></a><strong>总结对比</strong></h3><p>为了让您看得更清楚，我们用一个表格来总结：</p><table><thead><tr><th>特性</th><th><strong>关联规则挖掘 (ARM)</strong></th><th><strong>相关性分析 (Correlation Analysis)</strong></th></tr></thead><tbody><tr><td><strong>核心思想</strong></td><td><strong>协同性 (Co-occurrence)</strong></td><td><strong>相关性 (Correlation)</strong></td></tr><tr><td><strong>是否处理数值大小？</strong></td><td><strong>否</strong>，只关心“有&#x2F;无”的布尔逻辑</td><td><strong>是</strong>，完全依赖于数值的大小和变化趋势</td></tr><tr><td><strong>典型数据类型</strong></td><td>交易数据、类别数据（商品清单、网页浏览记录）</td><td>数值型数据、连续型数据（身高、体重、收入、温度）</td></tr><tr><td><strong>回答的问题</strong></td><td>“哪些东西经常<strong>一起出现</strong>？”</td><td>“一个数值<strong>变大</strong>时，另一个数值是否也随之<strong>变大或变小</strong>？”</td></tr></tbody></table><p>导出到 Google 表格</p><p><strong>结论：</strong></p><p>您的理解非常敏锐，准确地抓住了关联规则挖掘的本质。但请务必记住，“关联特征分析”是一个更宽泛的领域。</p><ul><li>如果您面对的是像购物清单一样的<strong>类别数据</strong>，想找“一起出现”的模式，那么就是用关联规则挖掘，此时<strong>不考虑数值大小</strong>。</li><li>如果您面对的是像客户档案里的年龄、收入这样的<strong>数值数据</strong>，想看特征间的联动关系，那么就是用相关性分析，此时<strong>数值大小是分析的核心</strong>。</li></ul><p> 聚类有哪些算法，分别适用什么情况 </p><p>好的，这是一个非常实际且重要的问题。聚类算法有很多种，它们基于不同的数学原理，因此各自有其独特的优势和适用场景。没有“万能”的算法，选择哪种取决于您的数据特性和分析目标。</p><p>下面我将介绍几种最主流、最经典的聚类算法，并详细说明它们分别适用于什么情况。</p><hr><h3 id="1-K-均值聚类-K-Means-Clustering"><a href="#1-K-均值聚类-K-Means-Clustering" class="headerlink" title="1. K-均值聚类 (K-Means Clustering)"></a><strong>1. K-均值聚类 (K-Means Clustering)</strong></h3><p>这是最著名、最简单的聚类算法，属于“原型聚类”的代表，试图找到数据的“中心点”或“原型”。</p><ul><li><strong>工作原理：</strong><ol><li><strong>预设 K 值：</strong> 首先，您需要<strong>手动指定</strong>要将数据分成 K 个簇。</li><li><strong>随机初始化：</strong> 算法随机选择 K 个数据点作为初始的“簇中心”（Centroids）。</li><li><strong>迭代分配与更新：</strong><ul><li><strong>分配：</strong> 将每个数据点分配给离它最近的那个簇中心。</li><li><strong>更新：</strong> 重新计算每个簇所有数据点的平均值，将这个平均值作为新的簇中心。</li></ul></li><li><strong>循环此过程</strong>，直到簇中心不再变化为止。</li></ol></li><li><strong>适用情况：</strong><ul><li><strong>球状&#x2F;凸状数据分布：</strong> 当您的数据簇大致呈圆形或凸形时，K-Means 效果最好。</li><li><strong>大数据集：</strong> 算法非常高效，计算速度快，可扩展性好，适合处理大规模数据。</li><li><strong>簇的数量已知或可以预估：</strong> 当您对业务有一定了解，大致知道数据应该被分成几类时。</li></ul></li><li><strong>不适用&#x2F;缺点：</strong><ul><li><strong>需要预先指定K值：</strong> K值的选择对结果影响巨大，且往往难以确定。</li><li><strong>对初始值敏感：</strong> 随机选择的初始簇中心可能导致不同的聚类结果。</li><li><strong>对异常值敏感：</strong> 异常值会极大地影响簇中心的计算，可能导致簇中心偏离。</li><li><strong>无法处理非球状簇：</strong> 对于条形、环形或其他不规则形状的簇，K-Means 无法正确识别。</li></ul></li></ul><hr><h3 id="2-DBSCAN-Density-Based-Spatial-Clustering-of-Applications-with-Noise"><a href="#2-DBSCAN-Density-Based-Spatial-Clustering-of-Applications-with-Noise" class="headerlink" title="2. DBSCAN (Density-Based Spatial Clustering of Applications with Noise)"></a><strong>2. DBSCAN (Density-Based Spatial Clustering of Applications with Noise)</strong></h3><p>DBSCAN 是“基于密度的聚类”的杰出代表，它不关心数据的“中心”，只关心数据的“密度”。</p><ul><li><strong>工作原理：</strong><ol><li><strong>定义邻域：</strong> 需要设定两个参数：邻域半径（<code>eps</code>）和最小点数（<code>MinPts</code>）。</li><li><strong>识别核心点：</strong> 如果一个点的 <code>eps</code> 半径内包含了至少 <code>MinPts</code> 个点，那么这个点就是一个“核心点”。</li><li><strong>扩展簇：</strong> 从任意一个核心点出发，不断寻找其密度可达（即在 <code>eps</code> 范围内）的其他核心点和边界点，将它们合并成一个簇。</li><li><strong>识别噪声：</strong> 那些不属于任何簇的点被标记为“噪声”或“异常点”。</li></ol></li><li><strong>适用情况：</strong><ul><li><strong>任意形状的簇：</strong> DBSCAN 的最大优势，可以发现非球状、不规则形状的簇（如月牙形、环形）。</li><li><strong>需要识别异常点&#x2F;噪声：</strong> 能够自动将密度稀疏的区域识别为噪声，非常适合用于异常检测。</li><li><strong>不需要预设簇数：</strong> 算法会自动根据数据密度发现簇的数量，非常方便。</li></ul></li><li><strong>不适用&#x2F;缺点：</strong><ul><li><strong>对参数敏感：</strong> <code>eps</code> 和 <code>MinPts</code> 这两个参数的选择至关重要，且需要经验来调整。</li><li><strong>对密度不均的数据集效果不佳：</strong> 如果数据中不同簇的密度差异很大，用同一套 <code>eps</code> 和 <code>MinPts</code> 参数就很难同时覆盖所有簇。</li><li><strong>高维数据处理困难：</strong> 在高维空间中，“密度”的定义会变得模糊（维度灾难），<code>eps</code> 参数难以设定。</li></ul></li></ul><hr><h3 id="3-层次聚类-Hierarchical-Clustering"><a href="#3-层次聚类-Hierarchical-Clustering" class="headerlink" title="3. 层次聚类 (Hierarchical Clustering)"></a><strong>3. 层次聚类 (Hierarchical Clustering)</strong></h3><p>层次聚类试图构建一个数据的层次结构，就像一棵树。它分为“自底向上”（凝聚型）和“自顶向下”（分裂型）两种。</p><ul><li><strong>工作原理（以凝聚型为例）：</strong><ol><li><strong>初始化：</strong> 将每个数据点都视为一个独立的簇。</li><li><strong>迭代合并：</strong> 找到所有簇中“距离”最近的两个簇，并将它们合并成一个新的簇。</li><li><strong>循环此过程</strong>，直到所有数据点最终被合并成一个最大的簇为止。</li><li><strong>结果呈现：</strong> 整个过程会形成一个树状图（Dendrogram），您可以根据需要，在任意高度“横切”一刀，来决定最终的簇数量。</li></ol></li><li><strong>适用情况：</strong><ul><li><strong>希望看到数据的层次关系：</strong> 当您不仅想知道数据分几类，还想了解类别之间的亲疏远近关系时，如生物学中的物种分类谱系。</li><li><strong>簇的数量不确定：</strong> 您可以通过观察树状图来决定一个合理的簇数量。</li><li><strong>小数据集：</strong> 对于小规模的数据，其结果直观且易于解释。</li></ul></li><li><strong>不适用&#x2F;缺点：</strong><ul><li><strong>计算复杂度高：</strong> 时间复杂度通常为 O(n³)，空间复杂度为 O(n²)，不适合处理大规模数据集。</li><li><strong>合并&#x2F;分裂不可逆：</strong> 一旦一个步骤的合并或分裂完成，后续就无法撤销，这可能导致次优的聚类结果。</li><li><strong>对距离度量敏感：</strong> 选择不同的距离计算方法（如欧氏距离、曼哈顿距离）和合并策略（如ward、complete）对结果影响很大。</li></ul></li></ul><hr><h3 id="4-高斯混合模型-Gaussian-Mixture-Model-GMM"><a href="#4-高斯混合模型-Gaussian-Mixture-Model-GMM" class="headerlink" title="4. 高斯混合模型 (Gaussian Mixture Model, GMM)"></a><strong>4. 高斯混合模型 (Gaussian Mixture Model, GMM)</strong></h3><p>GMM 是一种“基于概率分布的聚类”方法。它假设所有数据点都是从若干个不同的高斯分布（正态分布）中生成的。</p><ul><li><strong>工作原理：</strong><ol><li><strong>假设：</strong> 假定数据由 K 个高斯分布混合而成，每个分布代表一个簇。</li><li><strong>EM算法：</strong> 使用期望最大化（Expectation-Maximization, EM）算法进行迭代：<ul><li><strong>E-步（期望）：</strong> 估计每个数据点由每个高斯分布生成的<strong>概率</strong>。</li><li><strong>M-步（最大化）：</strong> 根据上一步的概率，更新每个高斯分布的参数（均值、方差、权重），使其能最大化地拟合数据。</li></ul></li><li><strong>循环此过程</strong>，直到模型收敛。最终，每个数据点可以被分配给生成它的概率最大的那个高斯分布（簇）。</li></ol></li><li><strong>适用情况：</strong><ul><li><strong>椭圆形簇：</strong> K-Means 只能处理球形簇，而GMM可以处理更具一般性的<strong>椭圆形簇</strong>。</li><li><strong>软聚类 (Soft Clustering)：</strong> GMM 不会硬性地将一个点分给某一类，而是给出一个<strong>概率</strong>。这对于处理簇边界模糊的数据非常有用。</li><li><strong>需要生成新样本：</strong> 由于GMM是一个生成模型，一旦训练完成，您可以用它来生成与原始数据分布类似的新数据点。</li></ul></li><li><strong>不适用&#x2F;缺点：</strong><ul><li><strong>计算复杂：</strong> EM算法的计算量比K-Means大。</li><li><strong>需要预设簇数：</strong> 和K-Means一样，需要指定高斯分布的数量。</li><li><strong>对非椭圆形数据效果不佳：</strong> 其假设是高斯分布，所以无法很好地拟合不规则形状的簇。</li></ul></li></ul><h3 id="总结：如何选择？"><a href="#总结：如何选择？" class="headerlink" title="总结：如何选择？"></a><strong>总结：如何选择？</strong></h3><table><thead><tr><th>算法</th><th>核心思想</th><th>簇形状</th><th>簇数量</th><th>规模</th><th>主要优点</th><th>主要缺点</th></tr></thead><tbody><tr><td><strong>K-Means</strong></td><td>基于中心</td><td><strong>球形&#x2F;凸形</strong></td><td><strong>需预设</strong></td><td>大</td><td>速度快，简单高效</td><td>对初始值&#x2F;异常值敏感，无法处理非球状</td></tr><tr><td><strong>DBSCAN</strong></td><td>基于密度</td><td><strong>任意形状</strong></td><td><strong>自动发现</strong></td><td>中&#x2F;大</td><td>能处理任意形状，能识别噪声</td><td>对参数和密度不均敏感</td></tr><tr><td><strong>层次聚类</strong></td><td>基于层次</td><td>任意形状</td><td>无需预设</td><td>小</td><td>提供层次关系，结果直观</td><td>计算复杂度高，不适合大数据</td></tr><tr><td><strong>GMM</strong></td><td>基于分布</td><td><strong>椭圆形</strong></td><td><strong>需预设</strong></td><td>中</td><td>提供属于各簇的概率（软聚类）</td><td>假设数据为高斯分布，计算较慢</td></tr></tbody></table><p>导出到 Google 表格</p><p><strong>一个简单的决策流程：</strong></p><ol><li><strong>数据量大，且簇的形状大致是球形？</strong> -&gt; <strong>首选 K-Means</strong>。</li><li><strong>不确定要分几类，簇的形状可能不规则，且想识别噪声点？</strong> -&gt; <strong>首选 DBSCAN</strong>。</li><li><strong>数据量不大，且想了解数据内在的层次结构？</strong> -&gt; <strong>使用层次聚类</strong>。</li><li><strong>簇的形状可能是椭圆形，或者希望得到一个点属于各个簇的概率？</strong> -&gt; <strong>考虑 GMM</strong>。</li></ol><p> 什么是簇的形状 </p><p>当然，这是一个非常好的问题！在聚类分析中，我们经常提到“簇的形状”，这听起来可能有点抽象，因为数据本身是没有物理形状的。</p><p>“簇的形状”其实是一个非常直观的比喻，它指的是<strong>数据点在特征空间（即图表上）的分布模式或排列形态</strong>。</p><p>为了方便理解，我们通常把它想象在一个二维的散点图上（例如，X轴是“收入”，Y轴是“消费频率”）。每个数据点就是图上的一个点，而一群点的聚集形态，就是我们所说的“簇的形状”。</p><p>下面我们来详细看一下几种典型的簇形状，以及它们如何影响算法的选择。</p><hr><h3 id="1-球形-凸形-Spherical-Convex-Shape"><a href="#1-球形-凸形-Spherical-Convex-Shape" class="headerlink" title="1. 球形&#x2F;凸形 (Spherical &#x2F; Convex Shape)"></a><strong>1. 球形&#x2F;凸形 (Spherical &#x2F; Convex Shape)</strong></h3><p>这是最简单、最理想的一种形状。</p><ul><li><strong>直观描述：</strong> 数据点紧密地聚集在一个大致<strong>圆形</strong>的区域内，密度从中心向四周均匀递减。从任何角度看，这个簇都是一个“实心”的团，没有凹陷。</li><li><strong>例子：</strong> 测量一大群同龄男性的身高和体重，这些数据点很可能会形成一个球状或椭圆形的簇。</li><li><strong>适合的算法：</strong> <strong>K-Means</strong>。因为K-Means的原理就是找到一个“中心点”，然后将离这个中心点近的所有点都归为一类。这种“离中心点近”的逻辑，天然地就定义出了一个球形的边界。</li></ul><hr><h3 id="2-椭圆形-Elliptical-Shape"><a href="#2-椭圆形-Elliptical-Shape" class="headerlink" title="2. 椭圆形 (Elliptical Shape)"></a><strong>2. 椭圆形 (Elliptical Shape)</strong></h3><p>这是球形的一种延伸，在现实世界中更常见。</p><ul><li><strong>直观描述：</strong> 数据点聚集在一个<strong>椭圆形</strong>的区域内。这通常意味着不同特征（坐标轴）之间的尺度不同，或者特征之间存在一定的相关性。</li><li><strong>例子：</strong> 客户的“年龄”和“收入”数据，很可能形成一个椭圆形，因为年龄和收入是正相关的，数据点会沿着一个方向被“拉长”。</li><li><strong>适合的算法：</strong> **高斯混合模型 (GMM)**。GMM假设数据是从高斯分布（正态分布）中生成的，而高斯分布的等高线图正好是椭圆形。它可以很好地拟合这种被拉伸或旋转的簇。K-Means在这种情况下效果会变差，因为它总想画一个“正圆”的边界。</li></ul><hr><h3 id="3-任意形状-Arbitrary-Shape"><a href="#3-任意形状-Arbitrary-Shape" class="headerlink" title="3. 任意形状 (Arbitrary Shape)"></a><strong>3. 任意形状 (Arbitrary Shape)</strong></h3><p>这是最复杂，但也最有趣的一类形状，它们不是一个“实心”的团。</p><ul><li><strong>直观描述：</strong> 数据的分布呈现出各种不规则的形态，比如条形、环形、月牙形、S形等。这些形状通常是“非凸”的，即内部有“凹陷”或“空洞”。</li><li><strong>例子：</strong><ul><li><strong>条形&#x2F;线性：</strong> 河流沿岸的村庄分布。</li><li><strong>环形&#x2F;同心圆：</strong> 靶心周围的弹孔分布，可能有一圈密集的9环和一圈密集的7环，但8环和靶心是空的。</li><li><strong>月牙形：</strong> 生物学或天文学中某些特定的数据模式。</li></ul></li><li><strong>适合的算法：</strong> <strong>DBSCAN</strong>。DBSCAN不关心簇的中心在哪里，只关心密度。只要点与点之间足够近，能够“连接”起来，它就能把它们都识别成一个簇。因此，它能像“贪吃蛇”一样，沿着任何形状的路径把簇找出来。</li></ul><p><em>(上图展示了不同算法在处理任意形状簇时的表现。可以看到K-Means完全失败了，而DBSCAN和层次聚类则表现得很好。)</em></p><hr><h3 id="为什么不同算法偏好不同形状？"><a href="#为什么不同算法偏好不同形状？" class="headerlink" title="为什么不同算法偏好不同形状？"></a><strong>为什么不同算法偏好不同形状？</strong></h3><p>这源于它们底层的数学逻辑：</p><ul><li><strong>K-Means的逻辑是“距离中心点近”</strong>：这个逻辑决定了它的势力范围必然是球形的。对于两个月牙形的簇，K-Means会错误地将距离各自中心点近的点划分在一起，从而把两个月牙都“切开”，并错误地组合在一起。</li><li><strong>DBSCAN的逻辑是“密度相连”</strong>：它的逻辑是“我的邻居是我的朋友，我邻居的邻居也是我的朋友”。这个逻辑与整体形状无关，只关心局部有多拥挤。因此，只要数据点能形成一条密度足够高的“小径”，DBSCAN就能沿着这条小径把整个簇识别出来，无论小径最终弯曲成了什么形状。</li></ul><h3 id="总结-3"><a href="#总结-3" class="headerlink" title="总结"></a><strong>总结</strong></h3><table><thead><tr><th>形状类型</th><th>直观描述</th><th>适合的算法</th><th>不适合的算法</th></tr></thead><tbody><tr><td><strong>球形&#x2F;凸形</strong></td><td>圆形的、实心的团</td><td><strong>K-Means</strong>, GMM</td><td>DBSCAN (也能用，但有点大材小用)</td></tr><tr><td><strong>椭圆形</strong></td><td>椭圆形的、被拉伸的团</td><td><strong>GMM</strong>, 层次聚类</td><td>K-Means (效果会变差)</td></tr><tr><td><strong>任意形状</strong></td><td>条形、环形、月牙形等不规则形状</td><td><strong>DBSCAN</strong>, 层次聚类</td><td><strong>K-Means</strong> (完全不适用), GMM</td></tr></tbody></table><p><strong>核心要点：</strong> 在选择聚类算法前，最好先通过<strong>数据可视化</strong>（比如抽样画出特征的散点图）对数据的分布形态有一个初步的了解。看到数据的“形状”，可以极大地帮助你选择正确的“工具”（算法），从而得到有意义的分析结果。</p><p> 降维的算法有哪些 </p><p>当然。降维算法种类繁多，它们可以被划分为两大主流派系：**特征选择（Feature Selection）**和**特征提取（Feature Extraction）**。</p><p>下面我将为您详细介绍这两个派系下的主要算法。</p><hr><h3 id="两大降维派系"><a href="#两大降维派系" class="headerlink" title="两大降维派系"></a><strong>两大降维派系</strong></h3><p>首先，理解这两个派系的根本区别至关重要：</p><ol><li><strong>特征选择 (Feature Selection):</strong><ul><li><strong>思想：</strong> 像一位“评审员”，直接从原始的特征中<strong>挑选出</strong>一个最优的子集，而<strong>不改变原始特征本身</strong>。被选中的特征保持原有的物理意义。</li><li><strong>优点：</strong> 可解释性强，因为你清楚地知道留下了哪些原始特征。</li><li><strong>例子：</strong> 从100个客户特征中，挑选出最重要的10个（如“收入”、“年龄”、“消费频率”等）。</li></ul></li><li><strong>特征提取 (Feature Extraction):</strong><ul><li><strong>思想：</strong> 像一位“炼金术士”，将原始的多个特征进行<strong>融合与重组</strong>，创造出全新的、数量更少的特征。新特征是原始特征的某种组合。</li><li><strong>优点：</strong> 能够保留更多原始数据的信息，通常降维效果更好。</li><li><strong>缺点：</strong> 新生成的特征通常失去了原有的物理意义，可解释性变差。</li><li><strong>例子：</strong> 将“身高”、“体重”、“臂展”等多个特征融合成一个新的特征，称为“体格因子”。</li></ul></li></ol><hr><h3 id="一、特征选择-Feature-Selection-的方法"><a href="#一、特征选择-Feature-Selection-的方法" class="headerlink" title="一、特征选择 (Feature Selection) 的方法"></a><strong>一、特征选择 (Feature Selection) 的方法</strong></h3><p>特征选择本身不是一个单一算法，而是一类方法的统称，主要分为三类：</p><h4 id="1-过滤法-Filter-Methods"><a href="#1-过滤法-Filter-Methods" class="headerlink" title="1. 过滤法 (Filter Methods)"></a><strong>1. 过滤法 (Filter Methods)</strong></h4><p>在任何模型训练之前，先对数据进行预处理，根据特征的统计属性（如方差、相关性、信息量）来“过滤”掉一部分特征。</p><ul><li><strong>方差选择法 (Variance Threshold):</strong> 优先删除那些方差很小甚至为零的特征，因为这些特征在所有样本上几乎没有变化，包含的信息量很少。</li><li><strong>相关系数法 (Correlation Coefficient):</strong> 计算特征之间的相关性，如果两个特征高度相关（如“房屋面积”和“房间数量”），则可以只保留其中一个。</li><li><strong>卡方检验 (Chi-Squared Test):</strong> 用于评估类别特征对于类别标签的相关性。</li><li><strong>信息增益 (Information Gain):</strong> 常用于决策树，评估一个特征对于数据集不确定性的减少程度。</li></ul><h4 id="2-包装法-Wrapper-Methods"><a href="#2-包装法-Wrapper-Methods" class="headerlink" title="2. 包装法 (Wrapper Methods)"></a><strong>2. 包装法 (Wrapper Methods)</strong></h4><p>将特征选择过程“包装”在一个特定的机器学习模型周围，通过评估模型性能来决定保留哪些特征。</p><ul><li><strong>递归特征消除 (Recursive Feature Elimination, RFE):</strong><ul><li><strong>思想：</strong> 首先用所有特征训练一个模型，然后移除最不重要的特征，再用剩下的特征重新训练模型……如此循环，直到剩下预设数量的特征。</li><li><strong>优点：</strong> 效果通常很好。</li><li><strong>缺点：</strong> 计算成本非常高，因为需要反复训练模型。</li></ul></li></ul><h4 id="3-嵌入法-Embedded-Methods"><a href="#3-嵌入法-Embedded-Methods" class="headerlink" title="3. 嵌入法 (Embedded Methods)"></a><strong>3. 嵌入法 (Embedded Methods)</strong></h4><p>在模型训练的过程中<strong>自动</strong>进行特征选择。</p><ul><li><strong>L1 正则化 (LASSO):</strong><ul><li><strong>思想：</strong> 在模型的损失函数中加入L1惩罚项，它倾向于将不重要的特征的系数直接压缩到<strong>零</strong>。训练完成后，系数不为零的特征就是被选中的特征。</li><li><strong>优点：</strong> 高效且常用，将特征选择与模型训练融为一体。</li></ul></li><li><strong>基于树模型的方法 (Tree-based Models):</strong><ul><li><strong>思想：</strong> 决策树、随机森林、梯度提升树等模型在构建过程中，会自然地计算每个特征的重要性（Feature Importance）。我们可以直接根据这个重要性排名来选择特征。</li></ul></li></ul><hr><h3 id="二、特征提取-Feature-Extraction-的算法"><a href="#二、特征提取-Feature-Extraction-的算法" class="headerlink" title="二、特征提取 (Feature Extraction) 的算法"></a><strong>二、特征提取 (Feature Extraction) 的算法</strong></h3><p>这是“降维算法”这个词通常所指代的，主要分为线性和非线性两大类。</p><h4 id="A-线性降维算法"><a href="#A-线性降维算法" class="headerlink" title="A. 线性降维算法"></a><strong>A. 线性降维算法</strong></h4><p>假设数据中的主要结构可以通过一个线性子空间来描述。</p><ul><li><strong>1. 主成分分析 (Principal Component Analysis, PCA)</strong><ul><li><strong>核心思想：</strong> 寻找数据中<strong>方差最大</strong>的方向，将这些方向作为新的坐标轴（主成分）。它旨在最大程度地保留原始数据的“可分性”（方差）。</li><li><strong>适用场景：</strong> <strong>最常用、最经典</strong>的降维算法，是大多数情况下的<strong>首选基准</strong>。广泛用于数据预处理、去噪和可视化。</li></ul></li><li><strong>2. 线性判别分析 (Linear Discriminant Analysis, LDA)</strong><ul><li><strong>核心思想：</strong> <strong>（注意：这是一个有监督算法）</strong> 与PCA不同，LDA的目标是寻找一个能<strong>最大化类间距离、同时最小化类内距离</strong>的投影方向。通俗讲，就是让不同类别的数据点在投影后分得尽可能开。</li><li><strong>适用场景：</strong> 主要用于<strong>分类问题</strong>的预处理，当你有类别标签时，降维的目标是为了更好地分类。</li></ul></li></ul><h4 id="B-非线性降维算法（流形学习-Manifold-Learning）"><a href="#B-非线性降维算法（流形学习-Manifold-Learning）" class="headerlink" title="B. 非线性降维算法（流形学习 Manifold Learning）"></a><strong>B. 非线性降维算法（流形学习 Manifold Learning）</strong></h4><p>假设高维数据实际上分布在一个低维的、弯曲的“流形”上。目标是“展开”这个流形，找到其内在的低维结构。</p><ul><li><strong>1. t-分布随机邻域嵌入 (t-SNE)</strong><ul><li><strong>核心思想：</strong> 重点保持数据点的<strong>局部邻域结构</strong>。它假设高维空间中距离近的点，在低维空间中也应该距离近。</li><li><strong>适用场景：</strong> <strong>数据可视化</strong>的王者。非常擅长将高维数据降到2D或3D，以观察其聚类结构。<strong>注意：</strong> t-SNE主要用于可视化，降维后的点间距离不具有真实意义，不建议直接作为其他模型的输入。</li></ul></li><li><strong>2. 均匀流形逼近与投影 (Uniform Manifold Approximation and Projection, UMAP)</strong><ul><li><strong>核心思想：</strong> 与t-SNE类似，但基于更坚实的数学理论。它在保持局部结构的同时，能更好地保留数据的<strong>全局结构</strong>。</li><li><strong>适用场景：</strong> 现代的<strong>数据可视化</strong>首选，通常比t-SNE<strong>速度更快</strong>，且可视化效果更好。</li></ul></li><li><strong>3. 等距映射 (Isometric Mapping, Isomap)</strong><ul><li><strong>核心思想：</strong> 尝试保持点之间的<strong>测地线距离</strong>（即沿着流形表面的最短距离），而不是欧氏距离（直线距离）。</li><li><strong>适用场景：</strong> 处理像“瑞士卷”这样被卷曲起来的数据集效果很好。</li></ul></li></ul><h3 id="总结：如何选择？-1"><a href="#总结：如何选择？-1" class="headerlink" title="总结：如何选择？"></a><strong>总结：如何选择？</strong></h3><table><thead><tr><th>类别</th><th>算法&#x2F;方法</th><th>核心思想</th><th>优点</th><th>主要应用场景</th></tr></thead><tbody><tr><td><strong>特征选择</strong></td><td><strong>过滤&#x2F;包装&#x2F;嵌入法</strong></td><td>挑选原始特征子集</td><td>可解释性强</td><td>当需要理解哪些原始特征最重要时</td></tr><tr><td><strong>线性提取</strong></td><td><strong>PCA (主成分分析)</strong></td><td>最大化方差</td><td><strong>通用、高效、稳定</strong></td><td><strong>通用的降维首选</strong>，数据去噪</td></tr><tr><td><strong>线性提取</strong></td><td><strong>LDA (线性判别分析)</strong></td><td>最大化类别分离度</td><td>(有监督) 降维后利于分类</td><td>分类任务的预处理</td></tr><tr><td><strong>非线性提取</strong></td><td><strong>t-SNE &#x2F; UMAP</strong></td><td>保持局部邻域结构</td><td><strong>可视化效果极佳</strong></td><td><strong>高维数据可视化</strong>，探索聚类结构</td></tr><tr><td><strong>非线性提取</strong></td><td><strong>Isomap</strong></td><td>保持测地线距离</td><td>能“展开”流形</td><td>学术研究，处理特定流形数据</td></tr></tbody></table><p><strong>一个简单的实践建议：</strong></p><ol><li><strong>不确定用什么？</strong> 从 <strong>PCA</strong> 开始。</li><li><strong>需要很强的可解释性？</strong> 尝试<strong>特征选择</strong>方法（如L1正则化或随机森林特征重要性）。</li><li><strong>主要目标是可视化？</strong> 使用 <strong>UMAP</strong> 或 <strong>t-SNE</strong>。</li><li><strong>怀疑数据有复杂的非线性结构？</strong> 可以探索Isomap等其他流形学习方法。</li></ol><h1 id="5-什么是数据的方差-信息量"><a href="#5-什么是数据的方差-信息量" class="headerlink" title="5.什么是数据的方差&#x2F;信息量"></a>5.什么是数据的方差&#x2F;信息量</h1><p>简单来说，<strong>方差（Variance）</strong> 在这里就是用来衡量您的某一个描述符（特征）在所有14091个材料中，<strong>数值分布的“离散程度”或“差异性大小”</strong>。</p><p>高方差 &#x3D; 差异性大 &#x3D; 信息量丰富 低方差 &#x3D; 差异性小 &#x3D; 信息量贫乏</p><hr><h3 id="让我们用一个具体的描述符来举例"><a href="#让我们用一个具体的描述符来举例" class="headerlink" title="让我们用一个具体的描述符来举例"></a>让我们用一个具体的描述符来举例</h3><p>在您那1559个特征中，我们假设有一个特征叫做 <strong>“密度 (Density)”</strong>。现在，我们只看这一列数据，它包含了14091个不同材料的密度值。</p><ul><li><p><strong>情况一：低方差 (Low Variance)</strong> 假设您计算出的所有14091个材料的密度值都<strong>非常接近</strong>，比如都在 <code>4.5 g/cm³</code> 到 <code>4.6 g/cm³</code> 这个极小的范围内。</p><p>在这种情况下，“密度”这个特征的<strong>方差就非常低</strong>。它告诉我们什么信息呢？它告诉我们，在“密度”这个属性上，您所有的材料都差不多，没什么区别。因此，这个特征对于区分不同材料、或者预测它们的性质，<strong>几乎没有帮助</strong>。它的“信息量”很贫乏。</p></li><li><p><strong>情况二：高方差 (High Variance)</strong> 现在，假设您的14091个材料的密度值<strong>分布得非常广泛</strong>，从很轻的 <code>1.0 g/cm³</code> 到非常重的 <code>22.0 g/cm³</code> 都有。</p><p>在这种情况下，“密度”这个特征的<strong>方差就非常高</strong>。它提供了一个非常有用的信息维度来区分您的材料。一个密度为2的材料和一个密度为20的材料，显然在物理性质上有着天壤之别。因此，这个特征<strong>信息量很丰富</strong>，对于后续的机器学习建模非常有价值。</p></li></ul><h3 id="从单个特征的方差到“总方差”"><a href="#从单个特征的方差到“总方差”" class="headerlink" title="从单个特征的方差到“总方差”"></a>从单个特征的方差到“总方差”</h3><p>现在，请想象一下，您的1559个特征（密度、平均键长、堆积因子、平均电负性…）中的<strong>每一个</strong>，都有自己独立的方差值。</p><ul><li>有些特征（像情况二的密度）方差很高，是很好的“区分器”。</li><li>有些特征（像情况一的密度）方差很低，是“噪音”或者说用处不大的信息。</li></ul><p><strong>总方差 (Total Variance)</strong> 就是把这<strong>所有1559个特征各自的方差简单地加在一起</strong>。 这个“总方差”就代表了您整个数据集在所有维度上<strong>信息量的总和</strong>。这就是我们之前比喻中的“所有原材料的总营养价值”。</p><h3 id="PCA是如何利用“方差”的？"><a href="#PCA是如何利用“方差”的？" class="headerlink" title="PCA是如何利用“方差”的？"></a>PCA是如何利用“方差”的？</h3><p>PCA的聪明之处在于，它不仅仅是看原始的1559个方向（密度、键长等）的方差，而是要在您那个1559维的复杂空间里，<strong>寻找到全新的、最优的方向</strong>。</p><ol><li><strong>主成分1 (PC1)<strong>：PCA找到的第一个新方向（PC1），是所有可能方向中，能让您的14091个数据点投影上去后</strong>分布得最开、差异性最大、方差最高</strong>的那个方向。它捕捉了整个数据集中<strong>最主要的变化来源</strong>。</li><li><strong>主成分2 (PC2)<strong>：在所有与PC1垂直的方向中，PCA找到能让数据投影后方差次高的那个方向。它捕捉了数据中</strong>第二重要的变化来源</strong>。</li><li>…以此类推。</li></ol><p>所以，当我们说“PC1解释了30%的方差”时，我们的意思就是： <strong>“沿着PC1这个新维度观察数据，其离散程度（方差）占到了整个数据集总离散程度（总方差）的30%。”</strong></p><p><strong>总结：</strong> 在您的数据中，“方差”衡量了<strong>一个描述符在区分不同材料方面的能力</strong>。PCA通过寻找数据中方差最大的新方向（主成分），来智能地将最有价值的信息（差异性）浓缩到少数几个维度中，从而实现高效、有意义的降维。</p><h1 id="6-聚类"><a href="#6-聚类" class="headerlink" title="6. 聚类"></a>6. 聚类</h1><p>聚类就是在降维后的高维空间中识别簇并划分</p><h1 id="7-DBSCAN聚类方法"><a href="#7-DBSCAN聚类方法" class="headerlink" title="7. DBSCAN聚类方法"></a>7. DBSCAN聚类方法</h1><p>两个重要参数</p><p>**<code>eps</code><strong>邻域半径社交距离 &#x2F; 一臂之长定义了“邻居”的范围有多大。</strong><code>min_samples</code>**核心点最小样本数形成核心圈子的最少人数定义了“多密集”才算是一个簇的核心。</p><h3 id="K距离图（K-distance-Graph）的含义"><a href="#K距离图（K-distance-Graph）的含义" class="headerlink" title="K距离图（K-distance Graph）的含义"></a>K距离图（K-distance Graph）的含义</h3><p>首先，我们再回顾一下这张图的含义：</p><ul><li><strong>Y轴</strong>：距离值。代表一个点要“走”多远，才能找到它的第 <code>min_samples</code> 个邻居。</li><li><strong>X轴</strong>：数据集中的所有点。为了方便观察，我们把这些点按照Y轴的距离值<strong>从小到大</strong>重新排了序。</li></ul><p>所以，这张图的曲线实际上展示了数据集中所有点的“<strong>局部密度</strong>”分布情况：</p><ul><li><strong>曲线左侧（Y值很低）</strong>：这些点很“幸福”，不用走多远就能找到足够多的邻居。这说明它们身处<strong>人口稠密的市中心（密集区域&#x2F;簇内）</strong>。</li><li><strong>曲线右侧（Y值很高）</strong>：这些点很“孤独”，需要走很远才能找到足够多的邻居。这说明它们身处<strong>人烟稀少的郊区或乡村（稀疏区域&#x2F;噪声）</strong>。</li></ul><h3 id="2-“拐点”（Elbow）的特殊意义"><a href="#2-“拐点”（Elbow）的特殊意义" class="headerlink" title="2. “拐点”（Elbow）的特殊意义"></a>2. “拐点”（Elbow）的特殊意义</h3><p>现在，我们来看“拐点”。</p><p>拐点是曲线上斜率<strong>变化最剧烈</strong>的地方。在这个点：</p><ul><li><strong>拐点之前</strong>：曲线很平缓。这代表了所有“市中心”的居民。虽然大家住的地方有好有坏，但总体上邻里距离都差不多，都比较近。</li><li><strong>拐点之后</strong>：曲线突然变得非常陡峭。这代表了那些“郊区”的居民。他们的邻里距离突然变得非常大。</li></ul><p>因此，这个<strong>拐点</strong>就理所当然地成为了<strong>区分“市中心居民”和“郊区居民”的最佳分界线</strong>。它就像是这个城市的“<strong>天然边界</strong>”。</p><h3 id="3-为什么这个边界就是-eps？"><a href="#3-为什么这个边界就是-eps？" class="headerlink" title="3. 为什么这个边界就是 eps？"></a>3. 为什么这个边界就是 <code>eps</code>？</h3><p>现在我们回到DBSCAN算法的目标：找到由<strong>核心点</strong>组成的簇。</p><p><strong>核心点的定义是</strong>：在 <code>eps</code> 半径内，至少有 <code>min_samples</code> 个邻居。</p><ul><li><strong>如果我们把 <code>eps</code> 设置为拐点的Y轴值</strong>（也就是那个临界距离）：<ul><li>对于所有在<strong>拐点左边</strong>的点，它们找到第 <code>min_samples</code> 个邻居的实际距离都<strong>小于或等于</strong>我们设定的 <code>eps</code>。这意味着，它们都满足成为<strong>核心点</strong>的条件！</li><li>对于所有在<strong>拐点右边</strong>的点，它们找到第 <code>min_samples</code> 个邻居的实际距离都<strong>大于</strong>我们设定的 <code>eps</code>。这意味着，它们无法满足成为核心点的条件，因此它们理应被当作<strong>噪声点</strong>。</li></ul></li></ul><h3 id="总结-4"><a href="#总结-4" class="headerlink" title="总结"></a>总结</h3><p><strong>拐点处的Y值，是那个能够“一刀切”地将大部分核心点和大部分噪声点分开的理想距离阈值。</strong></p><ul><li>选择一个比拐点<strong>低很多</strong>的<code>eps</code>，会导致连很多“市中心”的点都因为邻域太小而被误判为噪声。</li><li>选择一个比拐点<strong>高很多</strong>的<code>eps</code>，会导致把很多“郊区”的噪声点也因为邻域太大而被错误地圈进了城市里。</li></ul><p>因此，拐点是平衡这两者的最佳选择，它代表了我们能容忍的、构成一个“密集区域”的<strong>最大邻居距离</strong>。</p><h1 id="8-PCA与UMAP对比"><a href="#8-PCA与UMAP对比" class="headerlink" title="8. PCA与UMAP对比"></a>8. PCA与UMAP对比</h1><table><thead><tr><th>特性</th><th><strong>PCA (主成分分析)</strong></th><th align="left"><strong>UMAP (均匀流形近似与投影)</strong></th></tr></thead><tbody><tr><td><strong>核心原理</strong></td><td><strong>线性</strong> (Linear)</td><td align="left"><strong>非线性 &#x2F; 流形学习</strong> (Non-linear)</td></tr><tr><td><strong>主要目标</strong></td><td><strong>最大化方差</strong> (Maximize Variance)</td><td align="left"><strong>保持拓扑结构</strong> (Preserve Topology)</td></tr><tr><td></td><td>(保留数据整体的“伸展”方向)</td><td align="left">(保持数据点之间的“邻里关系”)</td></tr><tr><td><strong>关注点</strong></td><td><strong>全局结构</strong> (Global Structure)</td><td align="left"><strong>局部结构</strong>为主，兼顾全局结构</td></tr><tr><td><strong>可解释性</strong></td><td><strong>强</strong> (High)</td><td align="left"><strong>弱</strong> (Low) &#x2F; 黑盒</td></tr><tr><td></td><td>(每个主成分都是原始特征的线性组合)</td><td align="left">(降维后的坐标轴没有直观物理解释)</td></tr><tr><td><strong>计算速度</strong></td><td><strong>非常快</strong> (Very Fast)</td><td align="left"><strong>比PCA慢，但比t-SNE快得多</strong> (Slower)</td></tr><tr><td><strong>主要应用</strong></td><td><strong>数据预处理、去噪、特征工程</strong></td><td align="left"><strong>数据可视化、探索性数据分析</strong></td></tr></tbody></table><h1 id="9-KDBSCAN中的参数"><a href="#9-KDBSCAN中的参数" class="headerlink" title="9. KDBSCAN中的参数"></a>9. KDBSCAN中的参数</h1><p>社交范围和“圈子定义”</p><p><code>DBSCAN</code> 中这两个至关重要的参数：<code>eps</code> 和 <code>min_samples</code>。</p><p><code>DBSCAN</code> 是一种基于<strong>密度</strong>的聚类算法，而这两个参数正是用来定义“密度”的。您可以把它们想象成是在照片中识别“人群”的两个规则。</p><hr><h3 id="一个生动的比喻：寻找派对上的社交圈"><a href="#一个生动的比喻：寻找派对上的社交圈" class="headerlink" title="一个生动的比喻：寻找派对上的社交圈"></a>一个生动的比喻：寻找派对上的社交圈</h3><p>想象一下，您正在分析一张大型派对的俯瞰照片，照片上有很多客人（您的数据点）。您的任务是找出哪些客人形成了<strong>“社交圈”（簇）</strong>，哪些是<strong>“独行者”（噪声点）</strong>。</p><h4 id="1-eps-Epsilon-邻域半径"><a href="#1-eps-Epsilon-邻域半径" class="headerlink" title="1. eps (Epsilon) - 邻域半径"></a>1. <code>eps</code> (Epsilon) - 邻域半径</h4><ul><li><strong>定义</strong>：<code>eps</code> 是一个距离值，它定义了一个点的“邻近”范围。可以把它想象成每个人的<strong>“个人空间”或“社交距离”</strong>。</li><li><strong>作用</strong>：对于任何一个客人，我们以他&#x2F;她为中心，画一个半径为 <code>eps</code> 的圆。所有落在这个圆里的其他客人，都算是他&#x2F;她的“邻居”。</li></ul><p><strong>参数调整的影响：</strong></p><ul><li><strong>增加 <code>eps</code> 值 (例如，从 <code>eps=10</code> 增加到 <code>eps=20</code>)</strong><ul><li><strong>效果</strong>：相当于扩大了每个人的“社交距离”。原来一些距离较远的圈子现在可能会因为彼此的“社交圈”重叠而<strong>合并成一个更大的圈子</strong>。</li><li><strong>结果</strong>：<ul><li>簇的数量会<strong>减少</strong>，但每个簇的规模会<strong>变大</strong>。</li><li>更多的点会被纳入到簇中，被识别为<strong>噪声点的数量会减少</strong>。</li><li><strong>极端情况</strong>：如果 <code>eps</code> 太大，所有点可能会被合并成一个巨大的簇。</li></ul></li></ul></li><li><strong>降低 <code>eps</code> 值 (例如，从 <code>eps=10</code> 降低到 <code>eps=5</code>)</strong><ul><li><strong>效果</strong>：相当于缩小了每个人的“社交距离”，要求大家站得更近才算邻居。</li><li><strong>结果</strong>：<ul><li>一个原本较大的、松散的圈子可能会因为内部不够紧密而<strong>分裂成几个更小的、更紧密的簇</strong>。</li><li>簇的数量可能会<strong>增加</strong>，但每个簇的规模会<strong>变小</strong>。</li><li>由于标准变严，很多点找不到足够多的邻居，被识别为<strong>噪声点的数量会增加</strong>。</li></ul></li></ul></li></ul><h4 id="2-min-samples-核心点最小样本数"><a href="#2-min-samples-核心点最小样本数" class="headerlink" title="2. min_samples - 核心点最小样本数"></a>2. <code>min_samples</code> - 核心点最小样本数</h4><ul><li><strong>定义</strong>：<code>min_samples</code> 是一个整数，它定义了要形成一个“密集区域”（即一个簇的核心）所需要的<strong>最少邻居数量</strong>。</li><li><strong>作用</strong>：一个点如果在他自己的 <code>eps</code> 邻域内（包括他自己）拥有至少 <code>min_samples</code> 个点，那么这个点就被称作<strong>“核心点”</strong>。簇就是由这些核心点以及它们的邻居连接而成的。可以把它理解为“<strong>几个人才能算一个真正的社交圈</strong>”。</li></ul><p><strong>参数调整的影响：</strong></p><ul><li><strong>增加 <code>min_samples</code> 值 (例如，从 <code>min_samples=40</code> 增加到 <code>min_samples=80</code>)</strong><ul><li><strong>效果</strong>：相当于提高了形成“社交圈”的门槛。原来三四十个人就算一个圈子，现在必须凑够八十人才行。</li><li><strong>结果</strong>：<ul><li>只有<strong>密度非常高</strong>的区域才会被识别为簇。</li><li>一些原本被认为是簇的稀疏区域，现在可能会因为“人数”不够而被看作是<strong>噪声</strong>。</li><li><strong>噪声点的数量会增加</strong>。这个参数是控制噪声的主要手段。</li></ul></li></ul></li><li><strong>降低 <code>min_samples</code> 值 (例如，从 <code>min_samples=40</code> 降低到 <code>min_samples=20</code>)</strong><ul><li><strong>效果</strong>：相当于降低了形成“社交圈”的门槛。</li><li><strong>结果</strong>：<ul><li>即使在<strong>密度较低</strong>的区域也可能形成簇。</li><li>簇的数量可能会<strong>增加</strong>。</li><li><strong>噪声点的数量会减少</strong>。</li><li><strong>极端情况</strong>：如果 <code>min_samples</code> 太小（如1或2），几乎所有点都会成为核心点，可能会导致噪声点也被错误地划分进簇中。</li></ul></li></ul></li></ul><hr><h3 id="总结表格"><a href="#总结表格" class="headerlink" title="总结表格"></a>总结表格</h3><table><thead><tr><th>参数</th><th>增加该值的影响</th><th>降低该值的影响</th></tr></thead><tbody><tr><td><strong><code>eps</code></strong> (社交距离)</td><td>簇变大、变少；噪声点变少</td><td>簇变小、变多；噪声点变多</td></tr><tr><td><strong><code>min_samples</code></strong> (成圈人数)</td><td>簇变少、更紧密；噪声点变多</td><td>簇变多、更松散；噪声点变少</td></tr></tbody></table><p>导出到 Google 表格</p><p><strong>您的设置 <code>eps=10, min_samples=40</code> 意味着：</strong> “对于任何一个材料点，如果在10个单位的距离内，总共有至少40个其他材料点，那么这里就形成了一个高密度的核心区域。”</p><p>调整这两个参数通常需要一些实验，通过观察我们之前讨论过的“按簇标签着色的散点图”来判断聚类效果是否符合您的预期。</p><h1 id=""><a href="#" class="headerlink" title=""></a></h1><h1 id="10-UMAP-HDBSCAN-or-PCA-HDBSCAN"><a href="#10-UMAP-HDBSCAN-or-PCA-HDBSCAN" class="headerlink" title="10. UMAP+HDBSCAN or PCA+HDBSCAN"></a>10. UMAP+HDBSCAN or PCA+HDBSCAN</h1><p>对于你当前的数据情况——<strong>10000个样本，1500个维度</strong>——我的建议是：</p><p><strong>优先使用 UMAP + HDBSCAN。</strong></p><p>下面是详细的理由和为你量身定制的操作策略。</p><hr><h3 id="为什么优先选择-UMAP-HDBSCAN？"><a href="#为什么优先选择-UMAP-HDBSCAN？" class="headerlink" title="为什么优先选择 UMAP + HDBSCAN？"></a><strong>为什么优先选择 UMAP + HDBSCAN？</strong></h3><ol><li><strong>高维数据的非线性本质</strong>:<ul><li>在一个高达1500维的空间里，数据点之间的关系极不可能是简单的线性关系。真实世界的高维数据（如图像特征、基因表达、用户行为向量等）几乎总是分布在某个复杂的、扭曲的低维“流形”上。</li><li>PCA是一个<strong>线性</strong>工具，它会试图用“直线”（超平面）来切割和投影数据。这对于捕捉非线性结构是无效的，很可能会将原本分离的簇错误地重叠在一起，从而“污染”数据，让后续的HDBSCAN无法工作。</li><li>UMAP专门为发现这种<strong>非线性</strong>流形结构而设计。它能够“解开”高维空间中缠绕的数据结构，在低维空间中更真实地保留数据点之间的邻近关系。这正是HDBSCAN这种基于密度的聚类算法最需要的信息。</li></ul></li><li><strong>“维度灾难”的完美解药</strong>:<ul><li>在1500维下，任何基于距离的算法（包括HDBSCAN）都会因为“维度灾难”而失效——所有点到其他点的距离都趋向于相等，密度变得没有意义。因此，降维是<strong>必须</strong>的步骤。</li><li>UMAP在降维时，其核心目标就是保留数据的<strong>拓扑结构</strong>（哪些点是邻居，哪些簇是独立的）。这与HDBSCAN的目标（寻找密度相连的区域）完美契合。可以说，UMAP为HDBSCAN创造了最理想的工作环境。</li></ul></li><li><strong>计算性能完全可接受</strong>:<ul><li>你的数据量是10000，这对于现代的UMAP实现来说是完全可以接受的。虽然UMAP会比PCA慢，但在这个数据量级上，计算时间很可能在几分钟之内，而不是几小时或几天。为了获得质量高得多的聚类结果，这点额外的时间开销是非常值得的。</li></ul></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;[toc]&lt;/p&gt;
&lt;h1 id=&quot;1-无监督学习介绍&quot;&gt;&lt;a href=&quot;#1-无监督学习介绍&quot; class=&quot;headerlink&quot; title=&quot;1. 无监督学习介绍&quot;&gt;&lt;/a&gt;1. 无监督学习介绍&lt;/h1&gt;&lt;p&gt;无监督学习（Unsupervised Learning</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>名家集</title>
    <link href="http://example.com/2025/06/03/8-%E6%9D%82%E8%B0%88/%E5%90%8D%E5%AE%B6%E9%9B%86/"/>
    <id>http://example.com/2025/06/03/8-%E6%9D%82%E8%B0%88/%E5%90%8D%E5%AE%B6%E9%9B%86/</id>
    <published>2025-06-03T01:59:13.000Z</published>
    <updated>2025-09-14T07:52:46.161Z</updated>
    
    <content type="html"><![CDATA[<p>[toc]</p><blockquote><p>在此记录一些个人很喜欢的人物，会给出喜欢的理由和他们的生平介绍</p></blockquote><h1 id="1-路德维希·玻尔兹曼"><a href="#1-路德维希·玻尔兹曼" class="headerlink" title="1. 路德维希·玻尔兹曼"></a>1. 路德维希·玻尔兹曼</h1><img src="./../../图片/ludwig-boltzmann-portrait.jpeg" alt="ludwig-boltzmann-portrait" style="zoom: 33%;" /><p>* </p><h1 id="2-薛定谔"><a href="#2-薛定谔" class="headerlink" title="2. 薛定谔"></a>2. 薛定谔</h1><h1 id="3-朱自清"><a href="#3-朱自清" class="headerlink" title="3. 朱自清"></a>3. 朱自清</h1><h1 id="4-史铁生"><a href="#4-史铁生" class="headerlink" title="4. 史铁生"></a>4. 史铁生</h1><h1 id="5-王安石"><a href="#5-王安石" class="headerlink" title="5. 王安石"></a>5. 王安石</h1><h1 id="6-笛卡尔"><a href="#6-笛卡尔" class="headerlink" title="6. 笛卡尔"></a>6. 笛卡尔</h1><h1 id="7-刘慈欣"><a href="#7-刘慈欣" class="headerlink" title="7. 刘慈欣"></a>7. 刘慈欣</h1><h1 id="8-王立群"><a href="#8-王立群" class="headerlink" title="8. 王立群"></a>8. 王立群</h1><h1 id="9-李白"><a href="#9-李白" class="headerlink" title="9. 李白"></a>9. 李白</h1>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;[toc]&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;在此记录一些个人很喜欢的人物，会给出喜欢的理由和他们的生平介绍&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;1-路德维希·玻尔兹曼&quot;&gt;&lt;a href=&quot;#1-路德维希·玻尔兹曼&quot; class=&quot;headerlink</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>编译ACNN</title>
    <link href="http://example.com/2025/05/27/4-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BC%96%E8%AF%91ACNN/"/>
    <id>http://example.com/2025/05/27/4-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BC%96%E8%AF%91ACNN/</id>
    <published>2025-05-27T01:30:30.000Z</published>
    <updated>2025-05-27T02:51:21.817Z</updated>
    
    <content type="html"><![CDATA[<p>[toc]</p><h1 id="1-编译可使用ACNN势的lammps"><a href="#1-编译可使用ACNN势的lammps" class="headerlink" title="1. 编译可使用ACNN势的lammps"></a>1. 编译可使用ACNN势的lammps</h1><p>需要注意的点</p><ul><li><p>修改torchdemo-v3 里的prefix.cmake  修改里面openblas 和 torch的位置 </p></li><li><p>需要使用oneapi 来编译，因为需要用到mkl库</p><p>可以检查mpicxx -show  如果输出是icx 说明使用的是oneapi的编译器，如果输出是g++ ，说明使用的是openmpi </p></li><li><p>在interface 处sh bulid**.sh build</p></li><li><p>编译完成后，需要给出torch 和openblas的库文件位置以及source onempi 才能运行程序</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;[toc]&lt;/p&gt;
&lt;h1 id=&quot;1-编译可使用ACNN势的lammps&quot;&gt;&lt;a href=&quot;#1-编译可使用ACNN势的lammps&quot; class=&quot;headerlink&quot; title=&quot;1. 编译可使用ACNN势的lammps&quot;&gt;&lt;/a&gt;1. 编译可使用ACNN势的l</summary>
      
    
    
    
    <category term="机器学习" scheme="http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>关于毕业论文</title>
    <link href="http://example.com/2025/04/16/7-%E7%BB%98%E5%9B%BE%E4%B8%8E%E5%86%99%E4%BD%9C/%E5%85%B3%E4%BA%8E%E6%AF%95%E4%B8%9A%E8%AE%BA%E6%96%87/"/>
    <id>http://example.com/2025/04/16/7-%E7%BB%98%E5%9B%BE%E4%B8%8E%E5%86%99%E4%BD%9C/%E5%85%B3%E4%BA%8E%E6%AF%95%E4%B8%9A%E8%AE%BA%E6%96%87/</id>
    <published>2025-04-16T02:29:27.000Z</published>
    <updated>2025-04-16T02:31:18.847Z</updated>
    
    <content type="html"><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="Oh, this is an invalid password. Check and try again, please." data-whm="OOPS, these decrypted content may changed, but you can still have a look.">  <script id="hbeData" type="hbeData" data-hmacdigest="7c58f0a92fde60daf05aba79a36e05f0c00f433dd94983028d4c854f52c970dd">bda6ad0d5f606e7055c23f770369041ffa354e2b32a3834b155272c56f6444661ab7718603343a34c88aae20fc7454471ea25f2bf446205a6e0c3c512e3382d18684d1f39ffc2160101eedf9a9c1921c79e3b7f060e42f52505d7d4e245ac3e6440f5a6ac673744685875d76ad8b4041fb07f439ebb53b4250a386e8095159a4d3eaa727dce331e57c44488365c30ba2e7a3705f8e9e1fb2ccbacec4142ea887959eb02cce5283888538a79bd2d02848f1a740d1534328195c68896a1fd2a8959218e2098feb26048954fdacf02fcbcb4d74c15bc8c8e4cf5638dea23fac0f9d2e6be258dd267d6bcd526169157aa91c77b104fbf43ffe17972d70440383707e20bcaafc79c8d98de715601d29c6ef639b50f20abb33617db6043cbb76c8ef3e90ce4863c9372f9f922c755754a68de862510510be655855ca307c709032f18f031a57decac413adbae060843b60d1b30aae3b443541f50def21ce5ff6abf6b4c27445dd01c92136912cb450c869c0b5</script>  <div class="hbe hbe-content">    <div class="hbe hbe-input hbe-input-default">      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">        <span class="hbe hbe-input-label-content hbe-input-label-content-default">Hey, password is required here.</span>      </label>    </div>  </div></div><script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
    
    
    <summary type="html">Here&#39;s something encrypted, password is required to continue reading.</summary>
    
    
    
    <category term="绘图与写作" scheme="http://example.com/categories/%E7%BB%98%E5%9B%BE%E4%B8%8E%E5%86%99%E4%BD%9C/"/>
    
    
  </entry>
  
  <entry>
    <title>vasp中的分子动力学系综</title>
    <link href="http://example.com/2025/04/14/3-%E5%88%86%E5%AD%90%E5%8A%A8%E5%8A%9B%E5%AD%A6/vasp%E6%A8%A1%E6%8B%9F/vasp%E4%B8%AD%E7%9A%84%E5%88%86%E5%AD%90%E5%8A%A8%E5%8A%9B%E5%AD%A6%E7%B3%BB%E7%BB%BC/"/>
    <id>http://example.com/2025/04/14/3-%E5%88%86%E5%AD%90%E5%8A%A8%E5%8A%9B%E5%AD%A6/vasp%E6%A8%A1%E6%8B%9F/vasp%E4%B8%AD%E7%9A%84%E5%88%86%E5%AD%90%E5%8A%A8%E5%8A%9B%E5%AD%A6%E7%B3%BB%E7%BB%BC/</id>
    <published>2025-04-14T01:17:38.000Z</published>
    <updated>2025-06-17T07:42:07.002Z</updated>
    
    <content type="html"><![CDATA[<p>[toc]</p><h1 id="1-关于NPT系综"><a href="#1-关于NPT系综" class="headerlink" title="1.关于NPT系综"></a>1.关于NPT系综</h1><p>NPT系综中需要设置压力PSTRESS，在OUTCAR中，搜索关键词pressure会出现三个值</p><p><img src="/./../../../%E5%9B%BE%E7%89%87/image-20250414092020654.png" alt="image-20250414092020654"></p><p>其中，<code>in kB</code>行是压力矩阵的元素，前三个是主对角元元素，后面三个是非对角元元素</p><p>Pullay stress 是设置的PSTRESS的值，也就是外部压力（pstress)</p><p>external pressure是in kB行三个主对角元素平均值和Pullay stress的差值，对应于压力的波动量，这是结构的压力。</p><p><strong>由于有动能压力，导致内部会有一个内应力，动能压力总是正的，内应力也就是负数，对应于使得体积膨胀</strong></p><p>kinetic pressure 动能也会有一个压力，total pressure是最终的总压力，检查NPT是否平衡，计算这个值随步数的波动情况就可以</p><p>当有温度时，kinetic pressure不为0 ，且温度越高，kinetic pressure越大，external pressrure的值倾向于保持为负的kinetic pressure，这样，保持total pressure &#x3D; pullay stress，也就会导致热膨胀的出现</p><p><strong>不同的计算精度（ENCUT和KPOINTS对同一个结构计算的external pressure不同，尤其是对于大体系来说ENCUT, 如果要计算NPT来得到热膨胀效应，就必须要用相同的参数，不然可能会出现没有热膨胀，反而在设置的温度下体积相比结构优化的0 K下降的现象</strong></p><p>提取pressure的值</p><pre><code class="sh">grep &#39;total pressure&#39; OUTCAR | awk &#39;&#123;print NR, $4&#125;&#39; &gt; pressure.dat</code></pre><pre><code class="python">import numpy as npimport matplotlib.pyplot as pltimport matplotlibmatplotlib.use(&#39;Agg&#39;)import argparse parser = argparse.ArgumentParser(description=&#39;deal two column data&#39;)parser.add_argument(&#39;filename&#39;)parser.add_argument(&#39;xlabel&#39;)parser.add_argument(&#39;ylabel&#39;)args = parser.parse_args()data_txt = args.filenamex_label = args.xlabely_label = args.ylabel# print(&#39;=&#39;*40)# filename = input(&#39;请输入文件名：&#39;).strip()# x_label = input(&quot;请输入x轴标签（直接回车可跳过）: &quot;).strip()# y_label = input(&quot;请输入y轴标签（直接回车可跳过）: &quot;).strip()# print(&quot;=&quot;*40)# data_txt = filename# x_label = x_label# y_label = y_labeldata = np.loadtxt(data_txt)plt.rcParams[&#39;font.size&#39;] = 16plt.rcParams[&#39;axes.linewidth&#39;] = 2plt.rcParams[&#39;axes.titlesize&#39;] = 16plt.rcParams[&#39;axes.labelsize&#39;] = 20plt.rcParams[&#39;axes.labelweight&#39;] = &#39;bold&#39;plt.rcParams[&#39;xtick.labelsize&#39;] = 16plt.rcParams[&#39;ytick.labelsize&#39;] = 16plt.rcParams[&#39;legend.fontsize&#39;] = 16figure = plt.figure(figsize=(8,6),dpi = 300)grid = figure.add_gridspec(1,1)ax1 = figure.add_subplot(grid[0,0])x = data[:,0]y = data[:,1]ax1.plot(x,y,linewidth=1.8)plt.xlabel(x_label)plt.ylabel(y_label)plt.xticks(fontweight = &#39;bold&#39;)plt.yticks(fontweight = &#39;bold&#39;)plt.legend(prop = &#123;&#39;weight&#39; :&#39;bold&#39;&#125;)plt.tight_layout()plt.savefig(&#39;plot.png&#39;,dpi = 300)</code></pre><h1 id="2-关于NVE系综"><a href="#2-关于NVE系综" class="headerlink" title="2. 关于NVE系综"></a>2. 关于NVE系综</h1><p>NVE系综是最简单的系综，只根据牛顿定律进行动力学演化，没有热浴和控压器的影响。NVT就是在NVE的基础上加一个控温器。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;[toc]&lt;/p&gt;
&lt;h1 id=&quot;1-关于NPT系综&quot;&gt;&lt;a href=&quot;#1-关于NPT系综&quot; class=&quot;headerlink&quot; title=&quot;1.关于NPT系综&quot;&gt;&lt;/a&gt;1.关于NPT系综&lt;/h1&gt;&lt;p&gt;NPT系综中需要设置压力PSTRESS，在OUTCAR中，</summary>
      
    
    
    
    <category term="分子动力学" scheme="http://example.com/categories/%E5%88%86%E5%AD%90%E5%8A%A8%E5%8A%9B%E5%AD%A6/"/>
    
    <category term="vasp模拟" scheme="http://example.com/categories/%E5%88%86%E5%AD%90%E5%8A%A8%E5%8A%9B%E5%AD%A6/vasp%E6%A8%A1%E6%8B%9F/"/>
    
    
  </entry>
  
  <entry>
    <title>vscode快捷键</title>
    <link href="http://example.com/2025/04/09/5-linux%E5%AD%A6%E4%B9%A0%E4%BD%BF%E7%94%A8/vscode%E5%BF%AB%E6%8D%B7%E9%94%AE/"/>
    <id>http://example.com/2025/04/09/5-linux%E5%AD%A6%E4%B9%A0%E4%BD%BF%E7%94%A8/vscode%E5%BF%AB%E6%8D%B7%E9%94%AE/</id>
    <published>2025-04-09T12:47:00.000Z</published>
    <updated>2025-04-09T12:49:28.919Z</updated>
    
    <content type="html"><![CDATA[<p>[toc]</p><ul><li>关闭文件 ctrl +w</li><li>打开终端 ctrl + &#96;</li><li>关闭终端 ctrl +&#96;</li><li>转换终端ctrl + pagedown&#x2F;pageup</li><li>新建终端 ctrl + shift  + &#96;</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;[toc]&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;关闭文件 ctrl +w&lt;/li&gt;
&lt;li&gt;打开终端 ctrl + &amp;#96;&lt;/li&gt;
&lt;li&gt;关闭终端 ctrl +&amp;#96;&lt;/li&gt;
&lt;li&gt;转换终端ctrl + pagedown&amp;#x2F;pageup&lt;/li&gt;
&lt;li&gt;新建</summary>
      
    
    
    
    <category term="linux学习使用" scheme="http://example.com/categories/linux%E5%AD%A6%E4%B9%A0%E4%BD%BF%E7%94%A8/"/>
    
    
  </entry>
  
  <entry>
    <title>python绘图图案规范</title>
    <link href="http://example.com/2025/04/07/7-%E7%BB%98%E5%9B%BE%E4%B8%8E%E5%86%99%E4%BD%9C/python%E7%BB%98%E5%9B%BE%E5%9B%BE%E6%A1%88%E8%A7%84%E8%8C%83/"/>
    <id>http://example.com/2025/04/07/7-%E7%BB%98%E5%9B%BE%E4%B8%8E%E5%86%99%E4%BD%9C/python%E7%BB%98%E5%9B%BE%E5%9B%BE%E6%A1%88%E8%A7%84%E8%8C%83/</id>
    <published>2025-04-07T01:12:00.000Z</published>
    <updated>2025-09-16T02:33:16.224Z</updated>
    
    <content type="html"><![CDATA[<p>[toc]</p><h1 id="1-一行一列图"><a href="#1-一行一列图" class="headerlink" title="1. 一行一列图"></a>1. 一行一列图</h1><pre><code class="python">import numpy as npimport matplotlib.pyplot as pltimport matplotlib.font_manager as fmfont_path = &#39;/usr/share/fonts/truetype/msttcorefonts/Times_New_Roman.ttf&#39;fm.fontManager.addfont(font_path)plt.rcParams[&#39;font.family&#39;] = &#39;Times New Roman&#39;plt.rcParams[&#39;axes.linewidth&#39;] = 4fig = plt.figure(figsize=(8,8),dpi = 300)grid = fig.add_gridspec(1,1)ax = fig.add_subplot(grid[0,0])data1 = np.loadtxt(&#39;li_energy.dat&#39;)sort_indices = np.argsort(data1[:, 0])data1 = data1[sort_indices]data2 = np.loadtxt(&#39;na_energy.dat&#39;)sort_indices = np.argsort(data2[:, 0])data2 = data2[sort_indices]data3 = np.loadtxt(&#39;k_energy.dat&#39;)sort_indices = np.argsort(data3[:, 0])data3 = data3[sort_indices]x = np.sort(data2[:,0])y1 = data1[:,1]y2 = data2[:,1]y3 = data3[:,1]y1_lowest = y1.min()y1_minus = y1 - y1_lowesty1_per_atom = y1_minus/ 132 * 1000y1_per_atom_pad = np.pad(y1_per_atom,(0,x.shape[0] - len(y1_per_atom)),&#39;constant&#39;,constant_values = np.nan)y2_lowest = y2.min()y2_minus = y2 - y2_lowesty2_per_atom = y2_minus/ 132 * 1000y2_per_atom_pad = np.pad(y2_per_atom,(0,x.shape[0] - len(y2_per_atom)),&#39;constant&#39;,constant_values = np.nan)y3_lowest = y3.min()y3_minus = y3 - y3_lowesty3_per_atom = y3_minus/ 132 * 1000y3_per_atom_pad = np.pad(y3_per_atom,(0,x.shape[0] - len(y3_per_atom)),&#39;constant&#39;,constant_values = np.nan)x = np.arange(1,21,1)ax.plot(x,y1_per_atom_pad[0:20],label=&#39;Li&#39;)ax.scatter(x,y1_per_atom_pad[0:20])ax.plot(x,y2_per_atom_pad[0:20],label=&#39;Na&#39;)ax.scatter(x,y2_per_atom_pad[0:20])ax.plot(x,y3_per_atom_pad[0:20],label=&#39;K&#39;)ax.scatter(x,y3_per_atom_pad[0:20])ax.set_ylabel(&#39;Energy relative the lowest energy per atom (meV)&#39;, fontsize = 35,fontname=&#39;Times New Roman&#39;,fontweight=&quot;bold&quot;)plt.xticks(fontsize = 30,fontname = &quot;Times New Roman&quot;,fontweight = &quot;bold&quot;)plt.yticks(fontsize = 30,fontname = &quot;Times New Roman&quot;,fontweight = &quot;bold&quot;)plt.legend(prop=&#123;&#39;family&#39;: &#39;Times New Roman&#39;, &#39;weight&#39;: &#39;bold&#39;, &#39;size&#39;: 25&#125;)plt.gca().xaxis.set_major_locator(plt.MaxNLocator(4))plt.savefig(&#39;plot.png&#39;,dpi = 1000)plt.show()</code></pre><h1 id="2-一行两列图"><a href="#2-一行两列图" class="headerlink" title="2. 一行两列图"></a>2. 一行两列图</h1><pre><code class="python">import matplotlib.pyplot as pltplt.rcParams[&#39;font.family&#39;] = &#39;Times New Roman&#39;plt.rcParams[&#39;font.size&#39;] = 12plt.rcParams[&#39;axes.titlesize&#39;] = 16plt.rcParams[&#39;axes.labelsize&#39;] = 14plt.rcParams[&#39;xtick.labelsize&#39;] = 12plt.rcParams[&#39;ytick.labelsize&#39;] = 12plt.rcParams[&#39;legend.fontsize&#39;] = 12plt.rcParams[&#39;axes.linewidth&#39;] = 1.5fig, axs = plt.subplots(1, 2, figsize=(12, 5), dpi=300)for ax in axs:    ax.plot([1,2,3], [4,5,6], linewidth=1.8, marker=&#39;o&#39;, markersize=7)    ax.set_xlabel(&quot;X轴&quot;, fontsize=14)    ax.set_ylabel(&quot;Y轴&quot;, fontsize=14)    ax.legend([&quot;数据&quot;], frameon=True)plt.tight_layout()plt.savefig(&#39;figure.png&#39;,dpi=600)plt.savefig(&#39;figure.pdf&#39;,dpi=600)plt.show()</code></pre><h1 id="3-两行两列图"><a href="#3-两行两列图" class="headerlink" title="3. 两行两列图"></a>3. 两行两列图</h1><pre><code class="python">import matplotlib.pyplot as pltplt.rcParams[&#39;font.family&#39;] = &#39;Times New Roman&#39;plt.rcParams[&#39;font.size&#39;] = 12plt.rcParams[&#39;axes.titlesize&#39;] = 16plt.rcParams[&#39;axes.labelsize&#39;] = 14plt.rcParams[&#39;xtick.labelsize&#39;] = 12plt.rcParams[&#39;ytick.labelsize&#39;] = 12plt.rcParams[&#39;legend.fontsize&#39;] = 12plt.rcParams[&#39;axes.linewidth&#39;] = 1.5fig, axs = plt.subplots(2, 2, figsize=(10, 8), dpi=300)for ax in axs.flat:    ax.plot([1,2,3], [4,5,6], linewidth=1.8, marker=&#39;o&#39;, markersize=7)    ax.set_xlabel(&quot;X轴&quot;, fontsize=14)    ax.set_ylabel(&quot;Y轴&quot;, fontsize=14)    ax.legend([&quot;数据&quot;], frameon=True)plt.tight_layout()plt.show()</code></pre><h1 id="4-处理-1-2数据"><a href="#4-处理-1-2数据" class="headerlink" title="4. 处理 1*2数据"></a>4. 处理 1*2数据</h1><pre><code class="python">import numpy as npimport matplotlib.pyplot as pltimport matplotlibmatplotlib.use(&#39;Agg&#39;)import argparse parser = argparse.ArgumentParser(description=&#39;deal two column data&#39;)parser.add_argument(&#39;filename&#39;)parser.add_argument(&#39;xlabel&#39;)parser.add_argument(&#39;ylabel&#39;)args = parser.parse_args()data_txt = args.filenamex_label = args.xlabely_label = args.ylabel# print(&#39;=&#39;*40)# filename = input(&#39;请输入文件名：&#39;).strip()# x_label = input(&quot;请输入x轴标签（直接回车可跳过）: &quot;).strip()# y_label = input(&quot;请输入y轴标签（直接回车可跳过）: &quot;).strip()# print(&quot;=&quot;*40)# data_txt = filename# x_label = x_label# y_label = y_labeldata = np.loadtxt(data_txt)plt.rcParams[&#39;font.size&#39;] = 16plt.rcParams[&#39;axes.linewidth&#39;] = 2plt.rcParams[&#39;axes.titlesize&#39;] = 16plt.rcParams[&#39;axes.labelsize&#39;] = 20plt.rcParams[&#39;axes.labelweight&#39;] = &#39;bold&#39;plt.rcParams[&#39;xtick.labelsize&#39;] = 16plt.rcParams[&#39;ytick.labelsize&#39;] = 16plt.rcParams[&#39;legend.fontsize&#39;] = 16figure = plt.figure(figsize=(8,6),dpi = 300)grid = figure.add_gridspec(1,1)ax1 = figure.add_subplot(grid[0,0])x = data[:,0]y = data[:,1]ax1.plot(x,y,linewidth=1.8)plt.xlabel(x_label)plt.ylabel(y_label)plt.xticks(fontweight = &#39;bold&#39;)plt.yticks(fontweight = &#39;bold&#39;)plt.legend(prop = &#123;&#39;weight&#39; :&#39;bold&#39;&#125;)plt.tight_layout()plt.savefig(&#39;plot.png&#39;,dpi = 300)</code></pre><h1 id="5-大成版"><a href="#5-大成版" class="headerlink" title="5. 大成版"></a>5. 大成版</h1><pre><code class="python">import numpy as npimport osimport matplotlib.pyplot as pltfrom matplotlib import cmimport matplotlib.font_manager as fmfont_path = &#39;/usr/share/fonts/truetype/msttcorefonts/Times_New_Roman.ttf&#39;font_path_bold = &#39;/usr/share/fonts/truetype/msttcorefonts/Times_New_Roman_Bold.ttf&#39;fm.fontManager.addfont(font_path)fm.fontManager.addfont(font_path_bold)plt.rcParams[&#39;font.family&#39;] = &#39;Times New Roman&#39;plt.rcParams[&#39;axes.linewidth&#39;] = 4font_bold_prop = fm.FontProperties(family=&#39;Times New Roman&#39;, weight=&#39;bold&#39;)plt.rcParams.update(&#123;    &#39;mathtext.fontset&#39;: &#39;custom&#39;,    &#39;mathtext.rm&#39;: &#39;Times New Roman&#39;,    &#39;mathtext.bf&#39;: &#39;Times New Roman:bold&#39;,    &#39;font.family&#39;: &#39;Times New Roman&#39;,    &#39;font.weight&#39;: &#39;bold&#39;,    &#39;axes.labelweight&#39;: &#39;bold&#39;, &#125;)data = np.loadtxt(&#39;&#39;)x = data[:,0]y_data = data[:,1]fig = plt.figure(figsize=(8, 8),dpi=1000)fig.subplots_adjust(left=0.2, right=0.8, top=0.8, bottom=0.2)grid = fig.add_gridspec(1,1)ax = fig.add_subplot(grid[0,0])ax.plot(x, y_data,color=color, linewidth=4)    # ax.legend(#     # loc=&#39;center&#39;,#     # bbox_to_anchor=(0.8, 0.17),#     framealpha=1,#     labelspacing=0.3,#     prop=&#123;&#39;family&#39;: &#39;Times New Roman&#39;, &#39;size&#39;:18,&#39;weight&#39;: &#39;bold&#39;&#125;# )ax.tick_params(        axis=&#39;x&#39;,        which=&#39;both&#39;,        top=False,        bottom = True,        labelbottom = True,        labeltop=False,          width=2    )ax.tick_params(        axis=&#39;y&#39;,        which=&#39;both&#39;,        right=False,        left = True,        labelright=False,        labelleft = True,        width=2    )ax.set_xlim(0,200)ax.set_ylim(0,None)ax.set_xlabel(&#39;Time (ps)&#39;,fontsize = 35,fontname=&#39;Times New Roman&#39;,fontweight=&quot;bold&quot;)ax.set_ylabel(r&#39;MSD ($\mathrm&#123;\AA&#125;^2$)&#39;,fontsize = 35,fontname=&#39;Times New Roman&#39;,fontweight=&quot;bold&quot;)plt.xticks(fontsize = 30,fontname = &quot;Times New Roman&quot;,fontweight = &quot;bold&quot;)plt.yticks(fontsize = 30,fontname = &quot;Times New Roman&quot;,fontweight = &quot;bold&quot;)# plt.legend(prop=&#123;&#39;family&#39;: &#39;Times New Roman&#39;, &#39;weight&#39;: &#39;bold&#39;, &#39;size&#39;: 20&#125;)plt.gca().xaxis.set_major_locator(plt.MaxNLocator(4))plt.gca().yaxis.set_major_locator(plt.MaxNLocator(5))#plt.gca().spines[&#39;top&#39;].set_linewidth(4)#plt.gca().spines[&#39;right&#39;].set_linewidth(4)#plt.gca().spines[&#39;bottom&#39;].set_linewidth(4)#plt.gca().spines[&#39;left&#39;].set_linewidth(4)plt.savefig(&#39;msd.png&#39;,dpi=1000)</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;[toc]&lt;/p&gt;
&lt;h1 id=&quot;1-一行一列图&quot;&gt;&lt;a href=&quot;#1-一行一列图&quot; class=&quot;headerlink&quot; title=&quot;1. 一行一列图&quot;&gt;&lt;/a&gt;1. 一行一列图&lt;/h1&gt;&lt;pre&gt;&lt;code class=&quot;python&quot;&gt;import numpy</summary>
      
    
    
    
    <category term="绘图与写作" scheme="http://example.com/categories/%E7%BB%98%E5%9B%BE%E4%B8%8E%E5%86%99%E4%BD%9C/"/>
    
    
  </entry>
  
  <entry>
    <title>bader电荷分析</title>
    <link href="http://example.com/2025/02/17/2-%E6%A8%A1%E6%8B%9F%E6%96%B9%E6%B3%95/bader%E7%94%B5%E8%8D%B7%E5%88%86%E6%9E%90/"/>
    <id>http://example.com/2025/02/17/2-%E6%A8%A1%E6%8B%9F%E6%96%B9%E6%B3%95/bader%E7%94%B5%E8%8D%B7%E5%88%86%E6%9E%90/</id>
    <published>2025-02-17T06:21:06.000Z</published>
    <updated>2025-02-17T06:59:41.382Z</updated>
    
    <content type="html"><![CDATA[<p>[toc]</p><p><a href="https://theory.cm.utexas.edu/henkelman/code/bader/">https://theory.cm.utexas.edu/henkelman/code/bader/</a></p><p>VASP从入门到入土：Bader电荷的计算 - 知乎<br><a href="https://zhuanlan.zhihu.com/p/673557738">https://zhuanlan.zhihu.com/p/673557738</a></p><p><code> LAECHG=.TRUE.</code></p><pre><code class="shell"> chgsum.pl AECCAR0 AECCAR2 bader CHGCAR -ref CHGCAR_sum</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;[toc]&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://theory.cm.utexas.edu/henkelman/code/bader/&quot;&gt;https://theory.cm.utexas.edu/henkelman/code/bader/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;V</summary>
      
    
    
    
    <category term="模拟方法" scheme="http://example.com/categories/%E6%A8%A1%E6%8B%9F%E6%96%B9%E6%B3%95/"/>
    
    
  </entry>
  
  <entry>
    <title>mattersim-x</title>
    <link href="http://example.com/2025/02/14/7-%E7%BB%98%E5%9B%BE%E4%B8%8E%E5%86%99%E4%BD%9C/mattersim-x/"/>
    <id>http://example.com/2025/02/14/7-%E7%BB%98%E5%9B%BE%E4%B8%8E%E5%86%99%E4%BD%9C/mattersim-x/</id>
    <published>2025-02-14T05:55:22.000Z</published>
    <updated>2025-02-14T07:34:03.090Z</updated>
    
    <content type="html"><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="Oh, this is an invalid password. Check and try again, please." data-whm="OOPS, these decrypted content may changed, but you can still have a look.">  <script id="hbeData" type="hbeData" data-hmacdigest="251d28366651491a34ed14522ea40a4a246c7bec4c14851fc77911100d4a6db5">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</script>  <div class="hbe hbe-content">    <div class="hbe hbe-input hbe-input-default">      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">        <span class="hbe hbe-input-label-content hbe-input-label-content-default">Hey, password is required here.</span>      </label>    </div>  </div></div><script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
    
    
    <summary type="html">Here&#39;s something encrypted, password is required to continue reading.</summary>
    
    
    
    <category term="绘图与写作" scheme="http://example.com/categories/%E7%BB%98%E5%9B%BE%E4%B8%8E%E5%86%99%E4%BD%9C/"/>
    
    
  </entry>
  
  <entry>
    <title>功函数计算</title>
    <link href="http://example.com/2025/02/11/2-%E6%A8%A1%E6%8B%9F%E6%96%B9%E6%B3%95/%E5%8A%9F%E5%87%BD%E6%95%B0%E8%AE%A1%E7%AE%97/"/>
    <id>http://example.com/2025/02/11/2-%E6%A8%A1%E6%8B%9F%E6%96%B9%E6%B3%95/%E5%8A%9F%E5%87%BD%E6%95%B0%E8%AE%A1%E7%AE%97/</id>
    <published>2025-02-11T03:18:17.000Z</published>
    <updated>2025-02-11T06:59:46.385Z</updated>
    
    <content type="html"><![CDATA[<p>[toc]</p><h1 id="1-参考vaspkit的Au111表面功函数计算"><a href="#1-参考vaspkit的Au111表面功函数计算" class="headerlink" title="1. 参考vaspkit的Au111表面功函数计算"></a>1. 参考vaspkit的Au111表面功函数计算</h1><blockquote><p><a href="https://vaspkit.com/tutorials.html#potential-related">https://vaspkit.com/tutorials.html#potential-related</a></p><p><a href="http://bbs.keinsci.com/thread-27563-1-1.html">http://bbs.keinsci.com/thread-27563-1-1.html</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;[toc]&lt;/p&gt;
&lt;h1 id=&quot;1-参考vaspkit的Au111表面功函数计算&quot;&gt;&lt;a href=&quot;#1-参考vaspkit的Au111表面功函数计算&quot; class=&quot;headerlink&quot; title=&quot;1. 参考vaspkit的Au111表面功函数计算&quot;&gt;&lt;/a&gt;</summary>
      
    
    
    
    <category term="模拟方法" scheme="http://example.com/categories/%E6%A8%A1%E6%8B%9F%E6%96%B9%E6%B3%95/"/>
    
    
  </entry>
  
  <entry>
    <title>大模型</title>
    <link href="http://example.com/2025/01/21/4-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B/"/>
    <id>http://example.com/2025/01/21/4-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B/</id>
    <published>2025-01-21T13:22:55.000Z</published>
    <updated>2025-06-16T12:41:21.611Z</updated>
    
    <content type="html"><![CDATA[<p>[toc]</p><h1 id="1-原子大模型排名"><a href="#1-原子大模型排名" class="headerlink" title="1. 原子大模型排名"></a>1. 原子大模型排名</h1><p><a href="https://matbench-discovery.materialsproject.org/">https://matbench-discovery.materialsproject.org/</a></p><h1 id="2-使用ASE结合mattersim进行结构优化、分子动力学"><a href="#2-使用ASE结合mattersim进行结构优化、分子动力学" class="headerlink" title="2. 使用ASE结合mattersim进行结构优化、分子动力学"></a>2. 使用ASE结合mattersim进行结构优化、分子动力学</h1><h2 id="1-使用ASE进行包括晶胞的结构优化"><a href="#1-使用ASE进行包括晶胞的结构优化" class="headerlink" title="1. 使用ASE进行包括晶胞的结构优化"></a>1. 使用ASE进行包括晶胞的结构优化</h2><pre><code class="python">from mattersim.applications.moldyn import MolecularDynamicsfrom ase.io import read, writefrom mattersim.forcefield import MatterSimCalculatorfrom mattersim.applications.relax import Relaxerimport numpy as npfrom ase.optimize import LBFGSfrom ase.filters import ExpCellFilterfrom ase.io import Trajectory# calc = MatterSimCalculator(device=&#39;cuda&#39;)# calc = MatterSimCalculator(device=&#39;cuda:0&#39;)calc = MatterSimCalculator(load_path=&quot;MatterSim-v1.0.0-5M.pth&quot;, device=&#39;cuda:0&#39;)#relaxer = Relaxer(#    optimizer=&quot;BFGS&quot;, # the optimization method FIRE, BFGS#    filter=None, # filter to apply to the cell#    constrain_symmetry=True, # whether to constrain the symmetry#)atoms = read(&quot;POSCAR&quot;,format=&#39;vasp&#39;)atoms.calc = calcecf = ExpCellFilter(atoms)traj = Trajectory(&#39;optimization.traj&#39;, &#39;w&#39;, atoms)#converged, relaxed_structure = relaxer.relax_structures(atoms,optimizer=&quot;BFGS&quot;, # the optimization method FIRE, BFGS#    filter=None, #    constrain_symmetry=True, fmax=0.01 )opt = LBFGS(ecf)opt.attach(traj.write, interval=1)opt.run(fmax=0.01) write(&quot;POSCAR.vasp&quot;, atoms, format=&quot;vasp&quot;)</code></pre><h2 id="2-from-wangq"><a href="#2-from-wangq" class="headerlink" title="2. from wangq"></a>2. from wangq</h2><pre><code class="python">from mattersim.applications.moldyn import MolecularDynamicsfrom ase.io import read, writefrom mattersim.forcefield import MatterSimCalculatorfrom mattersim.applications.relax import Relaxerimport numpy as np# calc = MatterSimCalculator(device=&#39;cuda&#39;)calc = MatterSimCalculator(load_path=&quot;MatterSim-v1.0.0-5M.pth&quot;, device=&#39;cuda:2&#39;)#默认是1M参数大模型，下面的是5M的relaxer = Relaxer(    optimizer=&quot;BFGS&quot;, # the optimization method FIRE, BFGS    filter=None, # filter to apply to the cell    constrain_symmetry=True, # whether to constrain the symmetry)atoms = read(&quot;SPOSCAR&quot;,format=&#39;vasp&#39;)atoms.calc = calcconverged, relaxed_structure = relaxer.relax_structures(atoms,optimizer=&quot;FIRE&quot;, # the optimization method FIRE, BFGS    filter=None,     constrain_symmetry=True, fmax=0.1 )# # 获取晶胞矩阵# cell =   relaxed_structure.get_cell()# # 尝试使用 Cholesky 分解将晶胞矩阵转换为上三角矩阵# try:#     # 确保晶胞矩阵是正定的#     upper_triangular = np.linalg.cholesky(cell.dot(cell.T)).T# except np.linalg.LinAlgError:#     # 如果 Cholesky 分解失败，使用 QR 分解#     _, upper_triangular = np.linalg.qr(cell)# # 更新   relaxed_structure 对象的晶胞矩阵# relaxed_structure.set_cell(upper_triangular, scale_atoms=True)relaxed_structure.calc = calcensemble = &quot;NVT_BERENDSEN&quot;temperature = 1000timestep = 1.0taut = 100trajectory = &quot;atoms.traj&quot;logfile = &quot;atoms.log&quot;nvt_runner = MolecularDynamics(atoms=relaxed_structure, ensemble=ensemble, temperature=temperature, timestep=timestep, taut=taut, trajectory=trajectory, logfile = logfile)nvt_runner.run(1000000)</code></pre><h2 id="3-处理vaspkit-的MSD-dat得到电导率"><a href="#3-处理vaspkit-的MSD-dat得到电导率" class="headerlink" title="3. 处理vaspkit 的MSD.dat得到电导率"></a>3. 处理vaspkit 的MSD.dat得到电导率</h2><pre><code class="python">import numpy as npimport matplotlib.pyplot as pltfrom scipy.stats import linregressdef dealMSD(inputfile):    data = np.loadtxt(inputfile,skiprows = 1 )    data[:,0] = data[:,0] / 1000    n = data.shape[0]    start_idx = int(n*0.05)    end_idx = int(n*0.95)    time = data[start_idx:end_idx,0]    MSD = data[start_idx:end_idx,4]    slope, intercept, r_value, _, _ = linregress(time, MSD)    MSD_fit = slope * time + intercept        fig,ax1 = plt.subplots(figsize=(4,3),dpi = 600)    ax1.plot(data[:, 0], data[:, 4],             label=&#39;600 K&#39;,             linewidth=2,          # 更粗的线条            color=&#39;#2ecc71&#39;,      # 柔和的绿色            alpha=0.8)      ax1.plot(time, MSD_fit, label=f&#39;Fit: y = &#123;slope:.2f&#125;x + &#123;intercept:.2f&#125;&#39;, color=&#39;red&#39;)    ax1.set_xlabel(&#39;t (ps)&#39;)    ax1.set_ylabel(r&#39;MSD ($\AA^2$)&#39;)    ax1.legend()    ax1.grid(True)    output_filename = inputfile.replace(&#39;/&#39;,&#39;-&#39;) + &#39;.png&#39;    plt.savefig(output_filename, bbox_inches=&#39;tight&#39;)    plt.close()#    plt.show()    return slopediffD = []temp = [600, 800,1000]for i in temp:    inputfile = f&quot;&#123;i&#125;/msd/MSD.dat&quot;    try:        slope = dealMSD(inputfile)        diffuD = slope / 60000        diffD.append(diffuD)    except FileNotFoundError:        print(f&quot;文件 &#123;inputfile&#125; 不存在&quot;)        diffD.append(0)logdiffD = np.log10(diffD)temp_inv = np.array([1000 / i for i in temp]) slope_D, intercept_D, _, _, _ = linregress(temp_inv, logdiffD)temp_inv_fit = np.linspace(1, 3.3, 100)logDfit = slope_D * temp_inv_fit + intercept_D#logDfit = slope_D * temp_inv + intercept_Dfig,ax1 = plt.subplots(figsize=(4,3),dpi = 600)ax1.plot(temp_inv_fit, logDfit, label=f&#39;Fit: y = &#123;slope_D:.2f&#125;x + &#123;intercept_D:.2f&#125;&#39;, color=&#39;red&#39;)ax1.scatter(temp_inv, logdiffD,color = &#39;blue&#39;,marker = &#39;o&#39;)ax1.set_xlabel(&#39;1000/T (1/K)&#39;)ax1.set_ylabel(r&#39;log10(D) (Å$^2$/ps)&#39;)ax1.set_xlim(0.9, 3.5)ax1.set_ylim(slope_D * 3.5 + intercept_D, slope_D * 0.9 + intercept_D+ 0.3)y_min = slope_D * 3.5 + intercept_Dy_max = slope_D * 0.9 + intercept_D + 0.3y_ticks = np.arange(np.floor(y_min / 0.5) * 0.5, np.ceil(y_max / 0.5) * 0.5, 0.5)ax1.set_yticks(y_ticks)ax1.legend()ax1.grid(True)plt.savefig(&#39;arrnius.png&#39;,bbox_inches=&#39;tight&#39;)from pymatgen.core import Structurestructure = Structure.from_file(&quot;POSCAR&quot;)volume = structure.volumeatomsnumber = 30Eanumber = 0.198691478T = 300logD300 = slope_D * (1000 / T) + intercept_DD = 10 ** logD300sigma300 = 1.858 * atomsnumber / volume / 300 * (10**12) * DEa = -Eanumber * slope_Dprint(Ea, sigma300)</code></pre><h2 id="4-mattersim-MD直接输出MSD"><a href="#4-mattersim-MD直接输出MSD" class="headerlink" title="4. mattersim-MD直接输出MSD"></a>4. mattersim-MD直接输出MSD</h2><pre><code class="python">from mattersim.applications.moldyn import MolecularDynamicsfrom ase.io import read, writefrom mattersim.forcefield import MatterSimCalculatorfrom mattersim.applications.relax import Relaxerimport numpy as npimport os# calc = MatterSimCalculator(device=&#39;cuda&#39;)# calc = MatterSimCalculator(device=&#39;cuda:0&#39;)calc = MatterSimCalculator(load_path=&quot;MatterSim-v1.0.0-1M.pth&quot;, device=&#39;cuda:0&#39;)relaxer = Relaxer(    optimizer=&quot;BFGS&quot;, # the optimization method FIRE, BFGS    filter=None, # filter to apply to the cell    constrain_symmetry=True, # whether to constrain the symmetry)atoms = read(&quot;POSCAR&quot;,format=&#39;vasp&#39;)atoms.calc = calcconverged, relaxed_structure = relaxer.relax_structures(atoms,optimizer=&quot;BFGS&quot;, # the optimization method FIRE, BFGS    filter=None,     constrain_symmetry=True, fmax=0.01 )# # 获取晶胞矩阵# cell =   relaxed_structure.get_cell()# # 尝试使用 Cholesky 分解将晶胞矩阵转换为上三角矩阵# try:#     # 确保晶胞矩阵是正定的#     upper_triangular = np.linalg.cholesky(cell.dot(cell.T)).T# except np.linalg.LinAlgError:#     # 如果 Cholesky 分解失败，使用 QR 分解#     _, upper_triangular = np.linalg.qr(cell)# # 更新   relaxed_structure 对象的晶胞矩阵# relaxed_structure.set_cell(upper_triangular, scale_atoms=True)relaxed_structure.calc = calc# import torch# torch.cuda.empty_cache() ensemble = &quot;NVT_BERENDSEN&quot;temperature = 600timestep = 2.0taut = 100trajectory = &quot;atoms.traj&quot;logfile = &quot;atoms.log&quot;  nvt_runner = MolecularDynamics(atoms=relaxed_structure, ensemble=ensemble, temperature=temperature, timestep=timestep, taut=taut, trajectory=trajectory, loginterval=1,logfile = logfile)nvt_runner.run(250000)#将轨迹写入XDATCARatoms_xda = read(&#39;atoms.traj&#39;, index=&#39;:&#39;)write(&#39;XDATCAR&#39;, atoms_xda)os.remove(&#39;atoms.traj&#39;)import numpy as npimport matplotlibmatplotlib.use(&quot;Agg&quot;)import matplotlib.pyplot as pltinput_file = &#39;atoms.log&#39;data = np.loadtxt(input_file,skiprows=1)fig,(ax1,ax2) = plt.subplots(1,2,figsize=(10,6),dpi=100)ax1.plot(data[:, 0], data[:, 1],          label=&#39;t-Energy&#39;,          linewidth=2,          # 更粗的线条         color=&#39;#2ecc71&#39;,      # 柔和的绿色         alpha=0.8)            # 轻微的透明度ax1.set_xlabel(&#39;t (ps)&#39;)ax1.set_ylabel(&#39;Energy (eV)&#39;)ax1.set_title(&#39;t-Energy&#39;)ax1.legend()ax1.grid(True)ax2.plot(data[:, 0], data[:, 4],          label=&#39;t-Temperature&#39;,          linewidth=2,          color=&#39;#e74c3c&#39;,      # 柔和的红色         alpha=0.8)ax2.set_xlabel(&#39;t (ps)&#39;)ax2.set_ylabel(&#39;Temperature (K)&#39;)ax2.set_title(&#39;t-Energy&#39;)ax2.legend()ax2.grid(True)fig.tight_layout()plot_file = &#39;t-E-T.png&#39;fig.savefig(plot_file, dpi=300, bbox_inches=&#39;tight&#39;, facecolor=&#39;white&#39;)#vaspkit处理import subprocessdef run_vaspkit(task_id, selectype, element, skip_steps, frame_interval):    # 构造VASPKIT命令    command = f&quot;(echo &#123;task_id&#125;;echo &#123;selectype&#125;;echo &#123;element&#125;;echo &#123;skip_steps&#125;;echo &#123;frame_interval&#125;)| vaspkit&quot;    # 执行命令    process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)    stdout, stderr = process.communicate()    # 输出结果    if process.returncode == 0:        print(&quot;VASPKIT执行成功！&quot;)        print(stdout.decode())    else:        print(&quot;VASPKIT执行失败！&quot;)        print(stderr.decode())# 示例调用task_id = 722selectype = 1element = &quot;Na&quot;skip_steps = 5000frame_interval = 1run_vaspkit(task_id, selectype, element, skip_steps, frame_interval)if os.path.exists(&#39;MSD.dat&#39;):    os.remove(&#39;XDATCAR&#39;)</code></pre><h2 id="5-mattersim使用Nose-Hoover"><a href="#5-mattersim使用Nose-Hoover" class="headerlink" title="5. mattersim使用Nose-Hoover"></a>5. mattersim使用Nose-Hoover</h2><pre><code class="python">from ase.io import read, writefrom ase.optimize import BFGSfrom ase.md.nose_hoover_chain import NoseHooverChainNVTfrom ase import unitsimport numpy as npimport osfrom ase.md.velocitydistribution import (     MaxwellBoltzmannDistribution,    Stationary,)from mattersim.forcefield import MatterSimCalculatorcalc = MatterSimCalculator(load_path=&quot;MatterSim-v1.0.0-1M.pth&quot;, device=&#39;cuda:0&#39;)atoms = read(&quot;POSCAR&quot;,format=&#39;vasp&#39;)atoms.calc = calcdyn = BFGS(atoms)dyn.run(fmax=0.01)write(&quot;optimized_structure.vasp&quot;, atoms) temperature = 600timestep = 2.0 * units.fstdamp = 100trajectory = &quot;atoms.traj&quot;logfile = &quot;atoms.log&quot;  loginterval = 1append_trajectory = FalseMaxwellBoltzmannDistribution(atoms,temperature_K=temperature,force_temp = True)Stationary(atoms)md1 = NoseHooverChainNVT(atoms=atoms,timestep=timestep,temperature_K = temperature,tdamp=tdamp,trajectory = None,logfile=&#39;equili.log&#39;,loginterval= loginterval,append_trajectory=append_trajectory)md1.run(5000)md2= NoseHooverChainNVT(atoms=atoms,timestep=timestep,temperature_K = temperature,tdamp=tdamp,trajectory = trajectory,logfile=logfile,loginterval= loginterval,append_trajectory=append_trajectory)md2.run(5000)#将轨迹写入XDATCARatoms_xda = read(&#39;atoms.traj&#39;, index=&#39;:&#39;)write(&#39;XDATCAR&#39;, atoms_xda)os.remove(&#39;atoms.traj&#39;)import numpy as npimport matplotlibmatplotlib.use(&quot;Agg&quot;)import matplotlib.pyplot as pltinput_file = &#39;atoms.log&#39;data = np.loadtxt(input_file,skiprows=1)fig,(ax1,ax2) = plt.subplots(1,2,figsize=(10,6),dpi=100)ax1.plot(data[:, 0], data[:, 1],          label=&#39;t-Energy&#39;,          linewidth=2,          # 更粗的线条         color=&#39;#2ecc71&#39;,      # 柔和的绿色         alpha=0.8)            # 轻微的透明度ax1.set_xlabel(&#39;t (ps)&#39;)ax1.set_ylabel(&#39;Energy (eV)&#39;)ax1.set_title(&#39;t-Energy&#39;)ax1.legend()ax1.grid(True)ax2.plot(data[:, 0], data[:, 4],          label=&#39;t-Temperature&#39;,          linewidth=2,          color=&#39;#e74c3c&#39;,      # 柔和的红色         alpha=0.8)ax2.set_xlabel(&#39;t (ps)&#39;)ax2.set_ylabel(&#39;Temperature (K)&#39;)ax2.set_title(&#39;t-Energy&#39;)ax2.legend()ax2.grid(True)fig.tight_layout()plot_file = &#39;t-E-T.png&#39;fig.savefig(plot_file, dpi=300, bbox_inches=&#39;tight&#39;, facecolor=&#39;white&#39;)#vaspkit处理import subprocessdef run_vaspkit(task_id, selectype, element, skip_steps, frame_interval):    # 构造VASPKIT命令    command = f&quot;(echo &#123;task_id&#125;;echo &#123;selectype&#125;;echo &#123;element&#125;;echo &#123;skip_steps&#125;;echo &#123;frame_interval&#125;)| vaspkit&quot;    # 执行命令    process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)    stdout, stderr = process.communicate()    # 输出结果    if process.returncode == 0:        print(&quot;VASPKIT执行成功！&quot;)        print(stdout.decode())    else:        print(&quot;VASPKIT执行失败！&quot;)        print(stderr.decode())# 示例调用task_id = 722selectype = 1element = &quot;Na&quot;skip_steps = 5000frame_interval = 1run_vaspkit(task_id, selectype, element, skip_steps, frame_interval)if os.path.exists(&#39;MSD.dat&#39;):    os.remove(&#39;XDATCAR&#39;)</code></pre><h2 id="6-计算MSD-处理equili-log-atoms-log"><a href="#6-计算MSD-处理equili-log-atoms-log" class="headerlink" title="6. 计算MSD 处理equili.log &amp; atoms.log"></a>6. 计算MSD 处理equili.log &amp; atoms.log</h2><pre><code class="python">import matplotlib.pyplot as pltimport matplotlibimport numpy as npimport os from matplotlib import cmfrom scipy.stats import linregressmatplotlib.use(&#39;Agg&#39;)def ET(input_file, ax1,ax2):    data = np.loadtxt(input_file,skiprows=1)    ax1.plot(data[:, 0], data[:, 1],             label=&#39;t-Energy&#39;,             linewidth=2,          # 更粗的线条            color=&#39;#2ecc71&#39;,      # 柔和的绿色            alpha=0.8)            # 轻微的透明度    ax1.set_xlabel(&#39;t (ps)&#39;)    ax1.set_ylabel(&#39;Energy (eV)&#39;)    ax1.set_title(&#39;t-Energy&#39;)    ax1.legend()    ax1.grid(True)    ax2.plot(data[:, 0], data[:, 4],             label=&#39;t-Temperature&#39;,             linewidth=2,             color=&#39;#e74c3c&#39;,      # 柔和的红色            alpha=0.8)    ax2.set_xlabel(&#39;t (ps)&#39;)    ax2.set_ylabel(&#39;Temperature (K)&#39;)    ax2.legend()    ax2.grid(True)def plottem(tem):    data1 = np.loadtxt(os.path.join(base_folder, str(tem), &#39;MSD.dat&#39;))    data10 = data1[:, [0,4]]    x = data10[:, 0] / 1000   # Convert time to ps and scale by 2 (example transformation)    y_data = data10[:, 1]    return x, y_datadef MSD_T(ax5):    colors = cm.tab10    # Plot data for each temperature    for tem in tem_list:        x, y_data = plottem(tem)        n = x.shape[0]        start_idx = int(n*0.05)        end_idx = int(n*0.95)        time = x[start_idx:end_idx]        MSD = y_data[start_idx:end_idx]        slope, intercept, r_value, _, _ = linregress(time, MSD)        MSD_fit = slope * time + intercept        color = colors.colors[int(tem /100)-4]        ax5.plot(x, y_data,color=color, label=f&#39;&#123;tem&#125; K&#39;,linewidth=2)        ax5.plot(time, MSD_fit, color=&#39;red&#39;)        ax5.set_xlabel(&#39;Time (ps)&#39;,fontsize=20, fontweight=&#39;bold&#39;)        ax5.set_ylabel(r&#39;MSD ($\mathrm&#123;\AA&#125;^2$)&#39;,fontsize=20,fontweight=&#39;bold&#39;)        ax5.legend(prop=&#123;&#39;weight&#39;:&#39;bold&#39;,&#39;size&#39;:16&#125;)def dealMSD(inputfile):    data = np.loadtxt(inputfile,skiprows = 1 )    data[:,0] = data[:,0] / 1000     n = data.shape[0]    start_idx = int(n*0.05)    end_idx = int(n*0.95)    time = data[start_idx:end_idx,0]    MSD = data[start_idx:end_idx,4]    slope, intercept, r_value, _, _ = linregress(time, MSD)    MSD_fit = slope * time + intercept    return slopedef arrniums(ax6):    diffD = []    for i in tem_list:        inputfile = os.path.join(base_folder,str(i),&#39;MSD.dat&#39;)        try:            slope = dealMSD(inputfile)            diffuD = slope / 60000            diffD.append(diffuD)        except FileNotFoundError:            print(f&quot;文件 &#123;inputfile&#125; 不存在&quot;)            diffD.append(0)    logdiffD = np.log10(diffD)    temp_inv = np.array([1000 / i for i in tem_list])     slope_D, intercept_D, _, _, _ = linregress(temp_inv, logdiffD)    temp_inv_fit = np.linspace(0.7, 3.3, 100)    logDfit = slope_D * temp_inv_fit + intercept_D    #logDfit = slope_D * temp_inv + intercept_D    ax6.plot(temp_inv_fit, logDfit, label=f&#39;Fit: y = &#123;slope_D:.2f&#125;x + &#123;intercept_D:.2f&#125;&#39;, color=&#39;red&#39;)    ax6.scatter(temp_inv, logdiffD,color = &#39;blue&#39;,marker = &#39;o&#39;)    ax6.set_xlabel(&#39;1000/T (1/K)&#39;)    ax6.set_ylabel(r&#39;log10(D) (Å$^2$/ps)&#39;)    ax6.set_xlim(0.6, 3.5)    ax6.set_ylim(slope_D * 3.5 + intercept_D, slope_D * 0.9 + intercept_D+ 0.3)    y_min = slope_D * 3.5 + intercept_D    y_max = slope_D * 0.7 + intercept_D + 0.3    y_ticks = np.arange(np.floor(y_min / 0.5) * 0.5, np.ceil(y_max / 0.5) * 0.5, 0.5)    ax6.set_yticks(y_ticks)    ax6.legend()    ax6.grid(True)    # plt.savefig(&#39;arrnius.png&#39;,bbox_inches=&#39;tight&#39;)    from pymatgen.core import Structure    structure = Structure.from_file(&quot;POSCAR&quot;)    num_atoms = structure.num_sites    if num_atoms == 132:        volume = structure.volume        atomsnumber = 30        Eanumber = 0.198691478        T = 300        logD300 = slope_D * (1000 / T) + intercept_D        D = 10 ** logD300        sigma300 = 1.858 * atomsnumber / volume / 300 * (10**12) * D        Ea = -Eanumber * slope_D        print(Ea, sigma300)        text_str = f&#39;Ea = &#123;Ea:.2f&#125;  eV\nSigma300K = &#123;sigma300:.2f&#125; mS/cm&#39;        ax6.text(0.95, 0.95, text_str, transform=ax6.transAxes,                 fontsize=10, verticalalignment=&#39;top&#39;, horizontalalignment=&#39;right&#39;,                bbox=dict(facecolor=&#39;white&#39;, alpha=0.8, edgecolor=&#39;black&#39;))    else:        print(&#39;not the 132 atoms cell&#39;)def main():    fig = plt.figure(figsize = (12,60), dpi = 300)    gs = fig.add_gridspec(len(tem_list)* 2 + 1 ,2)    ax1= fig.add_subplot(gs[0,0])    ax2= fig.add_subplot(gs[0,1])    MSD_T(ax1)    arrniums(ax2)    for idx, tem in enumerate(tem_list):        row = idx*2 + 1         equili_folder = os.path.join(base_folder,str(tem),&#39;equili.log&#39;)        atoms_folder = os.path.join(base_folder,str(tem),&#39;atoms.log&#39;)        ax_equili_T = fig.add_subplot(gs[row,0])        ax_equili_E = fig.add_subplot(gs[row,1])        ax_atoms_T = fig.add_subplot(gs[row+1,0])         ax_atoms_E = fig.add_subplot(gs[row+1,1])        ET(equili_folder,ax_equili_T,ax_equili_E)        ET(atoms_folder,ax_atoms_T,ax_atoms_E)        ax_equili_T.set_title(f&#39;&#123;tem&#125; K&#39;)    plt.tight_layout()    plt.savefig(&#39;msd-TE.png&#39;)base_folder = &#39;./&#39;tem_list = [600,800,1000,1200]if __name__ == &#39;__main__&#39;:    main()</code></pre><h2 id="7-处理不同次的MSD，得到所有MSD"><a href="#7-处理不同次的MSD，得到所有MSD" class="headerlink" title="7. 处理不同次的MSD，得到所有MSD"></a>7. 处理不同次的MSD，得到所有MSD</h2><pre><code class="python"># %%import numpy as npimport osimport matplotlib.pyplot as pltfrom matplotlib import cmimport matplotlib.font_manager as fmbase_folder = &#39;./&#39;def plottem(tem, msd_data_list):    data1 = np.loadtxt(os.path.join(base_folder, str(tem), str(1), &#39;msd.dat&#39;))    data10 = data1[:, 0]    msd_data_list.append(data10)    for i in range(1, 4, 1):        target_path = os.path.join(base_folder, str(tem), str(i), &#39;msd.dat&#39;)        # print(target_path)        data = np.loadtxt(target_path, skiprows=1)        data_all = data[:, 4]        data_all = data_all *132 / 30        msd_data_list.append(data_all)        # Padding to match the maximum length of data    max_len = max(len(arr) for arr in msd_data_list)    padded_data = np.array([np.pad(arr, (0, max_len - len(arr)), &#39;constant&#39;, constant_values=np.nan) for arr in msd_data_list])        msd_data = padded_data.T    x = msd_data[:, 0] / 1000 * 2  # Convert time to ps and scale by 2 (example transformation)    y_data = msd_data[:, 1:]    return x, y_dataplt.rcParams[&#39;font.family&#39;] = &#39;Times New Roman&#39;plt.rcParams[&#39;font.size&#39;] = 16plt.rcParams[&#39;axes.linewidth&#39;] = 2plt.rcParams[&#39;axes.titlesize&#39;] = 16plt.rcParams[&#39;axes.labelsize&#39;] = 20plt.rcParams[&#39;axes.labelweight&#39;] = &#39;bold&#39;plt.rcParams[&#39;xtick.labelsize&#39;] = 16plt.rcParams[&#39;ytick.labelsize&#39;] = 16plt.rcParams[&#39;legend.fontsize&#39;] = 16# Create the plotplt.figure(figsize=(8, 6),dpi=300)colors = cm.tab10# Plot data for each temperaturefor tem in [600, 700, 800, 900, 1000]:    msd_data_list = []    x, y_data = plottem(tem, msd_data_list)    y_min = np.nanmin(y_data, axis=1)    y_max = np.nanmax(y_data, axis=1)    color = colors.colors[int(tem /100)-5]    # Plot the curves for the current temperature    for i in range(y_data.shape[1]):        plt.plot(x, y_data[:, i],color=color, label=f&#39;&#123;tem&#125; K&#39; if i==0 else &quot;&quot;)        # Fill between the min and max values    plt.fill_between(x, y_min, y_max, color=color, alpha=0.3)# Final plot settingsplt.xlabel(&#39;Time (ps)&#39;)plt.ylabel(r&#39;MSD ($\mathrm&#123;\AA&#125;^2$)&#39;)plt.xticks(fontweight = &#39;bold&#39;)plt.yticks(fontweight = &#39;bold&#39;)plt.legend(prop = &#123;&#39;weight&#39; :&#39;bold&#39;&#125;)plt.tight_layout()# plt.show()plt.savefig(&#39;888.png&#39;,dpi=600)</code></pre><h2 id="8-计算不同次分子动力学平均后的电导率"><a href="#8-计算不同次分子动力学平均后的电导率" class="headerlink" title="8.计算不同次分子动力学平均后的电导率"></a>8.计算不同次分子动力学平均后的电导率</h2><pre><code class="python">import numpy as npimport matplotlib.pyplot as pltfrom scipy.stats import linregressdef dealMSD(inputfile):    data = np.loadtxt(inputfile,skiprows = 1 )    data[:,0] = data[:,0] / 1000 * 2    n = data.shape[0]    start_idx = int(n*0.05)    end_idx = int(n*0.95)    time = data[start_idx:end_idx,0]    MSD = data[start_idx:end_idx,4]    slope, intercept, r_value, _, _ = linregress(time, MSD)    MSD_fit = slope * time + intercept        fig,ax1 = plt.subplots(figsize=(4,3),dpi = 600)    ax1.plot(data[:, 0], data[:, 4],             label=&#39;600 K&#39;,             linewidth=2,          # 更粗的线条            color=&#39;#2ecc71&#39;,      # 柔和的绿色            alpha=0.8)      ax1.plot(time, MSD_fit, label=f&#39;Fit: y = &#123;slope:.2f&#125;x + &#123;intercept:.2f&#125;&#39;, color=&#39;red&#39;)    ax1.set_xlabel(&#39;t (ps)&#39;)    ax1.set_ylabel(r&#39;MSD ($\AA^2$)&#39;)    ax1.legend()    ax1.grid(True)    output_filename = inputfile.replace(&#39;/&#39;,&#39;-&#39;) + &#39;.png&#39;    plt.savefig(output_filename, bbox_inches=&#39;tight&#39;)    plt.close()#    plt.show()    return slopediffD = []temp = [600, 700,800,900,1000]for i in temp:    diff_temp = []    for j in [1,2,3]:        inputfile = f&quot;&#123;i&#125;/&#123;j&#125;/msd.dat&quot;        try:            slope = dealMSD(inputfile)            diffuD = slope / 60000            diff_temp.append(diffuD)            # diffD.append(diffuD)        except FileNotFoundError:            print(f&quot;文件 &#123;inputfile&#125; 不存在&quot;)            diff_temp.append(0)    diff_temp = np.array(diff_temp)    diff_temp_value = np.average(diff_temp)    diffD.append(diff_temp_value)logdiffD = np.log10(diffD)temp_inv = np.array([1000 / i for i in temp]) slope_D, intercept_D, _, _, _ = linregress(temp_inv, logdiffD)temp_inv_fit = np.linspace(1, 3.3, 100)logDfit = slope_D * temp_inv_fit + intercept_D#logDfit = slope_D * temp_inv + intercept_Dfig,ax1 = plt.subplots(figsize=(4,3),dpi = 600)ax1.plot(temp_inv_fit, logDfit, label=f&#39;Fit: y = &#123;slope_D:.2f&#125;x + &#123;intercept_D:.2f&#125;&#39;, color=&#39;red&#39;)ax1.scatter(temp_inv, logdiffD,color = &#39;blue&#39;,marker = &#39;o&#39;)ax1.set_xlabel(&#39;1000/T (1/K)&#39;)ax1.set_ylabel(r&#39;log10(D) (Å$^2$/ps)&#39;)ax1.set_xlim(0.9, 3.5)ax1.set_ylim(slope_D * 3.5 + intercept_D, slope_D * 0.9 + intercept_D+ 0.3)y_min = slope_D * 3.5 + intercept_Dy_max = slope_D * 0.9 + intercept_D + 0.3y_ticks = np.arange(np.floor(y_min / 0.5) * 0.5, np.ceil(y_max / 0.5) * 0.5, 0.5)ax1.set_yticks(y_ticks)ax1.legend()ax1.grid(True)plt.savefig(&#39;arrnius.png&#39;,bbox_inches=&#39;tight&#39;)from pymatgen.core import Structurestructure = Structure.from_file(&quot;POSCAR&quot;)volume = structure.volumeatomsnumber = 132Eanumber = 0.198691478T = 300logD300 = slope_D * (1000 / T) + intercept_DD = 10 ** logD300sigma300 = 1.858 * atomsnumber / volume / 300 * (10**12) * DEa = -Eanumber * slope_Dprint(Ea, sigma300)</code></pre><h1 id="3-一些结果"><a href="#3-一些结果" class="headerlink" title="3. 一些结果"></a>3. 一些结果</h1><p>大模型对NaInSiO的计算</p><p><img src="/./../../%E5%9B%BE%E7%89%87/image-20250121214124415.png" alt="image-20250121214124415"></p><p>大模型能够比较好的模拟出Na的离子扩散行为</p><h1 id="4-一些脚本"><a href="#4-一些脚本" class="headerlink" title="4. 一些脚本"></a>4. 一些脚本</h1><h2 id="1-把ase轨迹转换为XDATCAR的脚本"><a href="#1-把ase轨迹转换为XDATCAR的脚本" class="headerlink" title="1. 把ase轨迹转换为XDATCAR的脚本"></a>1. 把ase轨迹转换为XDATCAR的脚本</h2><p>使用ase自带的方法</p><p><code>ase convert --input-format traj --output-format vasp-xdatcar atoms.traj XDATCAR</code></p><p>python脚本</p><pre><code class="python">from ase.io import read, write# 读取原始轨迹文件atoms = read(&#39;atoms.traj&#39;, index=&#39;:&#39;)# 将轨迹写入 XDATCAR 格式write(&#39;XDATCAR&#39;, atoms)</code></pre><h2 id="2-蒸馏大模型数据变成符合acnn标准的xsf文件的脚本"><a href="#2-蒸馏大模型数据变成符合acnn标准的xsf文件的脚本" class="headerlink" title="2. 蒸馏大模型数据变成符合acnn标准的xsf文件的脚本"></a>2. 蒸馏大模型数据变成符合acnn标准的xsf文件的脚本</h2><pre><code class="python">from mattersim.applications.moldyn import MolecularDynamicsfrom ase.io import readfrom mattersim.forcefield import MatterSimCalculatorfrom mattersim.applications.relax import Relaxerimport numpy as np# 使用 MatterSimCalculator 初始化计算器calc = MatterSimCalculator(load_path=&quot;MatterSim-v1.0.0-5M.pth&quot;, device=&#39;cuda:0&#39;)# 设置优化器relaxer = Relaxer(    optimizer=&quot;BFGS&quot;,  # 优化方法，使用 FIRE 或 BFGS    filter=None,  # 是否应用过滤器    constrain_symmetry=True,  # 是否约束对称性)# 读取 POSCAR 文件atoms = read(&quot;POSCAR111.vasp&quot;, format=&#39;vasp&#39;)atoms.calc = calc# 进行结构弛豫converged, relaxed_structure = relaxer.relax_structures(atoms, optimizer=&quot;FIRE&quot;, filter=None, constrain_symmetry=True, fmax=0.05)# 设置计算器并准备进行分子动力学模拟relaxed_structure.calc = calc# 分子动力学参数ensemble = &quot;NVT_BERENDSEN&quot;temperature = 1000timestep = 1.0taut = 50trajectory = &quot;atoms.traj&quot;logfile = &quot;atoms.log&quot;nvt_runner = MolecularDynamics(    atoms=relaxed_structure,    ensemble=ensemble,    temperature=temperature,    timestep=timestep,    taut=taut,    trajectory=trajectory,    loginterval=1,    logfile=logfile)# 保存每一帧为 .xsf 文件的函数def write2my(file_path, ene_i, lat_i, ele_i, coo_i, foc_i):    lat_i = lat_i.reshape(3, 3)    coo_i = coo_i.reshape(-1, 3)    foc_i = foc_i.reshape(-1, 3)    with open(file_path, &#39;w&#39;) as file:        file.write(f&quot;# total energy = &#123;ene_i&#125; eV\n\n&quot;)        file.write(&quot;CRYSTAL\n&quot;)        file.write(&quot;PRIMVEC\n&quot;)                for j in lat_i:            for k in j:                file.write(f&#39;&#123;k:20.8f&#125;&#39;)            file.write(&#39;\n&#39;)        file.write(&quot;PRIMCOORD\n&quot;)        file.write(f&quot;&#123;len(coo_i)&#125; 1\n&quot;)        for j in range(len(coo_i)):            element_name = chemical_symbols[ele_i[j]]            file.write(f&#39;&#123;element_name:2&#125; &#39;)            # 写入坐标            for k in coo_i[j]:                file.write(f&quot;&#123;k:20.8f&#125;&quot;)            # 写入受力            for k in foc_i[j]:                file.write(f&quot;&#123;k:20.8f&#125;&quot;)            file.write(&quot;\n&quot;)# 模拟运行并每50步保存一次 .xsf 文件for step in range(1000000):  # 你可以根据需要设置步数    nvt_runner.run(1)  # 运行一个步长    atoms = nvt_runner.atoms  # 获取当前步长的原子对象        # 每50步保存一次数据    if step % 100 == 0:        # 获取总能量        energy = atoms.get_total_energy()                # 获取晶胞矩阵        cell = atoms.get_cell()                # 获取原子元素类型        atomic_numbers = atoms.get_atomic_numbers()                # 获取原子坐标        positions = atoms.get_positions()                # 获取原子受力        forces = atoms.get_forces()                # 保存当前帧数据为 .xsf 文件        frame_filename = f&quot;frame_&#123;step&#125;.xsf&quot;        write2my(frame_filename, energy, cell, atomic_numbers, positions, forces)</code></pre><h2 id="3-扩胞脚本"><a href="#3-扩胞脚本" class="headerlink" title="3. 扩胞脚本"></a>3. 扩胞脚本</h2><pre><code class="python">from pymatgen.io.vasp import Poscar# 读取 POSCAR 文件poscar = Poscar.from_file(&quot;POSCAR&quot;)# 扩胞为 2x2x3supercell = poscar.structure * [6, 6, 6]# 将扩胞后的结构写入新的 POSCAR 文件poscar = Poscar(supercell)poscar.write_file(&quot;POSCAR666.vasp&quot;)</code></pre><pre><code class="python">from ase.io import read,writefrom ase.build import make_supercellatoms = read(&quot;POSCAR&quot;)P = [[3, 0, 0],     [0, 3, 0],     [0, 0, 3]]supercell = make_supercell(atoms,P)supercell.write(&quot;POSCAR333&quot;)</code></pre><h2 id="4-计算体积脚本"><a href="#4-计算体积脚本" class="headerlink" title="4. 计算体积脚本"></a>4. 计算体积脚本</h2><pre><code class="python">from pymatgen.core import Structure# 读取POSCAR文件#structure = Structure.from_file(&quot;POSCAR.vasp&quot;)structure = Structure.from_file(&quot;POSCAR.vasp&quot;)# 计算体积volume = structure.volume# 输出体积print(f&quot;&#123;volume&#125; Å³&quot;)</code></pre><h2 id="5-元素替换脚本"><a href="#5-元素替换脚本" class="headerlink" title="5. 元素替换脚本"></a>5. 元素替换脚本</h2><pre><code class="python">import osimport shutil# 创建文件夹base_path = &quot;./&quot;  # 替换为你的根目录路径element_symbols = [&quot;La&quot;, &quot;Ce&quot;,&quot;Pr&quot;,&quot;Nd&quot;,&quot;Pm&quot;,&quot;Eu&quot;,&quot;Sm&quot;,&quot;Gd&quot;,&quot;Tb&quot;,&quot;Dy&quot;,&quot;Ho&quot;,&quot;Er&quot;,&quot;Tm&quot;,&quot;Sc&quot;,&quot;Ti&quot;,&quot;V&quot;,&quot;Nb&quot;,&quot;Ta&quot;,&quot;Cr&quot;,&quot;Mo&quot;,&quot;Mn&quot;,&quot;Fe&quot;,&quot;Ru&quot;,&quot;Co&quot;,&quot;Rh&quot;,&quot;Ir&quot;,&quot;Ni&quot;,&quot;Pd&quot;,&quot;Cu&quot;,&quot;B&quot;,&quot;Al&quot;,&quot;Ga&quot;,&quot;In&quot;,&quot;N&quot;,&quot;P&quot;,&quot;Sb&quot;,&quot;Bi&quot;]for idx, element in enumerate(element_symbols, start=1):    folder_name = f&quot;&#123;idx&#125;-&#123;element&#125;&quot;    folder_path = os.path.join(base_path, folder_name)        if not os.path.exists(folder_path):        os.makedirs(folder_path)# 读取原始 POSCAR 文件input_file = &quot;./POSCAR&quot;  # 替换为你的 POSCAR 文件路径with open(input_file, &quot;r&quot;) as file:    lines = file.readlines()# 逐个元素进行替换并创建文件夹for idx, element in enumerate(element_symbols, start=1):    folder_name = f&quot;&#123;idx&#125;-&#123;element&#125;&quot;    folder_path = os.path.join(base_path, folder_name)        modified_lines = [line.replace(&quot;Y&quot;, element) for line in lines]        # 写入修改后的内容到对应的文件夹    output_file = os.path.join(folder_path, &quot;POSCAR&quot;)    with open(output_file, &quot;w&quot;) as file:        file.writelines(modified_lines)        # 复制同名的 INCAR 文件到对应的文件夹    incar_source = &quot;./INCAR&quot;  # 替换为你的 INCAR 文件路径    incar_destination = os.path.join(folder_path, &quot;INCAR&quot;)    shutil.copy(incar_source, incar_destination)    lsf_source = &quot;./vasp.pbs&quot;  # 替换为你的 INCAR 文件路径    lsf_destination = os.path.join(folder_path, &quot;opt.lsf&quot;)    shutil.copy(lsf_source, lsf_destination)print(&quot;Replacement and file writing complete.&quot;)</code></pre><h1 id="5-使用m3gnet"><a href="#5-使用m3gnet" class="headerlink" title="5. 使用m3gnet"></a>5. 使用m3gnet</h1><pre><code class="python"># import warnings# from m3gnet.models import Relaxer# from pymatgen.core import Lattice, Structure# from ase.io import read, write# import tensorflow as tf# from ase.optimize import BFGS# for category in (UserWarning, DeprecationWarning):#     warnings.filterwarnings(&quot;ignore&quot;, category=category, module=&quot;tensorflow&quot;)# gpus = tf.config.list_physical_devices(&#39;GPU&#39;)# if len(gpus) &gt; 0:#     tf.config.set_visible_devices(gpus[0], &#39;GPU&#39;) # atoms = read(&quot;POSCAR222.vasp&quot;,format=&#39;vasp&#39;)#  # 只使用第一块 GPU# relaxer = Relaxer(optimizer = &quot;BFGS&quot;)  # This loads the default pre-trained model# relax_results = relaxer.relax(atoms,verbose=True)# final_structure = relax_results[&#39;final_structure&#39;]# final_energy_per_atom = float(relax_results[&#39;trajectory&#39;].energies[-1] / len(atoms))# print(f&quot;Relaxed lattice parameter is &#123;final_structure.lattice.abc[0]:.3f&#125; Å&quot;)# print(f&quot;Final energy is &#123;final_energy_per_atom:.3f&#125; eV/atom&quot;)from ase.optimize import BFGSfrom m3gnet.models import Relaxer,M3GNetCalculatorfrom ase.io import read, writeimport tensorflow as tfgpus = tf.config.list_physical_devices(&#39;GPU&#39;)if len(gpus) &gt; 0:    tf.config.set_visible_devices(gpus[0], &#39;GPU&#39;) relaxer = Relaxer()calculator = relaxer.calculatoratoms = read(&quot;POSCAR222.vasp&quot;,format=&#39;vasp&#39;)# print(f&quot;unrelaxed lattice parameter is &#123;atoms.lattice.abc[0]:.3f&#125; Å&quot;)atoms.calc = calculatoroptimizer = BFGS(atoms)optimizer.run(fmax=0.01) # print(f&quot;Relaxed lattice parameter is &#123;atoms.lattice.abc[0]:.3f&#125; Å&quot;)</code></pre><h1 id="6-ASE结合phonopy-使用大模型作为计算器"><a href="#6-ASE结合phonopy-使用大模型作为计算器" class="headerlink" title="6. ASE结合phonopy 使用大模型作为计算器"></a>6. ASE结合phonopy 使用大模型作为计算器</h1><h2 id="1-关于声子谱"><a href="#1-关于声子谱" class="headerlink" title="1.关于声子谱"></a>1.关于声子谱</h2><pre><code>有限位移法（Finite Displacement Method）是一种用于计算晶体声子谱的数值方法，其基本原理是通过对晶体结构中的原子进行微小的位移，计算相应的力，从而构建力常数矩阵，进而求解声子频率和振动模式。具体步骤如下：结构优化：首先，对晶体结构进行高精度的优化，以获得平衡的原子位置和晶格常数。在优化过程中，需要设置适当的收敛标准，如能量收敛（EDIFF）和力收敛（EDIFFG）等，以确保结构的准确性。构建超胞：在优化后的结构基础上，使用Phonopy等工具构建超胞。超胞的尺寸通常是原胞的整数倍，具体尺寸取决于所需的声子计算精度和计算资源。原子位移：对超胞中的每个原子进行微小的位移，通常在0.01到0.03埃之间。这些位移可以是沿着晶体轴的正负方向，或者在不同方向上进行。力计算：在每个位移结构上，进行单点能量计算，获取每个原子所受的力。这些力数据用于构建力常数矩阵。构建力常数矩阵：利用获得的力数据，构建力常数矩阵。该矩阵描述了原子间的相互作用，是计算声子谱的基础。声子谱计算：通过对力常数矩阵进行对角化，得到声子的频率和振动模式。进一步，可以绘制声子色散曲线，分析声子的行为。注意事项：有限位移法的计算精度高度依赖于力的计算精度，因此在结构优化和单点计算中需要设置严格的收敛标准。位移幅度的选择需要平衡计算精度和计算量，过大的位移可能导致力常数矩阵的非线性，过小的位移可能导致数值误差。计算过程中，可能需要考虑晶体的对称性，以减少计算量。通过上述步骤，有限位移法能够有效地计算晶体的声子谱，为研究材料的热力学性质、动力学稳定性等提供重要信息。</code></pre><h2 id="2-绘制投影声子态密度"><a href="#2-绘制投影声子态密度" class="headerlink" title="2. 绘制投影声子态密度"></a>2. 绘制投影声子态密度</h2><pre><code class="python">import numpy as npimport matplotlibmatplotlib.use(&#39;Agg&#39;)import matplotlib.pyplot as plt# 读取文件input_file1 = &#39;projected_dos.dat&#39;  # 输入文件名input_file2 = &#39;total_dos.dat&#39;output_file = &#39;tdosandpdos.dat&#39;  # 输出文件名# 读取数据data = np.loadtxt(input_file1)data2 = np.loadtxt(input_file2)# 处理数据# 第一列保持不变col0 = data2[:,1]col1 = data[:, 0]# 第2-31列求和放到第二列col2 = np.sum(data[:, 1:31], axis=1)# 第32-37列求和放到第三列col3 = np.sum(data[:, 31:37], axis=1)# 第38-61列求和放到第四列col4 = np.sum(data[:, 37:61], axis=1)# 第62-133列求和放到第五列col5 = np.sum(data[:, 61:133], axis=1)# 将处理后的数据保存到新文件processed_data = np.column_stack((col1, col2, col3, col4, col5,col0))np.savetxt(output_file, processed_data, fmt=&#39;%.6f&#39;, delimiter=&#39;\t&#39;)plt.figure(figsize=(10, 6), dpi=100)  # 增加 dpi 以提高分辨率# 绘制图形，增强样式plt.plot(processed_data[:, 0], processed_data[:, 1],          label=&#39;PDOS_Na&#39;,          linewidth=2,          # 更粗的线条         color=&#39;#2ecc71&#39;,      # 柔和的绿色         alpha=0.8)           # 轻微的透明度plt.plot(processed_data[:, 0], processed_data[:, 2],          label=&#39;PDOS_X&#39;,          linewidth=2,          color=&#39;#e74c3c&#39;,      # 柔和的红色         alpha=0.8)plt.plot(processed_data[:, 0], processed_data[:, 3],          label=&#39;PDOS_Si&#39;,          linewidth=2,          color=&#39;#3498db&#39;,      # 柔和的蓝色         alpha=0.8)plt.plot(processed_data[:, 0], processed_data[:, 4],          label=&#39;PDOS_O&#39;,          linewidth=2,          color=&#39;#9b59b6&#39;,      # 紫色         alpha=0.8)plt.plot(processed_data[:, 0], processed_data[:, 5],          label=&#39;TDOS&#39;,          linewidth=2.5,        # TDOS 线条稍粗         color=&#39;#34495e&#39;,      # 深灰色         alpha=0.9)# 自定义坐标轴plt.xlabel(&#39;ω (THz)&#39;, fontsize=12, labelpad=10)  # 使用希腊字母 ω 表示频率plt.ylabel(&#39;Number&#39;, fontsize=12, labelpad=10)plt.title(&#39;Partial and Total Density of States&#39;,           fontsize=14,           pad=15,           fontweight=&#39;bold&#39;)# 增强图例plt.legend(    fontsize=10,    frameon=True,           # 添加边框    framealpha=0.9,         # 轻微透明的边框    edgecolor=&#39;gray&#39;,       # 边框颜色    loc=&#39;best&#39;              # 自动选择最佳位置)# 自定义网格（可选 - 浅色网格）plt.grid(True, linestyle=&#39;--&#39;, alpha=0.3, color=&#39;gray&#39;)# 调整边框（坐标轴边框）ax = plt.gca()ax.spines[&#39;top&#39;].set_color(&#39;gray&#39;)ax.spines[&#39;right&#39;].set_color(&#39;gray&#39;)ax.spines[&#39;left&#39;].set_color(&#39;gray&#39;)ax.spines[&#39;bottom&#39;].set_color(&#39;gray&#39;)ax.spines[&#39;top&#39;].set_alpha(0.5)ax.spines[&#39;right&#39;].set_alpha(0.5)# 添加次要刻度plt.minorticks_on()# 调整刻度参数plt.tick_params(axis=&#39;both&#39;, which=&#39;major&#39;, labelsize=10)plt.tick_params(axis=&#39;both&#39;, which=&#39;minor&#39;, length=2)# 紧凑布局，防止标签被截断plt.tight_layout()# 保存高质量图像plot_file = &#39;DOS.png&#39;plt.savefig(plot_file, dpi=300, bbox_inches=&#39;tight&#39;, facecolor=&#39;white&#39;)</code></pre><h1 id="7-ASE-grace"><a href="#7-ASE-grace" class="headerlink" title="7. ASE+grace"></a>7. ASE+grace</h1><h2 id="1-BFGS优化-NVTBerendsen分子动力学"><a href="#1-BFGS优化-NVTBerendsen分子动力学" class="headerlink" title="1. BFGS优化+NVTBerendsen分子动力学"></a>1. BFGS优化+NVTBerendsen分子动力学</h2><p>NVTBerendsen在taut比较小时可能得不到正确的动力学结果 ，因此模拟还是要用nose Hoover</p><p><img src="/./../../%E5%9B%BE%E7%89%87/image-20250320144100597.png" alt="image-20250320144100597"></p><pre><code class="python">from ase.io import read, writefrom ase.optimize import BFGSfrom ase.md.nvtberendsen import NVTBerendsenfrom ase import unitsfrom tensorpotential.calculator import grace_fmimport numpy as npimport osfrom ase.md.velocitydistribution import (     MaxwellBoltzmannDistribution,    Stationary,)calc = grace_fm(&#39;GRACE-2L-OMAT&#39;)atoms = read(&quot;POSCAR&quot;,format=&#39;vasp&#39;)atoms.calc = calcdyn = BFGS(atoms)dyn.run(fmax=0.01) temperature = 600timestep = 2.0 * units.fstaut = 100trajectory = &quot;atoms.traj&quot;logfile = &quot;atoms.log&quot;  loginterval = 1append_trajectory = FalseMaxwellBoltzmannDistribution(atoms,temperature_K=temperature,force_temp = True)Stationary(atoms)md = NVTBerendsen(atoms=atoms,timestep=timestep,temperature_K = temperature,taut=taut,trajectory = trajectory,logfile=logfile,loginterval= loginterval,append_trajectory=append_trajectory)md.run(250000)#后处理#将轨迹写入XDATCARatoms_xda = read(&#39;atoms.traj&#39;, index=&#39;:&#39;)write(&#39;XDATCAR&#39;, atoms_xda)os.remove(&#39;atoms.traj&#39;)import numpy as npimport matplotlibmatplotlib.use(&quot;Agg&quot;)import matplotlib.pyplot as pltinput_file = &#39;atoms.log&#39;data = np.loadtxt(input_file,skiprows=1)fig,(ax1,ax2) = plt.subplots(1,2,figsize=(10,6),dpi=100)ax1.plot(data[:, 0], data[:, 1],          label=&#39;t-Energy&#39;,          linewidth=2,          # 更粗的线条         color=&#39;#2ecc71&#39;,      # 柔和的绿色         alpha=0.8)            # 轻微的透明度ax1.set_xlabel(&#39;t (ps)&#39;)ax1.set_ylabel(&#39;Energy (eV)&#39;)ax1.set_title(&#39;t-Energy&#39;)ax1.legend()ax1.grid(True)ax2.plot(data[:, 0], data[:, 4],          label=&#39;t-Temperature&#39;,          linewidth=2,          color=&#39;#e74c3c&#39;,      # 柔和的红色         alpha=0.8)ax2.set_xlabel(&#39;t (ps)&#39;)ax2.set_ylabel(&#39;Temperature (K)&#39;)ax2.set_title(&#39;t-Energy&#39;)ax2.legend()ax2.grid(True)fig.tight_layout()plot_file = &#39;t-E-T.png&#39;fig.savefig(plot_file, dpi=300, bbox_inches=&#39;tight&#39;, facecolor=&#39;white&#39;)#vaspkit处理import subprocessdef run_vaspkit(task_id, selectype, element, skip_steps, frame_interval):    # 构造VASPKIT命令    command = f&quot;(echo &#123;task_id&#125;;echo &#123;selectype&#125;;echo &#123;element&#125;;echo &#123;skip_steps&#125;;echo &#123;frame_interval&#125;)| vaspkit&quot;    # 执行命令    process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)    stdout, stderr = process.communicate()    # 输出结果    if process.returncode == 0:        print(&quot;VASPKIT执行成功！&quot;)        print(stdout.decode())    else:        print(&quot;VASPKIT执行失败！&quot;)        print(stderr.decode())# 示例调用task_id = 722selectype = 1element = &quot;Na&quot;skip_steps = 5000frame_interval = 1run_vaspkit(task_id, selectype, element, skip_steps, frame_interval)if os.path.exists(&#39;MSD.dat&#39;):    os.remove(&#39;XDATCAR&#39;)</code></pre><h2 id="2-使用ASE中的Nose-Hoover-NVT"><a href="#2-使用ASE中的Nose-Hoover-NVT" class="headerlink" title="2. 使用ASE中的Nose-Hoover NVT"></a>2. 使用ASE中的Nose-Hoover NVT</h2><pre><code class="python">from ase.io import read, writefrom ase.optimize import BFGSfrom ase.md.nose_hoover_chain import NoseHooverChainNVTfrom ase import unitsfrom tensorpotential.calculator import grace_fmimport numpy as npimport osfrom ase.md.velocitydistribution import (     MaxwellBoltzmannDistribution,    Stationary,)calc = grace_fm(&#39;GRACE-2L-OMAT&#39;)atoms = read(&quot;POSCAR&quot;,format=&#39;vasp&#39;)atoms.calc = calcdyn = BFGS(atoms)dyn.run(fmax=0.01)write(&quot;optimized_structure.vasp&quot;, atoms) temperature = 600timestep = 2.0 * units.fstdamp = 100trajectory = &quot;atoms.traj&quot;logfile = &quot;atoms.log&quot;  loginterval = 1append_trajectory = FalseMaxwellBoltzmannDistribution(atoms,temperature_K=temperature,force_temp = True)Stationary(atoms)md1 = NoseHooverChainNVT(atoms=atoms,timestep=timestep,temperature_K = temperature,tdamp=tdamp,trajectory = None,logfile=&#39;equili.log&#39;,loginterval= loginterval,append_trajectory=append_trajectory)md1.run(10000)md2= NoseHooverChainNVT(atoms=atoms,timestep=timestep,temperature_K = temperature,tdamp=tdamp,trajectory = trajectory,logfile=logfile,loginterval= loginterval,append_trajectory=append_trajectory)md2.run(250000)</code></pre><h1 id="8-Nose-Hoover和Berendsen的对比"><a href="#8-Nose-Hoover和Berendsen的对比" class="headerlink" title="8. Nose-Hoover和Berendsen的对比"></a>8. Nose-Hoover和Berendsen的对比</h1><blockquote><p>更大的晶胞也需要更长的弛豫时间</p></blockquote><ul><li><p>Nose-Hoover  tdamp&#x3D; 200 vs Berendsen taut&#x3D;100</p><p>Nose-Hoover和Berendsen的动力学过程不同</p><p>Nose-Hoover</p><p><img src="/./../../%E5%9B%BE%E7%89%87/t-E-T-1742462430030-9.png" alt="t-E-T"></p></li></ul><p>Berendsen</p><p><img src="/./../../%E5%9B%BE%E7%89%87/t-E-T.png" alt="t-E-T"></p><ul><li><p>Nose-Hoover tdamp &#x3D; 40 100 200 400 对比</p><p>40 </p><p><img src="/./../../%E5%9B%BE%E7%89%87/t-E-T-1742462498650-11.png" alt="t-E-T"></p></li></ul><p>​     100</p><p>   <img src="/./../../%E5%9B%BE%E7%89%87/t-E-T-1742462527710-13.png" alt="t-E-T"></p><p>200</p><p><img src="/./../../%E5%9B%BE%E7%89%87/t-E-T-1742462552301-15.png" alt="t-E-T"></p><p>400</p><p><img src="/./../../%E5%9B%BE%E7%89%87/t-E-T-1742462576244-17.png" alt="t-E-T"></p><p>from deepseek</p><p><img src="/./../../%E5%9B%BE%E7%89%87/image-20250320172836556.png" alt="image-20250320172836556"></p><p><img src="/./../../%E5%9B%BE%E7%89%87/image-20250320172853036.png" alt="image-20250320172853036"></p><p><img src="/./../../%E5%9B%BE%E7%89%87/image-20250320172925841.png" alt="image-20250320172925841"></p><p><img src="/./../../%E5%9B%BE%E7%89%87/image-20250320172947930.png" alt="image-20250320172947930"></p><p><img src="/./../../%E5%9B%BE%E7%89%87/image-20250320173043216.png" alt="image-20250320173043216"></p><h1 id="9-学习mattersim的phonon的方法"><a href="#9-学习mattersim的phonon的方法" class="headerlink" title="9. 学习mattersim的phonon的方法"></a>9. 学习mattersim的phonon的方法</h1><h2 id="1-包装ase的结构为phonon的格式"><a href="#1-包装ase的结构为phonon的格式" class="headerlink" title="1. 包装ase的结构为phonon的格式"></a>1. 包装ase的结构为phonon的格式</h2><p><a href="https://github.com/microsoft/mattersim/blob/main/src/mattersim/utils/phonon_utils.py">https://github.com/microsoft/mattersim/blob/main/src/mattersim/utils/phonon_utils.py</a></p><pre><code class="python">def to_phonopy_atoms(atoms: Atoms):    &quot;&quot;&quot;    Transform ASE atoms object to Phonopy object    Args:        atoms (Atoms): ASE atoms object to provide lattice informations.    &quot;&quot;&quot;    phonopy_atoms = PhonopyAtoms(        symbols=atoms.get_chemical_symbols(),        cell=atoms.get_cell(),        masses=atoms.get_masses(),        positions=atoms.get_positions(),    )    return phonopy_atomsdef to_ase_atoms(phonopy_atoms):    &quot;&quot;&quot;    Transform Phonopy object to ASE atoms object    Args:        phonopy_atoms (Phonopy): Phonopy object to provide lattice informations.    &quot;&quot;&quot;    atoms = Atoms(        symbols=phonopy_atoms.symbols,        cell=phonopy_atoms.cell,        masses=phonopy_atoms.masses,        positions=phonopy_atoms.positions,        pbc=True,    )    return atoms</code></pre><h2 id="2-修改mattersim以输出投影声子密度，并且指定固定的路径内的q点个数来匹配自己写的绘制声子谱的脚本（vasp模拟部分）（auto-band得到的q点个数在不同路径上不是固定的）"><a href="#2-修改mattersim以输出投影声子密度，并且指定固定的路径内的q点个数来匹配自己写的绘制声子谱的脚本（vasp模拟部分）（auto-band得到的q点个数在不同路径上不是固定的）" class="headerlink" title="2. 修改mattersim以输出投影声子密度，并且指定固定的路径内的q点个数来匹配自己写的绘制声子谱的脚本（vasp模拟部分）（auto_band得到的q点个数在不同路径上不是固定的）"></a>2. 修改mattersim以输出投影声子密度，并且指定固定的路径内的q点个数来匹配自己写的绘制声子谱的脚本（vasp模拟部分）（auto_band得到的q点个数在不同路径上不是固定的）</h2><p>修改&#x2F;lib&#x2F;python3.12&#x2F;site-packages&#x2F;mattersim&#x2F;applications&#x2F;phonon.py </p><pre><code class="python">def compute_phonon_spectrum_dos(        atoms: Atoms, phonon: Phonopy, k_point_mesh: Union[int, Iterable[int]]    ):        &quot;&quot;&quot;        Calculate phonon spectrum and DOS based on force constant matrix in        phonon object        Args:            atoms (Atoms): ASE atoms object to provide lattice information            phonon (Phonopy): Phonopy object which contains force constants matrix            k_point_mesh (Union[int, Iterable[int]]): The qpoints number in First                Brillouin Zone in three directions for DOS calculation.        &quot;&quot;&quot;        print(f&quot;Qpoints mesh for Brillouin Zone integration : &#123;k_point_mesh&#125;&quot;)        phonon.run_mesh(k_point_mesh)        print(            &quot;Dispersion relations using phonopy for &quot;            + str(atoms.symbols)            + &quot; ...&quot;            + &quot;\n&quot;        )        # plot phonon spectrum        phonon.auto_band_structure(plot=True, write_yaml=True, with_eigenvectors=True).savefig(            f&quot;&#123;str(atoms.symbols)&#125;_phonon_band.png&quot;, dpi=300        )        phonon.auto_total_dos(plot=True, write_dat=True).savefig(            f&quot;&#123;str(atoms.symbols)&#125;_phonon_dos.png&quot;, dpi=300        )        # Save additional files        phonon.save(settings=&#123;&quot;force_constants&quot;: True&#125;)</code></pre><p>主要修改了compute_force_constants 这个函数，替换为 </p><pre><code class="python"># -*- coding: utf-8 -*-import datetimeimport osfrom typing import Iterable, Unionimport numpy as npfrom ase import Atomsfrom phonopy import Phonopyfrom tqdm import tqdmfrom seekpath import get_pathfrom phonopy.phonon.band_structure import get_band_qpoints_and_path_connectionsfrom mattersim.utils.phonon_utils import (    get_primitive_cell,    to_ase_atoms,    to_phonopy_atoms,)from mattersim.utils.supercell_utils import get_supercell_parametersclass PhononWorkflow(object):    &quot;&quot;&quot;    This class is used to calculate the phonon dispersion relationship of    material using phonopy    &quot;&quot;&quot;    def __init__(        self,        atoms: Atoms,        find_prim: bool = False,        work_dir: str = None,        amplitude: float = 0.01,        supercell_matrix: np.ndarray = None,        qpoints_mesh: np.ndarray = None,        max_atoms: int = None,        calc_spec: bool = True,    ):        &quot;&quot;&quot;_summary        Args:            atoms (Atoms): ASE atoms object contains structure information and                calculator.            find_prim (bool, optional): If find the primitive cell and use it                to calculate phonon. Default to False.            work_dir (str, optional): workplace path to contain phonon result.                Defaults to data + chemical_symbols + &#39;phonon&#39;            amplitude (float, optional): Magnitude of the finite difference to                displace in force constant calculation, in Angstrom. Defaults                to 0.01 Angstrom.            supercell_matrix (nd.array, optional): Supercell matrix for constr                -uct supercell, priority over than max_atoms. Defaults to None.            qpoints_mesh (nd.array, optional): Qpoint mesh for IBZ integral,                priority over than max_atoms. Defaults to None.            max_atoms (int, optional): Maximum atoms number limitation for the                supercell generation. If not set, will automatic generate super                -cell based on symmetry. Defaults to None.            calc_spec (bool, optional): If calculate the spectrum and check                 imaginary frequencies. Default to True.        &quot;&quot;&quot;        assert (            atoms.calc is not None        ), &quot;PhononWorkflow only accepts ase atoms with an attached calculator&quot;        if find_prim:            self.atoms = get_primitive_cell(atoms)            self.atoms.calc = atoms.calc        else:            self.atoms = atoms        if work_dir is not None:            self.work_dir = work_dir        else:            current_datetime = datetime.datetime.now()            formatted_datetime = current_datetime.strftime(&quot;%Y-%m-%d-%H-%M&quot;)            self.work_dir = (                f&quot;&#123;formatted_datetime&#125;-&#123;atoms.get_chemical_formula()&#125;-phonon&quot;            )        self.amplitude = amplitude        if supercell_matrix is not None:            if supercell_matrix.shape == (3, 3):                self.supercell_matrix = supercell_matrix            elif supercell_matrix.shape == (3,):                self.supercell_matrix = np.diag(supercell_matrix)            else:                assert (                    False                ), &quot;Supercell matrix must be an array (3,1) or a matrix (3,3).&quot;        else:            self.supercell_matrix = supercell_matrix        if qpoints_mesh is not None:            assert qpoints_mesh.shape == (3,), &quot;Qpoints mesh must be an array (3,1).&quot;            self.qpoints_mesh = qpoints_mesh        else:            self.qpoints_mesh = qpoints_mesh        self.max_atoms = max_atoms        self.calc_spec = calc_spec    def compute_force_constants(self, atoms: Atoms, nrep_second: np.ndarray):        &quot;&quot;&quot;        Calculate force constants        Args:            atoms (Atoms): ASE atoms object to provide lattice informations.            nrep_second (np.ndarray): Supercell size used for 2nd force                constant calculations.        &quot;&quot;&quot;        print(f&quot;Supercell matrix for 2nd force constants : \n&#123;nrep_second&#125;&quot;)        # Generate phonopy object        phonon = Phonopy(            to_phonopy_atoms(atoms),            supercell_matrix=nrep_second,            primitive_matrix=&quot;auto&quot;,            log_level=2,        )        # Generate displacements        phonon.generate_displacements(distance=self.amplitude)        # Compute force constants        second_scs = phonon.supercells_with_displacements        second_force_sets = []        print(&quot;\n&quot;)        print(&quot;Inferring forces for displaced atoms and computing fcs ...&quot;)        for disp_second in tqdm(second_scs):            pa_second = to_ase_atoms(disp_second)            pa_second.calc = self.atoms.calc            second_force_sets.append(pa_second.get_forces())        phonon.forces = np.array(second_force_sets)        phonon.produce_force_constants()        phonon.symmetrize_force_constants()        return phonon    @staticmethod    def compute_phonon_spectrum_dos(        atoms: Atoms, phonon: Phonopy, k_point_mesh: Union[int, Iterable[int]]    ):        &quot;&quot;&quot;        Calculate phonon spectrum and DOS based on force constant matrix in        phonon object        Args:            atoms (Atoms): ASE atoms object to provide lattice information            phonon (Phonopy): Phonopy object which contains force constants matrix            k_point_mesh (Union[int, Iterable[int]]): The qpoints number in First                Brillouin Zone in three directions for DOS calculation.        &quot;&quot;&quot;        print(f&quot;Qpoints mesh for Brillouin Zone integration : &#123;k_point_mesh&#125;&quot;)        phonon.run_mesh(k_point_mesh)        print(            &quot;Dispersion relations using phonopy for &quot;            + str(atoms.symbols)            + &quot; ...&quot;            + &quot;\n&quot;        )        #phonon.auto_band_structure(plot=True, write_yaml=True, with_eigenvectors=False).savefig(           # f&quot;&#123;str(atoms.symbols)&#125;_auto_band.png&quot;, dpi=300)                 lattice = atoms.cell        scaled_positions = atoms.get_scaled_positions()        atomic_numbers = atoms.get_atomic_numbers()        path_data = get_path((lattice, scaled_positions, atomic_numbers))        point_coords = path_data[&quot;point_coords&quot;]        band_segments = path_data[&quot;path&quot;]        from phonopy.phonon.band_structure import get_band_qpoints_and_path_connections        raw_labels = []        path = []        connectionsall = []        for start_label, end_label in band_segments:            q_start = point_coords[start_label]            q_end = point_coords[end_label]            path.append([q_start,q_end])            raw_labels.append(start_label)            raw_labels.append(end_label)            connectionsall.append(&#39;False&#39;)        qpoints, connections = get_band_qpoints_and_path_connections(path, npoints=51)        def convert_labels(raw_labels):            latex_labels = []            for label in raw_labels:                if label.upper() == &quot;GAMMA&quot;:                    latex_labels.append(&quot;$\\Gamma$&quot;)                else:                    latex_labels.append(label)            return latex_labels        labels = convert_labels(raw_labels)        phonon.run_band_structure(qpoints, path_connections=connections, labels=labels)        bs = phonon.band_structure        bs.write_yaml()        plt = phonon.plot_band_structure()        plt.savefig(f&quot;&#123;str(atoms.symbols)&#125;_manual_band.png&quot;,dpi=300)        phonon.auto_total_dos(plot=True, write_dat=True).savefig(            f&quot;&#123;str(atoms.symbols)&#125;_phonon_dos.png&quot;, dpi=300        )        phonon.auto_projected_dos(plot=True,write_dat=True).savefig(            f&quot;&#123;str(atoms.symbols)&#125;_phonon_projected_dos.png&quot;, dpi=300        )        phonon.save(settings=&#123;&quot;force_constants&quot;: True&#125;)    @staticmethod    def check_imaginary_freq(phonon: Phonopy):        &quot;&quot;&quot;        Check whether phonon has imaginary frequency.        Args:            phonon (Phonopy): Phonopy object which contains phonon spectrum frequency.        &quot;&quot;&quot;        band_dict = phonon.get_band_structure_dict()        frequencies = np.concatenate(            [np.array(freq).flatten() for freq in band_dict[&quot;frequencies&quot;]], axis=None        )        has_imaginary = False        if np.all(np.array(frequencies) &gt;= -0.299):            pass        else:            print(&quot;Warning! Imaginary frequencies found!&quot;)            has_imaginary = True        return has_imaginary    def run(self):        &quot;&quot;&quot;        The entrypoint to start the workflow.        &quot;&quot;&quot;        current_path = os.path.abspath(&quot;.&quot;)        try:            # check folder exists            if not os.path.exists(self.work_dir):                os.makedirs(self.work_dir)            os.chdir(self.work_dir)            try:                # Generate supercell parameters based on optimized structures                nrep_second, k_point_mesh = get_supercell_parameters(                    self.atoms, self.supercell_matrix, self.qpoints_mesh, self.max_atoms                )            except Exception as e:                print(&quot;Error whille generating supercell parameters:&quot;, e)                raise            try:                # Calculate 2nd force constants                phonon = self.compute_force_constants(self.atoms, nrep_second)            except Exception as e:                print(&quot;Error while computing force constants:&quot;, e)                raise            if self.calc_spec:                try:                    # Calculate phonon spectrum                    self.compute_phonon_spectrum_dos(self.atoms, phonon, k_point_mesh)                    # check whether has imaginary frequency                    has_imaginary = self.check_imaginary_freq(phonon)                except Exception as e:                    print(&quot;Error while computing phonon spectrum and dos:&quot;, e)                    raise            else:                has_imaginary = &#39;Not calculated, set calc_spec True&#39;                phonon.save(settings=&#123;&quot;force_constants&quot;: True&#125;)        except Exception as e:            print(&quot;An error occurred during the Phonon workflow:&quot;, e)            raise        finally:            os.chdir(current_path)        return has_imaginary, phonon</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;[toc]&lt;/p&gt;
&lt;h1 id=&quot;1-原子大模型排名&quot;&gt;&lt;a href=&quot;#1-原子大模型排名&quot; class=&quot;headerlink&quot; title=&quot;1. 原子大模型排名&quot;&gt;&lt;/a&gt;1. 原子大模型排名&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https://matbench-d</summary>
      
    
    
    
    <category term="机器学习" scheme="http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>一些课题</title>
    <link href="http://example.com/2025/01/09/6-%E8%AF%BE%E9%A2%98%E7%A0%94%E7%A9%B6/%E4%B8%80%E4%BA%9B%E8%AF%BE%E9%A2%98/"/>
    <id>http://example.com/2025/01/09/6-%E8%AF%BE%E9%A2%98%E7%A0%94%E7%A9%B6/%E4%B8%80%E4%BA%9B%E8%AF%BE%E9%A2%98/</id>
    <published>2025-01-09T06:10:02.000Z</published>
    <updated>2025-09-09T06:23:03.881Z</updated>
    
    <content type="html"><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="Oh, this is an invalid password. Check and try again, please." data-whm="OOPS, these decrypted content may changed, but you can still have a look.">  <script id="hbeData" type="hbeData" data-hmacdigest="ba121f27bbc4d704b3578b2f1eac76e5c64447cbd88f8f4115d90dd7843b8ea1">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</script>  <div class="hbe hbe-content">    <div class="hbe hbe-input hbe-input-default">      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">        <span class="hbe hbe-input-label-content hbe-input-label-content-default">Hey, password is required here.</span>      </label>    </div>  </div></div><script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
    
    
    <summary type="html">Here&#39;s something encrypted, password is required to continue reading.</summary>
    
    
    
    <category term="课题研究" scheme="http://example.com/categories/%E8%AF%BE%E9%A2%98%E7%A0%94%E7%A9%B6/"/>
    
    
  </entry>
  
  <entry>
    <title>镶嵌图形</title>
    <link href="http://example.com/2025/01/02/6-%E8%AF%BE%E9%A2%98%E7%A0%94%E7%A9%B6/%E9%95%B6%E5%B5%8C%E5%9B%BE%E5%BD%A2/"/>
    <id>http://example.com/2025/01/02/6-%E8%AF%BE%E9%A2%98%E7%A0%94%E7%A9%B6/%E9%95%B6%E5%B5%8C%E5%9B%BE%E5%BD%A2/</id>
    <published>2025-01-02T03:07:02.000Z</published>
    <updated>2025-01-07T00:45:23.403Z</updated>
    
    <content type="html"><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="Oh, this is an invalid password. Check and try again, please." data-whm="OOPS, these decrypted content may changed, but you can still have a look.">  <script id="hbeData" type="hbeData" data-hmacdigest="79d088dd5b4958d74509930a13fec04f9144751aa75bbfb8785681847fb55252">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</script>  <div class="hbe hbe-content">    <div class="hbe hbe-input hbe-input-default">      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">        <span class="hbe hbe-input-label-content hbe-input-label-content-default">Hey, password is required here.</span>      </label>    </div>  </div></div><script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
    
    
    <summary type="html">Here&#39;s something encrypted, password is required to continue reading.</summary>
    
    
    
    <category term="课题研究" scheme="http://example.com/categories/%E8%AF%BE%E9%A2%98%E7%A0%94%E7%A9%B6/"/>
    
    
  </entry>
  
  <entry>
    <title>交流站</title>
    <link href="http://example.com/2024/12/25/9-%E7%BD%91%E7%AB%99%E6%94%B6%E9%9B%86/%E4%BA%A4%E6%B5%81%E7%AB%99/"/>
    <id>http://example.com/2024/12/25/9-%E7%BD%91%E7%AB%99%E6%94%B6%E9%9B%86/%E4%BA%A4%E6%B5%81%E7%AB%99/</id>
    <published>2024-12-25T08:15:50.000Z</published>
    <updated>2025-09-14T05:00:17.899Z</updated>
    
    <content type="html"><![CDATA[<p>[toc]</p><h1 id="1-技术站"><a href="#1-技术站" class="headerlink" title="1. 技术站"></a>1. 技术站</h1><ol><li><p><a href="https://www.coolaler.com/forums/threads/word-grindeq-math-utilities-2024.382145/">台湾硬件交流</a></p></li><li><p><a href="https://www.nodeseek.com/">NodeSeek</a></p></li><li><p><a href="https://linux.do/">LINUX DO </a></p></li><li><p><a href="https://news.ycombinator.com/news">Hacker News</a></p></li></ol><h1 id="2-知识站"><a href="#2-知识站" class="headerlink" title="2. 知识站"></a>2. 知识站</h1><ol><li><a href="https://www.chaspark.com/#/home">黄大年茶思屋</a></li></ol><h1 id="3-新闻站"><a href="#3-新闻站" class="headerlink" title="3. 新闻站"></a>3. 新闻站</h1><ol><li><a href="https://kite.kagi.com/">kite</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;[toc]&lt;/p&gt;
&lt;h1 id=&quot;1-技术站&quot;&gt;&lt;a href=&quot;#1-技术站&quot; class=&quot;headerlink&quot; title=&quot;1. 技术站&quot;&gt;&lt;/a&gt;1. 技术站&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://www.coolaler.com/</summary>
      
    
    
    
    <category term="网站收集" scheme="http://example.com/categories/%E7%BD%91%E7%AB%99%E6%94%B6%E9%9B%86/"/>
    
    
  </entry>
  
  <entry>
    <title>沸石结构</title>
    <link href="http://example.com/2024/12/17/6-%E8%AF%BE%E9%A2%98%E7%A0%94%E7%A9%B6/%E6%B2%B8%E7%9F%B3%E7%BB%93%E6%9E%84/"/>
    <id>http://example.com/2024/12/17/6-%E8%AF%BE%E9%A2%98%E7%A0%94%E7%A9%B6/%E6%B2%B8%E7%9F%B3%E7%BB%93%E6%9E%84/</id>
    <published>2024-12-17T02:58:35.000Z</published>
    <updated>2024-12-17T12:35:47.165Z</updated>
    
    <content type="html"><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="Oh, this is an invalid password. Check and try again, please." data-whm="OOPS, these decrypted content may changed, but you can still have a look.">  <script id="hbeData" type="hbeData" data-hmacdigest="c1225e29e7de34315ebe7e62a6df8204e3981ec4e4792c61a3c8991ac7bf5f5a">bda6ad0d5f606e7055c23f770369041ffa354e2b32a3834b155272c56f6444661ab7718603343a34c88aae20fc74544723e3f5a785c272956c08b08ed598c2b95ad0ba281bb8c0d0467d8e87b7444228cbc3c750e7d910f39d08ecda732a5f3c6f263f358037a9df260e4ccdbd524de5c21a63c50c77e9c96275c561cbd2d04cc0275330d017d2cdfa7b6ed012f55a70789ae0689d9424d0d0d965b8d9b28ec70be831f23d69ebf6dad257e2e0e0143fb6bfcd965d189060cf3ea8708d1a1db3dc7e7298e03d76070f30b5c287d73b67ab9a2bb060eee9ae7953c30b31bb99dba49e6705963dd27f9567979d705c4e76a7fbce9d7b499e3c939e4aeab1e1b7f7d797ccc9aaac9debc3a73763bafd4b575a9d7f9b2f1f10ef2fd1e07f8a6a7e1e106fc42dc85a3181bdd56f93e1fc013525f6a5b51aa6dac3adbbd847e8119f984d80c98ce2747a182b814292407cdeafa9efbd65dabdf03231b43468b4b842e9333eaf0c8c1ca423d4ad871047246b13e7b495d304f7d3ea3d1eaf96cfa9145484ab88db0e4e9fbcf3fbcb913d9b2f0992d2acf5d5d21f19ef38f158454fe7c59ccbfbb47ac5de0921e69c57bd0cbb0cdb0102a1cc0394c2abe632f8d0a5982778105396a551240047b35c4f3026436d690da2327f8d039fe480698cd8b8f6d07b5816a1cedd6aa20aa28f9811ae2c48d96539c11ed894c17c12b6856b49fb7124f81a0c80314245b87e87868257f0139c1bbc4dcadf0179850f966b84dc63a64cfa835dc672333d8d62aab373d043b3181106645017f1ca35d084faf8012f0c98119d7dc48f6cbdab0f659613e524a7c0a8d6aede4ec93ffa966a1e810f1de2b7b03db187c925789caf369f2735c1e76587d975e4f3665a03c892f0343c0cda78e0fd9b82601c92ad313333742abc53cfde004c0587e285e6a54f59e092e8db2d314959306afdb3d966cf99e713ec5501c496bda777e9945cfe1fb12aed5e55da0bf74164b44341df5f05b5b701710e85845df61502ab51d97ef92641196511da0024f330197e4e3e624c2609b8a1ecd2f8967fd991eafc1f4100d8b3a48f9bdfb7d3f77cb9e4cf73e60343d3ca2a53ae96c6cd5e0f5a1103f7774cb00f1a395cad9abd95595b4ea31817d1d58b3957</script>  <div class="hbe hbe-content">    <div class="hbe hbe-input hbe-input-default">      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">        <span class="hbe hbe-input-label-content hbe-input-label-content-default">Hey, password is required here.</span>      </label>    </div>  </div></div><script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
    
    
    <summary type="html">Here&#39;s something encrypted, password is required to continue reading.</summary>
    
    
    
    <category term="课题研究" scheme="http://example.com/categories/%E8%AF%BE%E9%A2%98%E7%A0%94%E7%A9%B6/"/>
    
    
  </entry>
  
  <entry>
    <title>资源网站</title>
    <link href="http://example.com/2024/12/16/9-%E7%BD%91%E7%AB%99%E6%94%B6%E9%9B%86/%E8%B5%84%E6%BA%90%E7%BD%91%E7%AB%99/"/>
    <id>http://example.com/2024/12/16/9-%E7%BD%91%E7%AB%99%E6%94%B6%E9%9B%86/%E8%B5%84%E6%BA%90%E7%BD%91%E7%AB%99/</id>
    <published>2024-12-16T08:56:28.000Z</published>
    <updated>2025-09-05T06:42:30.694Z</updated>
    
    <content type="html"><![CDATA[<p>[toc]</p><h1 id="1-影视"><a href="#1-影视" class="headerlink" title="1. 影视"></a>1. 影视</h1><ol><li><a href="https://www.jitutv.me/">极兔</a></li><li><a href="https://www.netflixgc.com/">奈飞工厂</a></li><li><a href="https://submit.zone.id/">影视搜索</a>  账号：linuxdo 密码 linuxdo</li><li><a href="https://acg.063888.xyz/">LibreTV - 免费在线视频搜索与观看平台</a> 密码 linuxdo</li><li><a href="https://www.xmaofx.com/">熊猫分享网</a></li></ol><h1 id="2-音乐"><a href="#2-音乐" class="headerlink" title="2. 音乐"></a>2. 音乐</h1><ol><li><p><a href="https://www.hifini.com/">HiFiNi - 音乐磁场</a></p></li><li><p><a href="https://xiageba.com/">下歌吧 </a></p></li></ol><h1 id="3-游戏"><a href="#3-游戏" class="headerlink" title="3. 游戏"></a>3. 游戏</h1><ol><li><a href="https://bbs.3dmgame.com/forum.php">破解游戏论坛 3dm</a></li><li><a href="https://www.xxworld.org/">云酒馆</a></li><li><a href="https://github.com/woniu9524/couple-flying-chess">情侣飞行棋</a></li></ol><h1 id="4-聚合站"><a href="#4-聚合站" class="headerlink" title="4. 聚合站"></a>4. 聚合站</h1><ol><li><a href="https://www.ysa.cc/">伊萨书签</a></li><li><a href="https://link3.cc/galijun">咖喱君的资源库</a></li><li><a href="https://www.xygalaxy.com/">星云导航</a></li><li><a href="https://heeee.com/">资源导航</a></li><li><a href="https://axutongxue.com/">阿虚同学的储物间</a></li><li><a href="https://xydh.fun/">iLinks (高级)</a></li><li><a href="https://www.chongbuluo.com/thread-7961-1-1.html">虫部落 小众网站合集</a></li><li><a href="https://caonima.de/">骂人宝典｜祖安语录</a></li></ol><h1 id="5-阅读"><a href="#5-阅读" class="headerlink" title="5. 阅读"></a>5. 阅读</h1><ol><li><a href="https://beddystories.com/zh">BeddyStories - 全球经典儿童睡前故事库（0-12岁）</a></li><li><a href="https://www.rymdh.com/10513.html">zlibrary数字图书馆官网</a></li><li><a href="https://szsyw.cn/book">电子书导航|数字素养网</a></li><li><a href="https://www.huaijiushuku.com/">怀旧书库 - 中文老旧图书资源下载</a></li><li><a href="https://github.com/TapXWorld/ChinaTextbook/tree/master">义务教育阶段教材</a></li></ol><h1 id="7-pt站"><a href="#7-pt站" class="headerlink" title="7. pt站"></a>7. pt站</h1><blockquote><p> <a href="https://iecho.cc/2019/01/09/PT-%E4%B8%8B%E8%BD%BD%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%BB%E8%80%81/">PT 下载从入门到养老篇一：站点介绍及生存指南 | 回声</a></p><p> <a href="https://wiki.ukenn.top/pt-bt-zhong-jing-chang-jian-dao-de-ci-hui">PT &amp; BT 中经常见到的词汇 | Private Tracker Wiki</a></p><p> <a href="https://post.smzdm.com/p/aqm8opw7/">玩转PT之PT-Plugin-Plus（PT助手)</a> (<a href="https://github.com/pt-plugins/PT-Plugin-Plus/releases/tag/v1.6.1.2780">https://github.com/pt-plugins/PT-Plugin-Plus/releases/tag/v1.6.1.2780</a>)</p><p> <a href="https://wiki.scio.icu/index.php/%E5%86%B3%E5%AE%9A%E8%B8%8F%E5%85%A5PT%E5%89%8D%E4%BD%A0%E5%BA%94%E8%AF%A5%E7%9F%A5%E9%81%93%E7%9A%84%E4%BA%8B%E6%83%85">决定踏入PT前你应该知道的事情</a></p><p> <a href="http://www.ptyqm.com/category/kfyqzc/">开放注册 | PT邀请码网</a></p><p> <a href="https://www.those.cc/652.html">pt 博客</a></p></blockquote><ol><li><a href="https://ptcafe.club/login.php">咖啡pt</a></li><li><a href="https://www.pttime.org/login.php">PTT </a></li><li><a href="https://ptlgs.org/login.php">PTLGS</a></li><li><a href="https://rousi.zip/login.php">Rousi</a></li><li><a href="https://www.icc2022.com/login.php">ICC冰淇淋 </a></li><li><a href="https://ptzone.xyz/login.php">PTzone </a></li><li><a href="https://ptfans.cc/login.php">PTFans</a></li><li><a href="https://1ptba.com/login.php">1PTBA</a></li><li><a href="https://cyanbug.net/login.php">大青虫</a></li><li><a href="https://lemonhd.club/login.php">LemonHD</a></li><li><a href="https://fsm.name/Users/login">FSM 无iyuu</a></li><li><a href="https://raingfh.top/login.php">雨</a></li><li><a href="https://pt.btschool.club/index.php">比特校园 学校</a></li><li><a href="https://52pt.site/index.php">52PT </a></li><li><a href="https://ptchina.org/index.php">铂金学院 </a></li><li><a href="https://discfan.net/torrents.php">DiscFan碟粉</a></li><li><a href="https://www.gamegamept.com/index.php">GGPT 无iyuu </a></li><li><a href="https://kp.m-team.cc/index">M-Team馒头</a></li><li><a href="https://carpt.net/torrents.php">CarPT 车站</a></li><li><a href="https://kufei.org/torrents.php">库非 </a></li><li><a href="https://hdtime.org/index.php">HDTIME</a></li><li><a href="https://ptlover.cc/ok.php?type=confirm">AFUN</a></li><li><a href="https://pt.soulvoice.club/login.php">聆音Club</a></li><li><a href="https://pt.0ff.cc/index.php">Free Farm 自由农场</a></li><li><a href="https://cspt.top/torrents.php">财神</a></li><li><a href="https://xingyunge.top/index.php">星陨阁</a></li><li><a href="https://crabpt.vip/index.php">蟹黄堡</a></li></ol><p>外站：</p><ol><li><a href="https://lusthive.org/">LustHive</a></li><li><a href="https://seedpool.org/login">seedpool</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;[toc]&lt;/p&gt;
&lt;h1 id=&quot;1-影视&quot;&gt;&lt;a href=&quot;#1-影视&quot; class=&quot;headerlink&quot; title=&quot;1. 影视&quot;&gt;&lt;/a&gt;1. 影视&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;https://www.jitutv.me/&quot;&gt;极兔&lt;/a&gt;&lt;/</summary>
      
    
    
    
    <category term="网站收集" scheme="http://example.com/categories/%E7%BD%91%E7%AB%99%E6%94%B6%E9%9B%86/"/>
    
    
    <category term="影视 音乐 游戏 pt站" scheme="http://example.com/tags/%E5%BD%B1%E8%A7%86-%E9%9F%B3%E4%B9%90-%E6%B8%B8%E6%88%8F-pt%E7%AB%99/"/>
    
  </entry>
  
  <entry>
    <title>git使用</title>
    <link href="http://example.com/2024/10/25/5-linux%E5%AD%A6%E4%B9%A0%E4%BD%BF%E7%94%A8/git%E4%BD%BF%E7%94%A8/"/>
    <id>http://example.com/2024/10/25/5-linux%E5%AD%A6%E4%B9%A0%E4%BD%BF%E7%94%A8/git%E4%BD%BF%E7%94%A8/</id>
    <published>2024-10-25T00:55:46.000Z</published>
    <updated>2025-07-25T03:04:17.392Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p><a href="http://www.cnblogs.com/hmy-666/p/17326120.html">www.cnblogs.com/hmy-666/p/17326120.html</a> git 分支的命令与使用</p><p>git 教程（新手向） <a href="https://zhuanlan.zhihu.com/p/135183491">Git 使用教程：最详细、最傻瓜、最浅显、真正手把手教！（万字长文） - 知乎</a></p><p>[Git 基本命令 – 你用过 git diff 吗？补习一下吧 - 知乎](<a href="https://zhuanlan.zhihu.com/p/148312377#:~:text=%E8%BF%90%E8%A1%8C">https://zhuanlan.zhihu.com/p/148312377#:~:text=运行</a> git log –pretty%3Doneline –abbrev-commit 命令看一下当前分支的提交记录，选择两个进行比较。 运行 git,commit 的差异： 好奇宝宝附体，咱们颠倒一下 commit 之间的顺序，看看差异效果 可以看到，比较对象的先后顺序决定了 diff 的差异结果的「增删」。)</p></blockquote><ul><li>概念合集</li></ul><p>远程服务器 远程分支 本地分支 远程跟踪分支&#x3D;&#x3D; 上游分支</p><p><strong>命令合集</strong></p><ul><li><p>指定添加远程仓库和本地名字 git remote add origin <a href="https://github.com/your-username/your-repo-name.git">https://github.com/your-username/your-repo-name.git</a></p></li><li><p>直接拉取远程仓库的main作为本地的main git pull origin main</p></li><li><p>查看分支<code>git branch</code></p></li><li><p>创建分支 <code>git branch &lt;本地分支&gt;</code></p></li><li><p>切换分支 <code>git checkout &lt;本地分支&gt;</code></p></li><li><p>当前分支跟踪远程分支 <code>git branch -u &lt;仓库&gt;/&lt;远程分支&gt;</code></p></li><li><p>将当前分支推送到远程仓库并跟踪新分支或旧分支 <code>git push -u &lt;远程仓库&gt; &lt;远程分支&gt;</code>  <strong>不适合直接修改完提交，会把仓库内旧分支覆盖，可以建一个新分支</strong></p></li><li><p>合并某分支到当前分支 <code>git merge &lt;远程分支&gt;</code> (需要先git fetch) 或者<code>&lt;本地分支&gt;</code></p></li><li><p>删除分支 <code>git branch -d name </code></p></li><li><p>创建本地分支跟踪远程分支 <code>git checkout -b  &lt;新建本地分支&gt; &lt;远程服务器分支&gt;/&lt;远程分支（上游分支&gt;</code> （本地分支和追踪的远程分支不要求名字一定想同）</p></li><li><p>指定已有的分支跟踪远程分支 </p><p><code>git branch &lt;已有的分支&gt; -u &lt;远程服务器分支&gt;/&lt;远程分支&gt; </code>   (u&#x3D; –set upstream-to)</p><p>如果在本地分支下可以 <code>git branch -u &lt;远程仓库&gt;/&lt;远程分支&gt;</code></p></li><li><p>查看远程分支和本地分支跟踪情况</p><p><code>git branch -vv</code></p></li><li><p>删除远程分支</p></li><li><p><code>git push &lt;远程仓库&gt;</code> –delete &lt;远程分支&gt;</p></li><li><p>获取所有分支的更新 <code>git fetch origin</code>  </p><p>获取特定分支的更新 <code>git fetch origin &lt;分支名称&gt;</code></p><p>显示区别 <code>git log / git diff</code></p><p>合并某分支到当前 <code>git merge origin/&lt;远程分支&gt;</code></p></li><li><p><code>git pull</code> 是git fetch 和git merge的组合  <code>git pull origin main</code> &#x3D;&#x3D; <code>git fetch origin </code> + <code>git merge origin/main</code></p></li><li><p>查看所有远程分支 <code>git remote show &lt;远程仓库&gt;</code> ；<code>git fetch </code> + <code>git branch -r</code>  or <code>git branch -a</code></p></li><li><p><code>git pull &lt;仓库名&gt; &lt;仓库分支&gt;:&lt;本地分支&gt;</code>  将仓库与本地分支合并，如果是当前分支，不需要冒号后面的内容</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;http://www.cnblogs.com/hmy-666/p/17326120.html&quot;&gt;www.cnblogs.com/hmy-666/p/17326120.html&lt;/a&gt; git 分支的命令与使用&lt;/p&gt;
&lt;p&gt;git</summary>
      
    
    
    
    <category term="linux学习使用" scheme="http://example.com/categories/linux%E5%AD%A6%E4%B9%A0%E4%BD%BF%E7%94%A8/"/>
    
    
  </entry>
  
  <entry>
    <title>manjaro学习笔记</title>
    <link href="http://example.com/2024/10/03/5-linux%E5%AD%A6%E4%B9%A0%E4%BD%BF%E7%94%A8/manjaro%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <id>http://example.com/2024/10/03/5-linux%E5%AD%A6%E4%B9%A0%E4%BD%BF%E7%94%A8/manjaro%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</id>
    <published>2024-10-03T03:38:17.000Z</published>
    <updated>2024-11-08T02:06:44.886Z</updated>
    
    <content type="html"><![CDATA[<p>[toc]</p><h1 id="1-pacman"><a href="#1-pacman" class="headerlink" title="1. pacman"></a>1. pacman</h1><h1 id="2-配置中文输入法"><a href="#2-配置中文输入法" class="headerlink" title="2.配置中文输入法"></a>2.配置中文输入法</h1><blockquote><p><a href="https://blog.csdn.net/Mingcai_Xiong/article/details/138989121">https://blog.csdn.net/Mingcai_Xiong/article/details/138989121</a></p></blockquote><h1 id="3-安装v2ray代理"><a href="#3-安装v2ray代理" class="headerlink" title="3. 安装v2ray代理"></a>3. 安装v2ray代理</h1><blockquote><p><a href="https://www.wannaexpresso.com/2020/02/23/manjaro-v2ray/">https://www.wannaexpresso.com/2020/02/23/manjaro-v2ray/</a></p><p><a href="https://toutyrater.github.io/prep/start.html">https://toutyrater.github.io/prep/start.html</a></p><p><a href="https://www.v2ray.com/chapter_00/start.html">https://www.v2ray.com/chapter_00/start.html</a></p></blockquote><h1 id="4-修改zsh为bash的shell"><a href="#4-修改zsh为bash的shell" class="headerlink" title="4. 修改zsh为bash的shell"></a>4. 修改zsh为bash的shell</h1><pre><code class="shell">sudo chsh -s --shell /bin/bash lizhao注销后登录</code></pre><h1 id="5-挂载u盘"><a href="#5-挂载u盘" class="headerlink" title="5. 挂载u盘"></a>5. 挂载u盘</h1><blockquote><p><a href="https://blog.csdn.net/qq_37677519/article/details/78160733">https://blog.csdn.net/qq_37677519/article/details/78160733</a></p></blockquote><p><img src="/./../../%E5%9B%BE%E7%89%87/image-20241003222642109.png" alt="image-20241003222642109"></p><p><img src="/./../../%E5%9B%BE%E7%89%87/image-20241003222653282.png" alt="image-20241003222653282"></p><p><img src="/./../../%E5%9B%BE%E7%89%87/image-20241003222706833.png" alt="image-20241003222706833"></p><p><img src="/./../../%E5%9B%BE%E7%89%87/image-20241003222736874.png" alt="image-20241003222736874"></p><p><img src="/./../../%E5%9B%BE%E7%89%87/image-20241003222854582.png" alt="image-20241003222854582"></p><p><img src="/./../../%E5%9B%BE%E7%89%87/image-20241003223013889.png" alt="image-20241003223013889"></p><p><img src="/./../../%E5%9B%BE%E7%89%87/image-20241003223028021.png" alt="image-20241003223028021"></p><p><img src="/./../../%E5%9B%BE%E7%89%87/image-20241003223136102.png" alt="image-20241003223136102"></p><h1 id="1-关于-systemctl"><a href="#1-关于-systemctl" class="headerlink" title="1. 关于 systemctl"></a>1. 关于 systemctl</h1><p><a href="https://www.cnblogs.com/zwcry/p/9602756.html">https://www.cnblogs.com/zwcry/p/9602756.html</a></p><h1 id="2-使用conections从linux连接windows"><a href="#2-使用conections从linux连接windows" class="headerlink" title="2.使用conections从linux连接windows"></a>2.使用conections从linux连接windows</h1><h1 id="3-使用samba访问nas文件"><a href="#3-使用samba访问nas文件" class="headerlink" title="3.使用samba访问nas文件"></a>3.使用samba访问nas文件</h1><p><a href="https://coda.world/linux-and-samba-share/#:~:text=%E7%94%A8%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86%E5%99%A8%E7%9B%B4%E6%8E%A5%E8%AE%BF%E9%97%AE">https://coda.world/linux-and-samba-share/#:~:text=%E7%94%A8%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86%E5%99%A8%E7%9B%B4%E6%8E%A5%E8%AE%BF%E9%97%AE</a></p><p>另一种（不优雅）：smbclient &#x2F;&#x2F;192.168.110.13&#x2F;Home1 -U 18843101769%1021</p><h1 id="4-配置代理"><a href="#4-配置代理" class="headerlink" title="4. 配置代理"></a>4. 配置代理</h1><p><a href="https://zhuanlan.zhihu.com/p/676022554#:~:text=%E6%89%93%E5%BC%80%E7%BB%88%E7%AB%AF%E8%BE%93%E5%85%A5%E4%BB%A5%E4%B8%8B%E5%91%BD%E4%BB%A4">https://zhuanlan.zhihu.com/p/676022554#:~:text=%E6%89%93%E5%BC%80%E7%BB%88%E7%AB%AF%E8%BE%93%E5%85%A5%E4%BB%A5%E4%B8%8B%E5%91%BD%E4%BB%A4</a></p><h1 id="5-使用快照备份系统"><a href="#5-使用快照备份系统" class="headerlink" title="5.使用快照备份系统"></a>5.使用快照备份系统</h1><p><a href="https://cn.linux-console.net/?p=19103#:~:text=%E6%9C%AC%E5%88%9D%E5%AD%A6%E8%80%85%E6%8C%87%E5%8D%97%E5%90%91%E6%82%A8%E5%B1%95%E7%A4%BA">https://cn.linux-console.net/?p=19103#:~:text=%E6%9C%AC%E5%88%9D%E5%AD%A6%E8%80%85%E6%8C%87%E5%8D%97%E5%90%91%E6%82%A8%E5%B1%95%E7%A4%BA</a></p><h1 id="6-使用Backups备份文件"><a href="#6-使用Backups备份文件" class="headerlink" title="6.使用Backups备份文件"></a>6.使用Backups备份文件</h1><h1 id="7-安装微信"><a href="#7-安装微信" class="headerlink" title="7.安装微信"></a>7.安装微信</h1><p><a href="https://wenku.csdn.net/answer/4tppvuy282">https://wenku.csdn.net/answer/4tppvuy282</a></p><h1 id="8-常用命令"><a href="#8-常用命令" class="headerlink" title="8.常用命令"></a>8.常用命令</h1><p><a href="https://cloud.tencent.com/developer/article/2223411">https://cloud.tencent.com/developer/article/2223411</a></p><h1 id="9-添加AUR源"><a href="#9-添加AUR源" class="headerlink" title="9.添加AUR源"></a>9.添加AUR源</h1><p><a href="https://cloud.tencent.com/developer/article/1948468">https://cloud.tencent.com/developer/article/1948468</a></p><h1 id="10-pamac无法查看分类-和AUR源"><a href="#10-pamac无法查看分类-和AUR源" class="headerlink" title="10. pamac无法查看分类 和AUR源"></a>10. pamac无法查看分类 和AUR源</h1><p>关闭软件模式</p><p><img src="/../../%E5%9B%BE%E7%89%87/image-20241008110252006.png" alt="image-20241008110252006"></p><ul><li><p>查看AUR源需要再点一下搜索，使用pamac命令在命令行搜索能够查找AUR源</p><p>或者关掉然后重新开启以下</p><p>查看源是否有问题 yay -p -Q</p></li></ul><h1 id="11-使用rsync备份文件"><a href="#11-使用rsync备份文件" class="headerlink" title="11.使用rsync备份文件"></a>11.使用rsync备份文件</h1><p><a href="https://www.ruanyifeng.com/blog/2020/08/rsync.html">https://www.ruanyifeng.com/blog/2020/08/rsync.html</a></p><h1 id="12-将用户加到管理员组"><a href="#12-将用户加到管理员组" class="headerlink" title="12.将用户加到管理员组"></a>12.将用户加到管理员组</h1><p><code>sudo usermod -aG wheel lizhao</code></p><h1 id="13-command命令"><a href="#13-command命令" class="headerlink" title="13.command命令"></a>13.command命令</h1><p>command -V </p><h1 id="14-关于路由、端口、主机动态ip、静态ip、主机mac"><a href="#14-关于路由、端口、主机动态ip、静态ip、主机mac" class="headerlink" title="14.关于路由、端口、主机动态ip、静态ip、主机mac"></a>14.关于路由、端口、主机动态ip、静态ip、主机mac</h1><ul><li><p>路由分配给主机ip, 这个主机相当于挂载在路由上的一个端口上。需要首先由路由分配给主机一个静态ip（从LAN设置）和设置一个端口映射，</p></li><li><p>主机应该打开sshd服务，这样外面的机器可以访问本地 </p><p><code>systemctl start sshd</code></p></li><li><p>同一个路由下的主机的ip地址前几个是相同的，可以通过输入前几个进入路由设置</p></li><li><p>访问时，访问路由的特定端口，然后 由路由转到主机</p></li><li><p>访问路由可以通过 ip address 查看ip,然后删除最后的数字换成1</p></li></ul><p><img src="/../../%E5%9B%BE%E7%89%87/image-20241008164703168.png" alt="image-20241008164703168"></p><p><img src="/../../%E5%9B%BE%E7%89%87/image-20241008165352346.png" alt="image-20241008165352346"></p><h1 id="15-xdotool工具"><a href="#15-xdotool工具" class="headerlink" title="15. xdotool工具"></a>15. xdotool工具</h1><p><a href="http://git.malu.me/xdotool%E8%87%AA%E5%8A%A8%E5%8C%96%E5%B7%A5%E5%85%B7%E7%AC%94%E8%AE%B0/w">http://git.malu.me/xdotool%E8%87%AA%E5%8A%A8%E5%8C%96%E5%B7%A5%E5%85%B7%E7%AC%94%E8%AE%B0/w</a></p><h1 id="16-不同系统的区别"><a href="#16-不同系统的区别" class="headerlink" title="16.不同系统的区别"></a>16.不同系统的区别</h1><p><a href="https://www.51cto.com/article/621615.html">https://www.51cto.com/article/621615.html</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;[toc]&lt;/p&gt;
&lt;h1 id=&quot;1-pacman&quot;&gt;&lt;a href=&quot;#1-pacman&quot; class=&quot;headerlink&quot; title=&quot;1. pacman&quot;&gt;&lt;/a&gt;1. pacman&lt;/h1&gt;&lt;h1 id=&quot;2-配置中文输入法&quot;&gt;&lt;a href=&quot;#2-配置中</summary>
      
    
    
    
    <category term="linux学习使用" scheme="http://example.com/categories/linux%E5%AD%A6%E4%B9%A0%E4%BD%BF%E7%94%A8/"/>
    
    
  </entry>
  
  <entry>
    <title>不同的主动学习方法</title>
    <link href="http://example.com/2024/08/29/4-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8D%E5%90%8C%E7%9A%84%E4%B8%BB%E5%8A%A8%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/"/>
    <id>http://example.com/2024/08/29/4-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8D%E5%90%8C%E7%9A%84%E4%B8%BB%E5%8A%A8%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/</id>
    <published>2024-08-29T00:08:58.000Z</published>
    <updated>2024-08-29T07:47:17.058Z</updated>
    
    <content type="html"><![CDATA[<p>[toc]</p><h1 id="1-随机位移的方法"><a href="#1-随机位移的方法" class="headerlink" title="1. 随机位移的方法"></a>1. 随机位移的方法</h1><p><strong>给整个结构中的原子引入随机位移，代替md过程，增加采样</strong></p><p>核心脚本</p><p><code>random_distance.py</code></p><p>需要的文件</p><p><code>sub-grade.sh  POSCAR inv2 </code></p><pre><code class="python">import numpy as npfrom sys import argvfrom ase.atoms import Atomsfrom ase.io import readimport osimport subprocessimport shutildef write2my(file_path, ene_i, lat_i, ele_i, coo_i, foc_i, vir_i=None):    lat_i = lat_i.reshape(3, 3)    coo_i = coo_i.reshape(-1, 3)    foc_i = foc_i.reshape(-1, 3)    with open(file_path, &#39;w&#39;) as file:        file.write(f&quot;# total energy = &#123;ene_i&#125; eV\n\n&quot;)        if vir_i is not None:            vir_i = np.array(vir_i).reshape(-1)            file.write(f&quot;VIRIAL\n&quot;)            for i in vir_i:                file.write(f&#39;&#123;i:20.8f&#125;&#39;)        file.write(&quot;\n&quot;)        file.write(&quot;CRYSTAL\n&quot;)        file.write(&quot;PRIMVEC\n&quot;)        for j in lat_i:            for k in j:                file.write(f&#39;&#123;k:20.8f&#125;&#39;)            file.write(&#39;\n&#39;)        file.write(&quot;PRIMCOORD\n&quot;)        file.write(f&quot;&#123;len(coo_i)&#125; 1\n&quot;)        for j in range(len(coo_i)):            file.write(f&#39;&#123;ele_i[j]:2&#125;&#39;)            # coo            for k in coo_i[j]:                file.write(f&quot;&#123;k:20.8f&#125;&quot;)            # force            for k in foc_i[j]:                file.write(f&quot;&#123;k:20.8f&#125;&quot;)            file.write(&quot;\n&quot;)    passdef read_from_ase_atoms(atoms: Atoms):    try:        ene = atoms.get_potential_energy()    except:        ene = 0.0    lat = atoms.get_cell()    pos = atoms.get_positions()    try:        foc = atoms.get_forces()    except:        foc = np.zeros_like(pos)    try:        sts = atoms.get_stress()        xx, yy, zz, yz, xz, xy = - sts * atoms.get_volume()        vir = np.array(            [[xx, xy, xz],             [xy, yy, yz],             [xz, yz, zz]]).reshape(-1)    except:        vir = np.zeros([3, 3])    ele = atoms.get_chemical_symbols()    return ene, lat, pos, foc, vir, eledef read_poscar(filename):    with open(filename,&#39;r&#39;) as file:        lines =file.readlines()    title =lines[0].strip()    scale =float(lines[1].strip())    #for i in range(2,5):    #    lattice_list.append(list(map(float,line[i].split())))    #lattice_array=np.array(lattice_list)    lattice_vectors = np.array([list(map(float,lines[i].split())) for i in range(2,5)])    element_type=lines[5].split()    atomnumbers=np.array(list(map(int,lines[6].split())))    atompositions=np.array([list(map(float,lines[i].split()[:3])) for i in range(8,8+sum(atomnumbers))])    cor_type = lines[7].strip()    if cor_type.lower() == &quot;direct&quot; or cor_type.lower() == &quot;d&quot;:        atompositions[atompositions &lt; 0]+=1        atompositions[atompositions &gt;=1]-=1    elif cor_type.lower() == &quot;cartesian&quot; or cor_type.lower() == &quot;c&quot;:        pass    return(title,scale,lattice_vectors,element_type,atomnumbers,cor_type,atompositions)def write_poscar(filename,title,scale,lattice_vectors,element_type,atomnumbers,cor_type,atompositions):     with open(filename,&#39;w&#39;) as file:        file.write(f&quot;&#123;title&#125;\n&quot;)        file.write(f&quot;&#123;scale&#125;\n&quot;)        for vec in lattice_vectors:            file.write(f&quot;&#123;vec[0]:.8f&#125;  &#123;vec[1]:.8f&#125;  &#123;vec[2]:.8f&#125;\n&quot;)        #&quot;  &quot;.join用于将可迭代对象的元素以空格连接起来        file.write(&quot;  &quot;.join(element_type)+ &quot;\n&quot;)        file.write(&quot;  &quot;.join(map(str,atomnumbers))+ &quot;\n&quot;)        file.write(f&quot;&#123;cor_type&#125;\n&quot;)        for pos in atompositions:            file.write(f&quot;&#123;pos[0]:.8f&#125;  &#123;pos[1]:.8f&#125;  &#123;pos[2]:.8f&#125;\n&quot;)def change_dir_to_car(filename):    title,scale,lattice_vectors,element_type,atomnumbers,cor_type,atompositions= read_poscar(filename)    if cor_type.lower() == &quot;cartesian&quot; or cor_type.lower() == &quot;c&quot;:        pass    elif cor_type.lower() == &quot;direct&quot; or cor_type.lower() == &quot;d&quot;:        atompositions = np.dot(atompositions,lattice_vectors)        cor_type = &quot;Cartesian&quot;    return title,scale,lattice_vectors,element_type,atomnumbers,cor_type,atompositionsdef atom_pos(atomnumbers,atompositions):    atom_pos = np.split(atompositions,np.cumsum(atomnumbers)[:-1])    return atom_posparent_dir = os.path.dirname(os.getcwd())oos_dir = os.path.join(parent_dir, &quot;oos&quot;)os.makedirs(oos_dir, exist_ok=True)counter = 0counter2 = 0counter3 = 0exit_flag = Falsefor itera in range(1, 100):    if exit_flag:        break    mignitude1 = 0.0018*itera    mignitude2 = 0.0009*itera    mignitude3 = 0.0017*itera    mignitude4 = 0.0022*itera        title,scale,lattice_vectors,element_type,atomnumbers,cor_type,atompositions=change_dir_to_car(&quot;POSCAR&quot;)        atom_pos = atom_pos(atomnumbers,atompositions)    for i in range(1,10001):        counter3 +=1        if exit_flag:            break        counter +=1        rd1=np.random.randn(atomnumbers[0],3)*mignitude1        rd2=np.random.randn(atomnumbers[1],3)*mignitude1        rd3=np.random.randn(atomnumbers[2],3)*mignitude1        rd4=np.random.randn(atomnumbers[3],3)*mignitude1        atom_pos[0]+=rd1        atom_pos[1]+=rd2        atom_pos[2]+=rd3        atom_pos[3]+=rd4        atompositions = np.concatenate(atom_pos)        write_poscar(f&quot;&#123;counter&#125;.vasp&quot;,title,scale,lattice_vectors,element_type,atomnumbers,cor_type,atompositions)        datas = read(f&quot;&#123;counter&#125;.vasp&quot;, index=&quot;:&quot;)        ene, lat, pos, foc, vir, ele = read_from_ase_atoms(datas[0])        write2my(            f&quot;&#123;counter&#125;.xsf&quot;,            ene_i=ene,            lat_i=lat,            ele_i=ele,            coo_i=pos,            foc_i=foc,            vir_i=vir)        os.remove(f&quot;&#123;counter&#125;.vasp&quot;)        print(counter3)        if counter3 &gt;= 100:            subprocess.run([&quot;sh&quot;, &quot;sub-grade.sh&quot;], check=True)            with open(&quot;grade-log&quot;, &#39;r&#39;) as file:                lines = file.readlines()                        for line in lines:                if exit_flag:                    break                if &#39;grad:&#39; in line:                    parts = line.split()                    filename = parts[0]                    grade_value = float(parts[-1])                    if 3 &lt; grade_value &lt; 8:                        counter2 += 1                        if counter2 &gt;= 50:                            exit_flag = True                            break                        src = os.path.join(os.getcwd(), filename)                        dst = os.path.join(oos_dir, filename)                        shutil.move(src, dst)                    else:                        os.remove(filename)                    counter3 = 0            </code></pre><p><code>iter_scheduling_remote.sh</code> 中修改的内容</p><pre><code class="shell">echo &quot;Simulation ...&quot;# run local &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;mkdir random_vaspmv sub-grade.sh random_vaspmv Ap_inv* random_vaspmv inv2 random_vaspmv random_distance.py random_vaspmv POSCAR random_vaspcd random_vasppython random_distance.py</code></pre><h1 id="2-切割的方法"><a href="#2-切割的方法" class="headerlink" title="2. 切割的方法"></a>2. 切割的方法</h1><p>切割后的结构grade比较大，不太好用</p><pre><code class="python">&quot;&quot;&quot;输入可以有多种形式,输出目前只有writ_poscar可以&quot;&quot;&quot;import numpy as npimport osfrom ase.atoms import Atomsfrom ase.io import readimport subprocessimport shutildef write2my(file_path, ene_i, lat_i, ele_i, coo_i, foc_i, vir_i=None):    lat_i = lat_i.reshape(3, 3)    coo_i = coo_i.reshape(-1, 3)    foc_i = foc_i.reshape(-1, 3)    with open(file_path, &#39;w&#39;) as file:        file.write(f&quot;# total energy = &#123;ene_i&#125; eV\n\n&quot;)        if vir_i is not None:            vir_i = np.array(vir_i).reshape(-1)            file.write(f&quot;VIRIAL\n&quot;)            for i in vir_i:                file.write(f&#39;&#123;i:20.8f&#125;&#39;)        file.write(&quot;\n&quot;)        file.write(&quot;CRYSTAL\n&quot;)        file.write(&quot;PRIMVEC\n&quot;)        for j in lat_i:            for k in j:                file.write(f&#39;&#123;k:20.8f&#125;&#39;)            file.write(&#39;\n&#39;)        file.write(&quot;PRIMCOORD\n&quot;)        file.write(f&quot;&#123;len(coo_i)&#125; 1\n&quot;)        for j in range(len(coo_i)):            file.write(f&#39;&#123;ele_i[j]:2&#125;&#39;)            # coo            for k in coo_i[j]:                file.write(f&quot;&#123;k:20.8f&#125;&quot;)            # force            for k in foc_i[j]:                file.write(f&quot;&#123;k:20.8f&#125;&quot;)            file.write(&quot;\n&quot;)    passdef read_from_ase_atoms(atoms: Atoms):    try:        ene = atoms.get_potential_energy()    except:        ene = 0.0    lat = atoms.get_cell()    pos = atoms.get_positions()    try:        foc = atoms.get_forces()    except:        foc = np.zeros_like(pos)    try:        sts = atoms.get_stress()        xx, yy, zz, yz, xz, xy = - sts * atoms.get_volume()        vir = np.array(            [[xx, xy, xz],             [xy, yy, yz],             [xz, yz, zz]]).reshape(-1)    except:        vir = np.zeros([3, 3])    ele = atoms.get_chemical_symbols()    return ene, lat, pos, foc, vir, eledef read_poscar(filename):    with open(filename,&#39;r&#39;) as file:        lines =file.readlines()    title =lines[0].strip()    scale =float(lines[1].strip())    #for i in range(2,5):    #    lattice_list.append(list(map(float,line[i].split())))    #lattice_array=np.array(lattice_list)    lattice_vectors = np.array([list(map(float,lines[i].split())) for i in range(2,5)])    element_type=lines[5].split()    atomnumbers=np.array(list(map(int,lines[6].split())))    atompositions=np.array([list(map(float,lines[i].split()[:3])) for i in range(8,8+sum(atomnumbers))])    cor_type = lines[7].strip()    if cor_type.lower() == &quot;direct&quot; or cor_type.lower() == &quot;d&quot;:        atompositions[atompositions &lt; 0]+=1        atompositions[atompositions &gt;=1]-=1    elif cor_type.lower() == &quot;cartesian&quot; or cor_type.lower() == &quot;c&quot;:        pass    return(title,scale,lattice_vectors,element_type,atomnumbers,cor_type,atompositions)def write_poscar(filename,title,scale,lattice_vectors,element_type,atomnumbers,cor_type,atompositions):     with open(filename,&#39;w&#39;) as file:        file.write(f&quot;&#123;title&#125;\n&quot;)        file.write(f&quot;&#123;scale&#125;\n&quot;)        for vec in lattice_vectors:            file.write(f&quot;&#123;vec[0]:.8f&#125;  &#123;vec[1]:.8f&#125;  &#123;vec[2]:.8f&#125;\n&quot;)        #&quot;  &quot;.join用于将可迭代对象的元素以空格连接起来        file.write(&quot;  &quot;.join(element_type)+ &quot;\n&quot;)        file.write(&quot;  &quot;.join(map(str,atomnumbers))+ &quot;\n&quot;)        file.write(f&quot;&#123;cor_type&#125;\n&quot;)        for pos in atompositions:            file.write(f&quot;&#123;pos[0]:.8f&#125;  &#123;pos[1]:.8f&#125;  &#123;pos[2]:.8f&#125;\n&quot;)#输出不同类型原子的坐标def atom_pos(atomnumbers,atompositions):    atom_pos = np.split(atompositions,np.cumsum(atomnumbers)[:-1])    return atom_pos        &quot;&quot;&quot;功能区&quot;&quot;&quot;#计算体积def cal_volume(lattice_vectors):    volume = np.abs(np.dot(lattice_vectors[0],np.cross(lattice_vectors[1],lattice_vectors[2])))    return volume#转换分数坐标为笛卡尔坐标def change_dir_to_car(filename):    title,scale,lattice_vectors,element_type,atomnumbers,cor_type,atompositions= read_poscar(filename)    if cor_type.lower() == &quot;cartesian&quot; or cor_type.lower() == &quot;c&quot;:        pass    elif cor_type.lower() == &quot;direct&quot; or cor_type.lower() == &quot;d&quot;:        atompositions = np.dot(atompositions,lattice_vectors)        cor_type = &quot;Cartesian&quot;    return title,scale,lattice_vectors,element_type,atomnumbers,cor_type,atompositions#笛卡尔坐标转换为分数坐标def change_car_to_dir(filename):    title,scale,lattice_vectors,element_type,atomnumbers,cor_type,atompositions = read_poscar(filename)    if cor_type.lower() == &quot;cartesian&quot; or cor_type.lower() == &quot;c&quot;:        atompositions = np.dot(atompositions,np.linalg.inv(lattice_vectors))        cor_type = &quot;Direct&quot;        atompositions[atompositions &lt; 0]+=1        atompositions[atompositions &gt;=1]-=1    elif cor_type.lower() == &quot;direct&quot; or cor_type.lower() == &quot;d&quot;:        pass    return title,scale,lattice_vectors,element_type,atomnumbers,cor_type,atompositions#晶格向量的变换def lattice_change(filename,cell_type):    title,scale,lattice_vectors,element_type,atomnumbers,cor_type,atompositions= change_car_to_dir(filename)    if cell_type == &#39;211&#39;:        pass    elif cell_type == &quot;121&quot;:        middle_value = lattice_vectors[0].copy()        lattice_vectors[0] = lattice_vectors[1]        lattice_vectors[1] = lattice_vectors[2]        lattice_vectors[2] = middle_value        middle_value2 = atompositions[:,0].copy()        atompositions[:,0] = atompositions[:,1]        atompositions[:,1] = atompositions[:,2]        atompositions[:,2] = middle_value2    elif cell_type == &quot;112&quot;:        middle_value = lattice_vectors[0].copy()        lattice_vectors[0] = lattice_vectors[2]        lattice_vectors[2] = lattice_vectors[1]        lattice_vectors[1] = middle_value        middle_value2 = atompositions[:,0].copy        atompositions[:,0] = atompositions[:,2]        atompositions[:,2] = atompositions[:,1]        atompositions[:,1] = middle_value2    return title,scale,lattice_vectors,element_type,atomnumbers,cor_type,atompositions#将211晶胞分解为两个111晶胞def split_211(input_file,cell_type,output_file1,output_file2):    title,scale,lattice_vectors,element_type,atomnumbers,cor_type,atompositions= lattice_change(input_file,cell_type)    atom_type_pos = atom_pos(atomnumbers,atompositions)    total_atoms1 = []    total_atoms_number1 = []    total_atoms2 = []    total_atoms_number2 = []    if cor_type.lower() == &quot;direct&quot; or cor_type.lower() == &quot;d&quot;:        for sub_atom_type_pos in atom_type_pos:            print(sub_atom_type_pos)            coord_1=sub_atom_type_pos[sub_atom_type_pos[:,0]&lt;=0.48].copy()            total_atoms1.append(coord_1)            total_atoms_number1.append(len(coord_1))                    coord_2=sub_atom_type_pos[sub_atom_type_pos[:,0]&gt;0.52].copy()            total_atoms2.append(coord_2)            total_atoms_number2.append(len(coord_2))    # elif cor_type.lower() == &quot;cartesian&quot; or cor_type.lower() == &quot;c&quot;:    #     for sub_atom_type_pos in atom_type_pos:    #         sub_atom_type_pos=np.dot(sub_atom_type_pos,np.linalg.inv(lattice_vectors))    #         sub_atom_type_pos[sub_atom_type_pos &lt; 0]+=1    #         sub_atom_type_pos[sub_atom_type_pos &gt;=1]-=1    #         coord_1=sub_atom_type_pos[sub_atom_type_pos[:,0]&lt;=0.5].copy()    #         total_atoms1.append(coord_1)    #         total_atoms_number1.append(len(coord_1))            #         coord_2=sub_atom_type_pos[sub_atom_type_pos[:,0]&gt;0.5].copy()    #         total_atoms2.append(coord_2)    #         total_atoms_number2.append(len(coord_2))    #     cor_type = &quot;Direct&quot;    total_atoms1=np.vstack(total_atoms1)    total_atoms2=np.vstack(total_atoms2)    total_atoms1=np.dot(total_atoms1,lattice_vectors)    total_atoms2=np.dot(total_atoms2,lattice_vectors)    lattice_vectors[0]/=2    cor_type =&quot;Cartesian&quot;    # print(total_atoms1)    # print(total_atoms_number1)    write_poscar(output_file1,title,scale,lattice_vectors,element_type,total_atoms_number1,cor_type,total_atoms1)    write_poscar(output_file2,title,scale,lattice_vectors,element_type,total_atoms_number2,cor_type,total_atoms2)#POSCAR坐标的修改def coords_change(axis,value,cor_type,atompositions):    if cor_type.lower() == &quot;Cartesian&quot; or cor_type.lower() == &quot;c&quot;:        print(&quot;use change_car_to_dir to input&quot;)    elif cor_type.lower() == &quot;direct&quot; or cor_type.lower() == &quot;d&quot;:        if axis == &#39;x&#39;:           atompositions[:,0] += value        elif axis == &#39;y&#39;:           atompositions[:,1] += value        elif axis == &#39;z&#39;:           atompositions[:,2] += value        else:            raise ValueError(f&quot;invalid axis&quot;)    else:        raise ValueError(f&quot;invalid cor_type&quot;)    return atompositions#切割x*y*z倍的晶胞为x*y*z个晶胞def split_cell(input_file,x,y,z):    input_file_without_ext = os.path.splitext(input_file)[0]    title,scale,lattice_vectors,element_type,atomnumbers,cor_type,atompositions= change_car_to_dir(input_file)    atom_type_pos = atom_pos(atomnumbers,atompositions)    total_cells = [[[&#123;elem:[] for elem in element_type&#125; for _ in range(z)] for _ in range(y)] for _ in range(x)]    total_atom_numbers = [[[&#123;elem: 0 for elem in element_type&#125; for _ in range(z)] for _ in range(y)] for _ in range(x)]    if cor_type.lower() == &quot;direct&quot; or cor_type.lower == &quot;d&quot;:        for elem_index,sub_atom_type_pos in enumerate(atom_type_pos):            elem = element_type[elem_index]            for atom in sub_atom_type_pos:                ix = int(atom[0]*x)                iy = int(atom[1]*y)                iz = int(atom[2]*z)                total_cells[ix][iy][iz][elem].append(atom)                total_atom_numbers[ix][iy][iz][elem] += 1    cor_type =&quot;Cartesian&quot;    lattice_vectors_changed = np.zeros((3,3))    lattice_vectors_changed[0] = lattice_vectors[0]/x    lattice_vectors_changed[1] = lattice_vectors[1]/y    lattice_vectors_changed[2] = lattice_vectors[2]/z    os.makedirs(&quot;xsf_output&quot;)    for ix in range(x):        for iy in range(y):            for iz in range(z):                output_file =f&quot;&#123;input_file_without_ext&#125;_&#123;ix&#125;&#123;iy&#125;&#123;iz&#125;.vasp&quot;                sub_atoms = np.vstack([atom for elem in element_type for atom in total_cells[ix][iy][iz][elem]])                sub_atoms = np.dot(sub_atoms, lattice_vectors)                subcell_numbers = [total_atom_numbers[ix][iy][iz][elem] for elem in element_type]                write_poscar(output_file,title,scale,lattice_vectors_changed,element_type,subcell_numbers,cor_type,sub_atoms)                datas = read(output_file, index=&quot;:&quot;)                ene, lat, pos, foc, vir, ele = read_from_ase_atoms(datas[0])                output_file_path = os.path.join(&quot;xsf_output&quot;, f&quot;&#123;output_file&#125;.xsf&quot;)                write2my(                    output_file_path,                    ene_i=ene,                    lat_i=lat,                    ele_i=ele,                    coo_i=pos,                    foc_i=foc,                    vir_i=vir)split_cell(&quot;POSCAR&quot;,2,2,2)#os.remove(&quot;POS&quot;)subprocess.run([&quot;dsub&quot;,&quot;-s&quot;,&quot;sub-grade.sh&quot;], check=True)counter = 0with open(&quot;grade-log&quot;, &#39;r&#39;) as file:    lines = file.readlines()    for line in lines:        if &#39;grad:&#39; in line:            parts = line.split()            filename = parts[0]            filename_first = os.path.splitext(filename)[0]            grade_value = float(parts[-1])            if 3 &lt; grade_value &lt; 8:                os.makedirs(filename_first)                shutil.move(f&quot;&#123;filename_first&#125;&quot;, os.path.join (filename_first, &quot;POSCAR&quot;))            else:                os.remove(f&quot;&#123;filename_first&#125;&quot;)</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;[toc]&lt;/p&gt;
&lt;h1 id=&quot;1-随机位移的方法&quot;&gt;&lt;a href=&quot;#1-随机位移的方法&quot; class=&quot;headerlink&quot; title=&quot;1. 随机位移的方法&quot;&gt;&lt;/a&gt;1. 随机位移的方法&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;给整个结构中的原子引入随机位移，代替m</summary>
      
    
    
    
    <category term="机器学习" scheme="http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
</feed>
